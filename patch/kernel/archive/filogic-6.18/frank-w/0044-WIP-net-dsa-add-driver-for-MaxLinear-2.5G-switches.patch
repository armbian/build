From c5daa616c37a4aab28262c60f53976ddf241e3e3 Mon Sep 17 00:00:00 2001
From: Daniel Golle <daniel@makrotopia.org>
Date: Fri, 28 Feb 2025 13:24:27 +0000
Subject: [PATCH 044/116] WIP: net: dsa: add driver for MaxLinear 2.5G switches

Add support for the MXL862xx family of switches offering 4 or 8
2500M/1000M/100M/10M user ports as well as 1 or 2 USXGMII SerDes
interfaces.

WORK IN PROGRESS
---
 drivers/net/dsa/Kconfig                  |    2 +
 drivers/net/dsa/Makefile                 |    1 +
 drivers/net/dsa/mxl862xx/Kconfig         |    7 +
 drivers/net/dsa/mxl862xx/Makefile        |    3 +
 drivers/net/dsa/mxl862xx/mxl862xx-api.h  | 1468 +++++++++
 drivers/net/dsa/mxl862xx/mxl862xx-cmd.h  |  216 ++
 drivers/net/dsa/mxl862xx/mxl862xx-host.c |  201 ++
 drivers/net/dsa/mxl862xx/mxl862xx-host.h |    3 +
 drivers/net/dsa/mxl862xx/mxl862xx.c      | 3568 ++++++++++++++++++++++
 drivers/net/dsa/mxl862xx/mxl862xx.h      |   86 +
 10 files changed, 5555 insertions(+)
 create mode 100644 drivers/net/dsa/mxl862xx/Kconfig
 create mode 100644 drivers/net/dsa/mxl862xx/Makefile
 create mode 100644 drivers/net/dsa/mxl862xx/mxl862xx-api.h
 create mode 100644 drivers/net/dsa/mxl862xx/mxl862xx-cmd.h
 create mode 100644 drivers/net/dsa/mxl862xx/mxl862xx-host.c
 create mode 100644 drivers/net/dsa/mxl862xx/mxl862xx-host.h
 create mode 100644 drivers/net/dsa/mxl862xx/mxl862xx.c
 create mode 100644 drivers/net/dsa/mxl862xx/mxl862xx.h

diff --git a/drivers/net/dsa/Kconfig b/drivers/net/dsa/Kconfig
index 4d9af691b989..2000282185e6 100644
--- a/drivers/net/dsa/Kconfig
+++ b/drivers/net/dsa/Kconfig
@@ -78,6 +78,8 @@ source "drivers/net/dsa/ocelot/Kconfig"
 
 source "drivers/net/dsa/qca/Kconfig"
 
+source "drivers/net/dsa/mxl862xx/Kconfig"
+
 source "drivers/net/dsa/sja1105/Kconfig"
 
 source "drivers/net/dsa/xrs700x/Kconfig"
diff --git a/drivers/net/dsa/Makefile b/drivers/net/dsa/Makefile
index 0f8ff4a1a313..787dd30eb2f2 100644
--- a/drivers/net/dsa/Makefile
+++ b/drivers/net/dsa/Makefile
@@ -19,6 +19,7 @@ obj-y				+= hirschmann/
 obj-y				+= lantiq/
 obj-y				+= microchip/
 obj-y				+= mv88e6xxx/
+obj-y				+= mxl862xx/
 obj-y				+= ocelot/
 obj-y				+= qca/
 obj-y				+= realtek/
diff --git a/drivers/net/dsa/mxl862xx/Kconfig b/drivers/net/dsa/mxl862xx/Kconfig
new file mode 100644
index 000000000000..5b4e05181dc6
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/Kconfig
@@ -0,0 +1,7 @@
+# SPDX-License-Identifier: GPL-2.0-only
+config NET_DSA_MXL862
+	tristate "MaxLinear MxL862xx"
+	depends on NET_DSA
+	select NET_DSA_TAG_MXL862
+	help
+	  This enables support for the MaxLinear MxL862xx switch family.
diff --git a/drivers/net/dsa/mxl862xx/Makefile b/drivers/net/dsa/mxl862xx/Makefile
new file mode 100644
index 000000000000..d23dd3cd511d
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/Makefile
@@ -0,0 +1,3 @@
+# SPDX-License-Identifier: GPL-2.0
+obj-$(CONFIG_NET_DSA_MXL862) += mxl862xx_dsa.o
+mxl862xx_dsa-y := mxl862xx.o mxl862xx-host.o
diff --git a/drivers/net/dsa/mxl862xx/mxl862xx-api.h b/drivers/net/dsa/mxl862xx/mxl862xx-api.h
new file mode 100644
index 000000000000..d8ae6c1de289
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/mxl862xx-api.h
@@ -0,0 +1,1468 @@
+/**
+ * struct mdio_relay_data - relayed access to the switch internal MDIO bus
+ * @data: data to be read or written
+ * @phy: PHY index
+ * @mmd: MMD device
+ * @reg: register rndex
+ */
+struct mdio_relay_data {
+	__le16 data;
+	u8 phy;
+	u8 mmd;
+	__le16 reg;
+} __packed;
+
+/* Register access parameter to directly modify internal registers */
+struct mxl862xx_register_mod {
+	__le16 addr;
+	__le16 data;
+	__le16 mask;
+} __packed;
+
+/**
+ * enum mxl862xx_mac_clear_type - MAC table clear type
+ * @MXL862XX_MAC_CLEAR_PHY_PORT: clear dynamic entries based on port_id
+ * @MXL862XX_MAC_CLEAR_DYNAMIC: clear all dynamic entries
+ */
+enum mxl862xx_mac_clear_type {
+	MXL862XX_MAC_CLEAR_PHY_PORT = 0,
+	MXL862XX_MAC_CLEAR_DYNAMIC,
+};
+
+/**
+ * struct mxl862xx_mac_table_clear - MAC table clear
+ * @type: see &enum mxl862xx_mac_clear_type
+ * @port_id: physical port id
+ */
+struct mxl862xx_mac_table_clear {
+	u8 type;
+	u8 port_id;
+} __packed;
+
+/**
+ * enum mxl862xx_pmapper_mapping_mode - P-mapper Mapping Mode
+ * @MXL862XX_PMAPPER_MAPPING_PCP = 0, Use PCP for VLAN tagged packets to derive sub interface ID group
+ * @MXL862XX_PMAPPER_MAPPING_LAG = 1, Use LAG Index for Pmapper access (regardless of IP and VLAN packet)
+ * @MXL862XX_PMAPPER_MAPPING_DSCP = 2, Use DSCP for VLAN tagged IP packets to derive sub interface ID group
+ */
+enum mxl862xx_pmapper_mapping_mode {
+	MXL862XX_PMAPPER_MAPPING_PCP = 0,
+	MXL862XX_PMAPPER_MAPPING_LAG,
+	MXL862XX_PMAPPER_MAPPING_DSCP,
+};
+
+/**
+ * struct mxl862xx_monitor_port_cfg - Port monitor configuration
+ * @port_id: port number
+ * @sub_if_id: monitoring sub-interface id
+ * @monitor_port: reserved
+ */
+struct mxl862xx_monitor_port_cfg {;
+	u8 port_id;
+	__le16 sub_if_id;
+	u8 monitor_port;
+} __packed;
+
+/**
+ * enum mxl862xx_ctp_port_config_mask - CTP Port configuration mask.
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_BRIDGE_PORT_ID: Mask for bridge_port_id
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_FORCE_TRAFFIC_CLASS: Mask for forced_traffic_class and default_traffic_class
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN: Mask for ingress_extended_vlan_enable and ingress_extended_vlan_block_id
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN_IGMP: Mask for ingress_extended_vlan_igmp_enable and ingress_extended_vlan_block_id_igmp
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN: Mask for egress_extended_vlan_enable and egress_extended_vlan_block_id
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN_IGMP: Mask for egress_extended_vlan_igmp_enable and egress_extended_vlan_block_id_igmp
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_INRESS_NTO1_VLAN: Mask for ingress_nto1Vlan_enable
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_NTO1_VLAN: Mask for egress_nto1Vlan_enable
+ * @MXL862XX_CTP_PORT_CONFIG_INGRESS_MARKING: Mask for ingress_marking_mode
+ * @MXL862XX_CTP_PORT_CONFIG_EGRESS_MARKING: Mask for egress_marking_mode
+ * @MXL862XX_CTP_PORT_CONFIG_EGRESS_MARKING_OVERRIDE: Mask for egress_marking_override_enable and egress_marking_mode_override
+ * @MXL862XX_CTP_PORT_CONFIG_EGRESS_REMARKING: Mask for egress_remarking_mode
+ * @MXL862XX_CTP_PORT_CONFIG_INGRESS_METER: Mask for ingress_metering_enable and ingress_traffic_meter_id
+ * @MXL862XX_CTP_PORT_CONFIG_EGRESS_METER: Mask for egress_metering_enable and egress_traffic_meter_id
+ * @MXL862XX_CTP_PORT_CONFIG_BRIDGING_BYPASS: Mask for bridging_bypass
+ * @MXL862XX_CTP_PORT_CONFIG_FLOW_ENTRY: Mask for first_flow_entry_index and number_of_flow_entries
+ * @MXL862XX_CTP_PORT_CONFIG_LOOPBACK_AND_MIRROR: Mask for ingress_loopback_enable
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_ALL: Enable all fields
+ * @MXL862XX_CTP_PORT_CONFIG_MASK_FORCE: Bypass any check for debug purpose
+ */
+enum mxl862xx_ctp_port_config_mask {
+	MXL862XX_CTP_PORT_CONFIG_MASK_BRIDGE_PORT_ID = BIT(0),
+	MXL862XX_CTP_PORT_CONFIG_MASK_FORCE_TRAFFIC_CLASS = BIT(1),
+	MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN = BIT(2),
+	MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN_IGMP = BIT(3),
+	MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN = BIT(4),
+	MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN_IGMP = BIT(5),
+	MXL862XX_CTP_PORT_CONFIG_MASK_INRESS_NTO1_VLAN = BIT(6),
+	MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_NTO1_VLAN = BIT(7),
+	MXL862XX_CTP_PORT_CONFIG_INGRESS_MARKING = BIT(8),
+	MXL862XX_CTP_PORT_CONFIG_EGRESS_MARKING = BIT(9),
+	MXL862XX_CTP_PORT_CONFIG_EGRESS_MARKING_OVERRIDE = BIT(10),
+	MXL862XX_CTP_PORT_CONFIG_EGRESS_REMARKING = BIT(11),
+	MXL862XX_CTP_PORT_CONFIG_INGRESS_METER = BIT(12),
+	MXL862XX_CTP_PORT_CONFIG_EGRESS_METER = BIT(13),
+	MXL862XX_CTP_PORT_CONFIG_BRIDGING_BYPASS = BIT(14),
+	MXL862XX_CTP_PORT_CONFIG_LOOPBACK_AND_MIRROR = BIT(16),
+	MXL862XX_CTP_PORT_CONFIG_MASK_ALL = 0x7FFFFFFF,
+	MXL862XX_CTP_PORT_CONFIG_MASK_FORCE = 0x8000000,
+};
+
+/** enum mxl862xx_color_marking_mode - Color Marking Mode
+ * @MXL862XX_MARKING_ALL_GREEN: mark packets (except critical) to green
+ * @MXL862XX_MARKING_INTERNAL_MARKING: do not change color and priority
+ * @MXL862XX_MARKING_DEI: DEI mark mode
+ * @MXL862XX_MARKING_PCP_8P0D: PCP 8P0D mark mode
+ * @MXL862XX_MARKING_PCP_7P1D: PCP 7P1D mark mode
+ * @MXL862XX_MARKING_PCP_6P2D: PCP 6P2D mark mode
+ * @MXL862XX_MARKING_PCP_5P3D: PCP 5P3D mark mode
+ * @MXL862XX_MARKING_DSCP_AF: DSCP AF class
+ */
+enum mxl862xx_color_marking_mode {
+	MXL862XX_MARKING_ALL_GREEN = 0,
+	MXL862XX_MARKING_INTERNAL_MARKING,
+	MXL862XX_MARKING_DEI,
+	MXL862XX_MARKING_PCP_8P0D,
+	MXL862XX_MARKING_PCP_7P1D,
+	MXL862XX_MARKING_PCP_6P2D,
+	MXL862XX_MARKING_PCP_5P3D,
+	MXL862XX_MARKING_DSCP_AF,
+};
+
+/**
+ * enum mxl862xx_color_remarking_mode - \brief Color Remarking Mode
+ * @MXL862XX_REMARKING_NONE: values from last process stage
+ * @MXL862XX_REMARKING_DEI: DEI mark mode
+ * @MXL862XX_REMARKING_PCP_8P0D: PCP 8P0D mark mode
+ * @MXL862XX_REMARKING_PCP_7P1D: PCP 7P1D mark mode
+ * @MXL862XX_REMARKING_PCP_6P2D: PCP 6P2D mark mode
+ * @MXL862XX_REMARKING_PCP_5P3D: PCP 5P3D mark mode
+ * @MXL862XX_REMARKING_DSCP_AF: DSCP AF class
+ */
+enum mxl862xx_color_remarking_mode {
+	MXL862XX_REMARKING_NONE = 0,
+	MXL862XX_REMARKING_DEI = 2,
+	MXL862XX_REMARKING_PCP_8P0D,
+	MXL862XX_REMARKING_PCP_7P1D,
+	MXL862XX_REMARKING_PCP_6P2D,
+	MXL862XX_REMARKING_PCP_5P3D,
+	MXL862XX_REMARKING_DSCP_AF,
+};
+
+/**
+ * struct mxl862xx_pmapper - P-mapper Configuration
+ * @pmapper_id: Index of P-mapper <0-31>
+ * @dest_sub_if_id_group: Sub interface ID group
+ */
+struct mxl862xx_pmapper {
+	__le16 pmapper_id;
+	u8 dest_sub_if_id_group[73];
+} __packed;
+
+/**
+ * struct mxl862xx_ctp_port_config -  CTP Port Configuration
+ * @logical_port_id: the ID of the port
+ * @n_sub_if_id_group: sub interface ID group. The valid range is hardware/protocol dependent
+ * @mask: See &enum mxl862xx_ctp_port_config_mask
+ * @bridge_port_id: bridge port ID association to ingress CTP
+ * @forced_traffic_class: default traffic class can not be overridden by other rules
+ * @default_traffic_class: default traffic class associated with all ingress traffic
+ * @ingress_extended_vlan_enable: Enable Extended VLAN processing for ingress non-IGMP traffic.
+ * @ingress_extended_vlan_block_id: Extended VLAN block allocated for ingress non-IGMP traffic
+ * @ingress_extended_vlan_block_size: Extended VLAN block size for ingress non-IGMP traffic
+ * @ingress_extended_vlan_igmp_enable: Enable extended VLAN processing for ingress IGMP traffic
+ * @ingress_extended_vlan_block_id_igmp: Extended VLAN block allocated for ingress IGMP traffic
+ * @ingress_extended_vlan_block_size_igmp: Extended VLAN block size for ingress IGMP traffic
+ * @egress_extended_vlan_enable: Enable extended VLAN processing for egress non-IGMP traffic
+ * @egress_extended_vlan_block_id: Extended VLAN block allocated for egress non-IGMP traffic
+ * @egress_extended_vlan_block_size: Extended VLAN block size for egress non-IGMP traffic
+ * @egress_extended_vlan_igmp_enable: Enable extended VLAN processing for egress IGMP traffic
+ * @egress_extended_vlan_block_id_igmp: Extended VLAN block allocated for egress IGMP traffic
+ * @egress_extended_vlan_block_size_igmp: Extended VLAN block size for egress IGMP traffic
+ * @ingress_marking_mode: See &enum mxl862xx_color_marking_mode
+ * @egress_marking_mode: See &enum mxl862xx_color_marking_mode
+ * @egress_marking_override_enable: Egress color marking mode override
+ * @egress_marking_mode_override: See &enum mxl862xx_color_marking_mode
+ * @ingress_metering_enable: Traffic metering on ingress traffic applies
+ * @ingress_traffic_meter_id: Meter for ingress CTP process
+ * @egress_metering_enable: Traffic metering on egress traffic applies.
+ * @egress_traffic_meter_id: Meter ID for egress CTP process
+ * @bridging_bypass: Ingress traffic bypass bridging/multicast processing
+ * @dest_logical_port_id: logical destination port port when bridging_bypass is set
+ * @pmapper_enable: Enable port mappin
+ * @dest_sub_if_id_group: defines destination sub interface ID group
+ * pmapper_mapping_mode: See &enum mxl862xx_pmapper_mapping_mode
+ * @pmapper: See &enum mxl862xx_pmapper
+ * @first_flow_entry_index: First traffic flow table entry is associated to this CTP port
+ * @number_of_flow_entries: Number of traffic flow table entries that are associated to this CTP port
+ * @ingress_loopback_enable: Ingress traffic from this CTP port will be redirected to the logical port
+ * @ingress_da_sa_swap_enable: Destination/Source MAC address of ingress traffic is swapped before transmission
+ * @egress_loopback_enable: Egress traffic to this CTP port will be redirected to ingress logical port
+ * @egress_da_sa_swap_enable: Destination/Source MAC address of egress traffic is swapped before transmission
+ * @ingress_mirror_enable: Ingress traffic is mirrored to the monitoring port
+ * @egress_mirror_enable: Egress traffic is mirrored to the monitoring port
+ */
+struct mxl862xx_ctp_port_config
+{
+	u8 logical_port_id;
+	__le16 n_sub_if_id_group;
+	enum mxl862xx_ctp_port_config_mask mask;
+	__le16 bridge_port_id;
+	u8 forced_traffic_class;
+	u8 default_traffic_class;
+	u8 ingress_extended_vlan_enable;
+	__le16 ingress_extended_vlan_block_id;
+	__le16 ingress_extended_vlan_block_size;
+	u8 ingress_extended_vlan_igmp_enable;
+	__le16 ingress_extended_vlan_block_id_igmp;
+	__le16 ingress_extended_vlan_block_size_igmp;
+	u8 egress_extended_vlan_enable;
+	__le16 egress_extended_vlan_block_id;
+	__le16 egress_extended_vlan_block_size;
+	u8 egress_extended_vlan_igmp_enable;
+	__le16 egress_extended_vlan_block_id_igmp;
+	__le16 egress_extended_vlan_block_size_igmp;
+	u8 ingress_nto1vlan_enable;
+	u8 egress_nto1vlan_enable;
+	enum mxl862xx_color_marking_mode ingress_marking_mode;
+	enum mxl862xx_color_marking_mode egress_marking_mode;
+	u8 egress_marking_override_enable;
+	enum mxl862xx_color_marking_mode egress_marking_mode_override;
+	enum mxl862xx_color_remarking_mode egress_remarking_mode;
+	u8 ingress_metering_enable;
+	__le16 ingress_traffic_meter_id;
+	u8 egress_metering_enable;
+	__le16 egress_traffic_meter_id;
+	u8 bridging_bypass;
+	u8 dest_logical_port_id;
+	u8 pmapper_enable;
+	__le16 dest_sub_if_id_group;
+	enum mxl862xx_pmapper_mapping_mode pmapper_mapping_mode;
+	u8 pmapper_id_valid;
+	struct mxl862xx_pmapper pmapper;
+	__le16 first_flow_entry_index;
+	__le16 number_of_flow_entries;
+	u8 ingress_loopback_enable;
+	u8 ingress_da_sa_swap_enable;
+	u8 egress_loopback_enable;
+	u8 egress_da_sa_swap_enable;
+	u8 ingress_mirror_enable;
+	u8 egress_mirror_enable;
+} __packed;
+
+/**
+ * enum mxl862xx_age_timer - Aging Timer Value.
+ * @MXL862XX_AGETIMER_1_SEC: 1 second aging time
+ * @MXL862XX_AGETIMER_10_SEC: 10 seconds aging time
+ * @MXL862XX_AGETIMER_300_SEC: 300 seconds aging time
+ * @MXL862XX_AGETIMER_1_HOUR: 1 hour aging time
+ * @MXL862XX_AGETIMER_1_DAY: 24 hours aging time
+ * @MXL862XX_AGETIMER_CUSTOM: Custom aging time in seconds
+ */
+enum mxl862xx_age_timer {
+	MXL862XX_AGETIMER_1_SEC = 1,
+	MXL862XX_AGETIMER_10_SEC,
+	MXL862XX_AGETIMER_300_SEC,
+	MXL862XX_AGETIMER_1_HOUR,
+	MXL862XX_AGETIMER_1_DAY,
+	MXL862XX_AGETIMER_CUSTOM,
+};
+
+/**
+ * struct mxl862xx_cfg -  Global Switch configuration Attributes
+ * @mac_table_age_timer: See &enum mxl862xx_age_timer
+ * @age_timer: Custom MAC table aging timer in seconds
+ * @max_packet_len: Maximum Ethernet packet length.
+ * @learning_limit_action: Automatic MAC address table learning limitation consecutive action
+ * @mac_locking_action: Accept or discard MAC port locking violation packets
+ * @mac_spoofing_action: Accept or discard MAC spoofing and port MAC locking violation packets
+ * @pause_mac_mode_src: Pause frame MAC source address mode
+ * @pause_mac_src: Pause frame MAC source address
+ */
+struct mxl862xx_cfg {
+	enum mxl862xx_age_timer mac_table_age_timer;
+	__le32 age_timer;
+	__le16 max_packet_len;
+	u8 learning_limit_action;
+	u8 mac_locking_action;
+	u8 mac_spoofing_action;
+	u8 pause_mac_mode_src;
+	u8 pause_mac_src[ETH_ALEN];
+} __packed;
+
+/**
+ * struct mxl862xx_ss_sp_tag
+ * @pid: port ID (1~16)
+ * @mask: bit value 1 to indicate valid field
+ *	0 - rx
+ *	1 - tx
+ *	2 - rx_pen
+ *	3 - tx_pen
+ * @rx: RX special tag mode
+ *	0 - packet does NOT have special tag and special tag is NOT inserted
+ *	1 - packet does NOT have special tag and special tag is inserted
+ *	2 - packet has special tag and special tag is NOT inserted
+ * @tx: TX special tag mode
+ *	0 - packet does NOT have special tag and special tag is NOT removed
+ *	1 - packet has special tag and special tag is replaced
+ *	2 - packet has special tag and special tag is NOT removed
+ *	3 - packet has special tag and special tag is removed
+ * @rx_pen: RX special tag info over preamble
+ *	0 - special tag info inserted from byte 2 to 7 are all 0
+ *	1 - special tag byte 5 is 16, other bytes from 2 to 7 are 0
+ *	2 - special tag byte 5 is from preamble field, others are 0
+ *	3 - special tag byte 2 to 7 are from preabmle field
+ * @tx_pen: TX special tag info over preamble
+ *	0 - disabled
+ *	1 - enabled
+*/
+struct mxl862xx_ss_sp_tag {
+	u8 pid;
+	u8 mask;
+	u8 rx;
+	u8 tx;
+	u8 rx_pen;
+	u8 tx_pen;
+} __packed;
+
+/**
+ * enum mxl862xx_logical_port_mode - Logical port mode
+ * @MXL862XX_LOGICAL_PORT_8BIT_WLAN: WLAN with 8-bit station ID
+ * @MXL862XX_LOGICAL_PORT_9BIT_WLAN: WLAN with 9-bit station ID
+ * @MXL862XX_LOGICAL_PORT_GPON: GPON OMCI context
+ * @MXL862XX_LOGICAL_PORT_EPON: EPON context
+ * @MXL862XX_LOGICAL_PORT_GINT: G.INT context
+ * @MXL862XX_LOGICAL_PORT_OTHER: Others
+ */
+enum mxl862xx_logical_port_mode {
+	MXL862XX_LOGICAL_PORT_8BIT_WLAN = 0,
+	MXL862XX_LOGICAL_PORT_9BIT_WLAN,
+	MXL862XX_LOGICAL_PORT_GPON,
+	MXL862XX_LOGICAL_PORT_EPON,
+	MXL862XX_LOGICAL_PORT_GINT,
+	MXL862XX_LOGICAL_PORT_OTHER = 0xFF,
+};
+
+/**
+ * struct mxl862xx_ctp_port_assignment - CTP Port Assignment/association with logical port
+ * @logical_port_id: Logical Port Id. The valid range is hardware dependent
+ * @first_ctp_port_id: First CTP Port ID mapped to above logical port ID
+ * @number_of_ctp_port: Total number of CTP Ports mapped above logical port ID
+ * @mode: See &enum mxl862xx_logical_port_mode
+ * @bridge_port_id: Bridge ID (FID)
+ */
+struct mxl862xx_ctp_port_assignment {
+	u8 logical_port_id;
+	__le16 first_ctp_port_id;
+	__le16 number_of_ctp_port;
+	enum mxl862xx_logical_port_mode mode;
+	__le16 bridge_port_id;
+} __packed;
+
+/**
+ * struct mxl862xx_mac_table_add - MAC Table Entry to be added
+ * @fid: Filtering Identifier (FID) (not supported by all switches)
+ * @port_id: Ethernet Port number
+ * @port_map: Bridge Port Map
+ * @sub_if_id: Sub-Interface Identifier Destination
+ * @age_timer: Aging Time in seconds
+ * @vlan_id: STAG VLAN Id
+ * @static_entry: Static Entry (value will be aged out if the entry is not set to static)
+ * @traffic_class: Egress queue traffic class
+ * @mac: MAC Address to add to the table
+ * @filter_flag: Source/Destination MAC address filtering flag
+ *	0 - not filter
+ *	1 - source address filter
+ *	2 - destination address filter
+ *	3 - both source and destination filter
+ * @igmp_controlled: Packet is marked as IGMP controlled if destination MAC address matche MAC in this entry
+ * @associated_mac: Associated Mac address
+ * @tci: TCI for B-Step
+ *	Bit [0:11] - VLAN ID
+ *	Bit [12] - VLAN CFI/DEI
+ *	Bit [13:15] - VLAN PRI
+ */
+struct mxl862xx_mac_table_add {
+	__le16 fid;
+	__le32 port_id;
+	__le16 port_map[8];
+	__le16 sub_if_id;
+	int age_timer;
+	__le16 vlan_id;
+	u8 static_entry;
+	u8 traffic_class;
+	u8 mac[ETH_ALEN];
+	u8 filter_flag;
+	u8 igmp_controlled;
+	u8 associated_mac[ETH_ALEN];
+	__le16 tci;
+} __packed;
+
+/**
+ * struct mxl862xx_mac_table_remove - MAC Table Entry to be removed
+ * @fid: Filtering Identifier (FID)
+ * @mac: MAC Address to be removed from the table.
+ * @filter_flag: Source/Destination MAC address filtering
+ *	0 - not filter
+ *	1 - source address filter
+ *	2 - destination address filter
+ *	3 - both source and destination filter
+ * @tci: TCI for B-Step
+ *	Bit [0:11] - VLAN ID
+ *	Bit [12] - VLAN CFI/DEI
+ *	Bit [13:15] - VLAN PRI
+ */
+struct mxl862xx_mac_table_remove {
+	__le16 fid;
+	u8 mac[ETH_ALEN];
+	u8 filter_flag;
+	__le16 tci;
+} __packed;
+
+/**
+ * struct mxl862xx_mac_table_read - MAC Table Entry to be read
+ * @initial: Restart the get operation from the beginning of the table
+ * @last: Indicates that the read operation returned last entry
+ * @fid: Get the MAC table entry belonging to the given Filtering Identifier
+ * @port_id: The Bridge Port ID
+ * @port_map: Bridge Port Map
+ * @age_timer: Aging Time
+ * @vlan_id: STAG VLAN Id
+ * @static_entry: Indicates if this is a Static Entry
+ * @sub_if_id: Sub-Interface Identifier Destination
+ * @mac: MAC Address. Filled out by the switch API implementation.
+ * @filter_flag: Source/Destination MAC address filtering
+ *	0 - not filter
+ *	1 - source address filter
+ *	2 - destination address filter
+ *	3 - both source and destination filter
+ * @igmp_controlled: Packet is marked as IGMP controlled if destination MAC address matches the MAC in this entry
+ * @entry_changed: Indicate if the Entry has Changed
+ * @associated_mac: Associated MAC address
+ * @hit_status: MAC Table Hit Status Update
+ * @tci: TCI for  B-Step
+ *	Bit [0:11] - VLAN ID
+ *	Bit [12] - VLAN CFI/DEI
+ *	Bit [13:15] - VLAN PRI
+ */
+struct mxl862xx_mac_table_read {
+	u8 initial;
+	u8 last;
+	__le16 fid;
+	__le32 port_id;
+	__le16 port_map[8];
+	int age_timer;
+	__le16 vlan_id;
+	u8 static_entry;
+	__le16 sub_if_id;
+	u8 mac[ETH_ALEN];
+	u8 filter_flag;
+	u8 igmp_controlled;
+	u8 entry_changed;
+	u8 associated_mac[ETH_ALEN];
+	u8 hit_status;
+	__le16 tci;
+	__le16 first_bridge_port_id;
+} __packed;
+
+/**
+ * enum mxl862xx_stp_port_state
+ * @MXL862XX_STP_PORT_STATE_FORWARD: Forwarding state
+ * @MXL862XX_STP_PORT_STATE_DISABLE: Disabled/Discarding state
+ * @MXL862XX_STP_PORT_STATE_LEARNING: Learning state
+ * @MXL862XX_STP_PORT_STATE_BLOCKING: Blocking/Listening
+ */
+enum mxl862xx_stp_port_state {
+	MXL862XX_STP_PORT_STATE_FORWARD = 0,
+	MXL862XX_STP_PORT_STATE_DISABLE,
+	MXL862XX_STP_PORT_STATE_LEARNING,
+	MXL862XX_STP_PORT_STATE_BLOCKING,
+};
+
+/**
+ * struct mxl862xx_stp_port_cfg - Configures the Spanning Tree Protocol state of an Ethernet port
+ * @port_id: Port number
+ * @fid: Filtering Identifier (FID)
+ * @port_state: See &enum mxl862xx_stp_port_state
+ */
+struct mxl862xx_stp_port_cfg {
+	__le16 port_id;
+	__le16 fid;
+	enum mxl862xx_stp_port_state port_state;
+} __packed;
+
+/**
+ * struct mxl862xx_bridge_port_alloc - Bridge Port Allocation.
+ * @bridge_port_id: If the bridge port allocation is successful, a valid ID will be
+ *		  returned in this field. Otherwise, INVALID_HANDLE is returned.
+ *		  For bridge port free, this field should contain a valid ID
+ *		  returned by the bridge port allocation. ID 0 is special for
+ *		  the CPU port in PRX300, mapping to CTP 0 (Logical Port 0 with
+ *		  Sub-interface ID 0), and is pre-allocated during initialization.
+ *
+ * Used by MXL862XX_BRIDGE_PORT_ALLOC and MXL862XX_BRIDGE_PORT_FREE.
+ */
+struct mxl862xx_bridge_port_alloc {
+	__le16 bridge_port_id;
+};
+
+/**
+ * enum mxl862xx_port_duplex - Ethernet port duplex status
+ * @MXL862XX_DUPLEX_FULL: Port operates in full-duplex mode
+ * @MXL862XX_DUPLEX_HALF: Port operates in half-duplex mode
+ * @MXL862XX_DUPLEX_AUTO: Port operates in Auto mode
+ */
+enum mxl862xx_port_duplex {
+	MXL862XX_DUPLEX_FULL = 0,
+	MXL862XX_DUPLEX_HALF,
+	MXL862XX_DUPLEX_AUTO,
+};
+
+/**
+ * enum mxl862xx_port_speed -  Ethernet port speed mode
+ * @MXL862XX_PORT_SPEED_10: 10 Mbit/s
+ * @MXL862XX_PORT_SPEED_100: 100 Mbit/s
+ * @MXL862XX_PORT_SPEED_200: 200 Mbit/s
+ * @MXL862XX_PORT_SPEED_1000: 1000 Mbit/s
+ * @MXL862XX_PORT_SPEED_2500: 2.5 Gbit/s
+ * @MXL862XX_PORT_SPEED_5000: 5 Gbit/s
+ * @MXL862XX_PORT_SPEED_10000: 10 Gbit/s
+ * @MXL862XX_PORT_SPEED_AUTO: Auto speed for XGMAC
+ */
+enum mxl862xx_port_speed {
+	MXL862XX_PORT_SPEED_10 = 0,
+	MXL862XX_PORT_SPEED_100,
+	MXL862XX_PORT_SPEED_200,
+	MXL862XX_PORT_SPEED_1000,
+	MXL862XX_PORT_SPEED_2500,
+	MXL862XX_PORT_SPEED_5000,
+	MXL862XX_PORT_SPEED_10000,
+	MXL862XX_PORT_SPEED_AUTO,
+};
+
+/**
+ * enum mxl862xx_port_link - Force the MAC and PHY link modus
+ * @MXL862XX_PORT_LINK_UP: Link up
+ * @MXL862XX_PORT_LINK_DOWN: Link down
+ * @MXL862XX_PORT_LINK_AUTO: Link Auto
+ */
+enum mxl862xx_port_link {
+	MXL862XX_PORT_LINK_UP = 0,
+	MXL862XX_PORT_LINK_DOWN,
+	MXL862XX_PORT_LINK_AUTO,
+};
+
+/**
+ * enum mxl862xx_mii_mode - Ethernet port interface mode
+ * @MXL862XX_PORT_HW_MII: Normal PHY interface
+ * @MXL862XX_PORT_HW_RMII: Reduced MII interface in normal mode
+ * @MXL862XX_PORT_HW_GMII: GMII or MII, depending upon the speed
+ * @MXL862XX_PORT_HW_RGMII: RGMII mode
+ * @MXL862XX_PORT_HW_XGMII: XGMII mode
+ */
+enum mxl862xx_mii_mode {
+	MXL862XX_PORT_HW_MII = 0,
+	MXL862XX_PORT_HW_RMII,
+	MXL862XX_PORT_HW_GMII,
+	MXL862XX_PORT_HW_RGMII,
+	MXL862XX_PORT_HW_XGMII,
+};
+
+/**
+ * enum mxl862xx_mii_type - Ethernet port configuration for PHY or MAC mode
+ * @MXL862XX_PORT_MAC: The Ethernet port is configured to work in MAC mode
+ * @MXL862XX_PORT_PHY: The Ethernet port is configured to work in PHY mode
+ */
+enum mxl862xx_mii_type {
+	MXL862XX_PORT_MAC = 0,
+	MXL862XX_PORT_PHY,
+};
+
+/**
+ * enum mxl862xx_clk_mode - Ethernet port clock source configuration
+ * @MXL862XX_PORT_CLK_NA: Clock Mode not applicable
+ * @MXL862XX_PORT_CLK_MASTER: Clock Master Mode. The port is configured to provide the clock as output signal
+ * @MXL862XX_PORT_CLK_SLAVE: Clock Slave Mode. The port is configured to use the input clock signal
+ */
+enum mxl862xx_clk_mode {
+	MXL862XX_PORT_CLK_NA = 0,
+	MXL862XX_PORT_CLK_MASTER,
+	MXL862XX_PORT_CLK_SLAVE,
+};
+
+/**
+ * struct mxl862xx_port_link_cfg - Ethernet port link, speed status and flow control status
+ * @port_id: Ethernet Port number
+ * @duplex_force: Force Port Duplex Mode
+ * @duplex: See &enum mxl862xx_port_duplex
+ * @speed_force: Force Link Speed
+ * @speed: See &enum mxl862xx_port_speed
+ * @link_force: Force Link
+ * @link: See &enum mxl862xx_port_link
+ * @mii_mode: See &enum mxl862xx_mii_mode
+ * @mii_type: See &enum mxl862xx_mii_type
+ * @clk_mode: See &enum mxl862xx_clk_mode
+ * @lpi: 'Low Power Idle' Support for 'Energy Efficient Ethernet'
+ */
+struct mxl862xx_port_link_cfg {
+	__le16 port_id;
+	u8 duplex_force;
+	enum mxl862xx_port_duplex duplex;
+	u8 speed_force;
+	enum mxl862xx_port_speed speed;
+	u8 link_force;
+	enum mxl862xx_port_link link;
+	enum mxl862xx_mii_mode mii_mode;
+	enum mxl862xx_mii_type mii_type;
+	enum mxl862xx_clk_mode clk_mode;
+	u8 lpi;
+} __packed;
+
+/**
+ * enum mxl862xx_port_type - Port Type
+ * @MXL862XX_LOGICAL_PORT: Logical Port
+ * @MXL862XX_PHYSICAL_PORT: Physical Port
+ * @MXL862XX_CTP_PORT: Connectivity Termination Port (CTP)
+ * @MXL862XX_BRIDGE_PORT: Bridge Port
+ */
+enum mxl862xx_port_type {
+	MXL862XX_LOGICAL_PORT = 0,
+	MXL862XX_PHYSICAL_PORT,
+	MXL862XX_CTP_PORT,
+	MXL862XX_BRIDGE_PORT,
+};
+
+/**
+ * enum mxl862xx_port_enable - port enable type selection.
+ * @MXL862XX_PORT_DISABLE: the port is disabled in both directions
+ * @MXL862XX_PORT_ENABLE_RXTX: the port is enabled in both directions
+ * @MXL862XX_PORT_ENABLE_RX: the port is enabled in the receive direction
+ * @MXL862XX_PORT_ENABLE_TX: the port is enabled in the transmit direction
+ */
+enum mxl862xx_port_enable{
+	MXL862XX_PORT_DISABLE = 0,
+	MXL862XX_PORT_ENABLE_RXTX,
+	MXL862XX_PORT_ENABLE_RX,
+	MXL862XX_PORT_ENABLE_TX,
+};
+
+/**
+ * enum mxl862xx_port_flow - ethernet flow control status
+ * @MXL862XX_FLOW_AUTO: automatic flow control
+ * @MXL862XX_FLOW_RX: receive flow control only
+ * @MXL862XX_FLOW_TX: transmit flow control only
+ * @MXL862XX_FLOW_RXTX: receive and transmit flow control
+ * @MXL862XX_FLOW_OFF: no flow control
+ */
+enum mxl862xx_port_flow {
+	MXL862XX_FLOW_AUTO = 0,
+	MXL862XX_FLOW_RX,
+	MXL862XX_FLOW_TX,
+	MXL862XX_FLOW_RXTX,
+	MXL862XX_FLOW_OFF,
+};
+
+/**
+ * enum mxl862xx_port_monitor - port mirror options
+ * @MXL862XX_PORT_MONITOR_NONE: mirroring is disabled
+ * @MXL862XX_PORT_MONITOR_RX: ingress packets are mirrored
+ * @MXL862XX_PORT_MONITOR_TX: egress packets are mirrored
+ * @MXL862XX_PORT_MONITOR_RXTX: ingress and egress packets are mirrored
+ * @MXL862XX_PORT_MONITOR_VLAN_UNKNOWN: mirroring of 'unknown VLAN violation' frames
+ * @MXL862XX_PORT_MONITOR_VLAN_MEMBERSHIP: mirroring of 'VLAN ingress or egress membership
+	violation' frames
+ * @MXL862XX_PORT_MONITOR_PORT_STATE: mirroring of 'port state violation' frames
+ * @MXL862XX_PORT_MONITOR_LEARNING_LIMIT: mirroring of 'MAC learning limit violation' frames
+ * @MXL862XX_PORT_MONITOR_PORT_LOCK: mirroring of 'port lock violation' frames
+ */
+enum mxl862xx_port_monitor {
+	MXL862XX_PORT_MONITOR_NONE = 0,
+	MXL862XX_PORT_MONITOR_RX,
+	MXL862XX_PORT_MONITOR_TX,
+	MXL862XX_PORT_MONITOR_RXTX,
+	MXL862XX_PORT_MONITOR_VLAN_UNKNOWN,
+	MXL862XX_PORT_MONITOR_VLAN_MEMBERSHIP = 16,
+	MXL862XX_PORT_MONITOR_PORT_STATE = 32,
+	MXL862XX_PORT_MONITOR_LEARNING_LIMIT = 64,
+	MXL862XX_PORT_MONITOR_PORT_LOCK = 128,
+};
+
+/**
+ * enum mxl862xx_if_rmon_mode - interface RMON counter mode
+ * @MXL862XX_IF_RMON_FID: FID based RMON counters
+ * @MXL862XX_IF_RMON_SUBID: sub-interface ID based
+ * @MXL862XX_IF_RMON_FLOWID_LSB: flow ID based (bits 3:0)
+ * @MXL862XX_IF_RMON_FLOWID_MSB: flow ID based (bits 7:4)
+ */
+enum mxl862xx_if_rmon_mode {
+	MXL862XX_IF_RMON_FID = 0,
+	MXL862XX_IF_RMON_SUBID,
+	MXL862XX_IF_RMON_FLOWID_LSB,
+	MXL862XX_IF_RMON_FLOWID_MSB,
+};
+
+/**
+ * struct mxl862xx_port_cfg - Port Configuration Parameters
+ * @port_type: See &enum mxl862xx_port_type
+ * @port_id: Ethernet Port number (zero-based counting)
+ * @enable: See &enum mxl862xx_port_enable
+ * @unicast_unknown_drop: Drop unknown unicast packets
+ * @multicast_unknown_drop: Drop unknown multicast packets
+ * @reserved_packet_drop: Drop reserved packet types
+ * @broadcast_drop: Drop broadcast packets
+ * @aging: Enables MAC address table aging.
+ * @learning: MAC address table learning
+ * @learning_mac_port_lock: Automatic MAC address table learning locking on the port
+ * @learning_limit: Automatic MAC address table learning limitation on this port
+ * @mac_spoofing_detection: MAC spoofing detection. Identifies ingress packets that carry
+ *      a MAC source address which was previously learned on a different ingress port
+ * @flow_ctrl: See &enum mxl862xx_port_flow
+ * @port_monitor: See &enum mxl862xx_port_monitor
+ * @if_counters: Assign Interface RMON Counters for this Port
+ * @if_count_start_idx: Interface RMON Counters Start Index
+ * @if_rmonmode: See &enum mxl862xx_if_rmon_mode
+ */
+struct mxl862xx_port_cfg {
+	enum mxl862xx_port_type port_type;
+	__le16 port_id;
+	enum mxl862xx_port_enable enable;
+	u8 unicast_unknown_drop;
+	u8 multicast_unknown_drop;
+	u8 reserved_packet_drop;
+	u8 broadcast_drop;
+	u8 aging;
+	u8 learning;
+	u8 learning_mac_port_lock;
+	__le16 learning_limit;
+	u8 mac_spoofing_detection;
+	enum mxl862xx_port_flow flow_ctrl;
+	enum mxl862xx_port_monitor port_monitor;
+	u8 if_counters;
+	int if_count_start_idx;
+	enum mxl862xx_if_rmon_mode if_rmonmode;
+} __packed;
+
+/**
+ * struct mxl862xx_bridge_alloc - Bridge Allocation
+ * @bridge_id: the ID assigned to the new bridge
+ */
+struct mxl862xx_bridge_alloc {
+	__le16 bridge_id;
+} __packed;
+
+/**
+ * enum mxl862xx_rmon_port_type - RMON counter table structure
+ */
+enum mxl862xx_rmon_port_type {
+	MXL862XX_RMON_CTP_PORT_RX = 0,
+	MXL862XX_RMON_CTP_PORT_TX,
+	MXL862XX_RMON_BRIDGE_PORT_RX,
+	MXL862XX_RMON_BRIDGE_PORT_TX,
+	MXL862XX_RMON_CTP_PORT_PCE_BYPASS,
+	MXL862XX_RMON_TFLOW_RX,
+	MXL862XX_RMON_TFLOW_TX,
+	MXL862XX_RMON_QMAP = 0x0E,
+	MXL862XX_RMON_METER = 0x19,
+	MXL862XX_RMON_PMAC = 0x1C,
+};
+
+/**
+ * struct mxl862xx_debug_rmon_port_cnt - Port Counters
+ * @port_id: Ethernet Port number
+ * @port_type: See &enum mxl862xx_rmon_port_type
+ * @rx_extended_vlan_discard_pkts: 
+ * @mtu_exceed_discard_pkts: 
+ * @tx_under_size_good_pkts: 
+ * @tx_oversize_good_pkts: 
+ * @rx_good_pkts: Receive Packet Count (only packets that are accepted and not discarded).
+ * @rx_unicast_pkts: Receive Unicast Packet Count.
+ * @rx_broadcast_pkts: Receive Broadcast Packet Count.
+ * @rx_multicast_pkts: Receive Multicast Packet Count.
+ * @rx_fcserror_pkts: Receive FCS Error Packet Count.
+ * @rx_under_size_good_pkts: Receive Undersize Good Packet Count.
+ * @rx_oversize_good_pkts: Receive Oversize Good Packet Count.
+ * @rx_under_size_error_pkts: Receive Undersize Error Packet Count.
+ * @rx_good_pause_pkts: Receive Good Pause Packet Count.
+ * @rx_oversize_error_pkts: Receive Oversize Error Packet Count.
+ * @rx_align_error_pkts: Receive Align Error Packet Count.
+ * @rx_filtered_pkts: Filtered Packet Count.
+ * @rx64byte_pkts: Receive Size 64 Bytes Packet Count.
+ * @rx127byte_pkts: Receive Size 65-127 Bytes Packet Count.
+ * @rx255byte_pkts: Receive Size 128-255 Bytes Packet Count.
+ * @rx511byte_pkts: Receive Size 256-511 Bytes Packet Count.
+ * @rx1023byte_pkts: Receive Size 512-1023 Bytes Packet Count.
+ * @rx_max_byte_pkts: Receive Size 1024-1522 Bytes (or more, if configured) Packet Count.
+ * @tx_good_pkts: Overall Transmit Good Packets Count.
+ * @tx_unicast_pkts: Transmit Unicast Packet Count.
+ * @tx_broadcast_pkts: Transmit Broadcast Packet Count.
+ * @tx_multicast_pkts: Transmit Multicast Packet Count.
+ * @tx_single_coll_count: Transmit Single Collision Count.
+ * @tx_mult_coll_count: Transmit Multiple Collision Count.
+ * @tx_late_coll_count: Transmit Late Collision Count.
+ * @tx_excess_coll_count: Transmit Excessive Collision Count.
+ * @tx_coll_count: Transmit Collision Count.
+ * @tx_pause_count: Transmit Pause Packet Count.
+ * @tx64byte_pkts: Transmit Size 64 Bytes Packet Count.
+ * @tx127byte_pkts: Transmit Size 65-127 Bytes Packet Count.
+ * @tx255byte_pkts: Transmit Size 128-255 Bytes Packet Count.
+ * @tx511byte_pkts: Transmit Size 256-511 Bytes Packet Count.
+ * @tx1023byte_pkts: Transmit Size 512-1023 Bytes Packet Count.
+ * @tx_max_byte_pkts: Transmit Size 1024-1522 Bytes (or more, if configured) Packet Count.
+ * @tx_dropped_pkts: Transmit Drop Packet Count.
+ * @tx_acm_dropped_pkts: Transmit Dropped Packet Count, based on Congestion Management.
+ * @rx_dropped_pkts: Receive Dropped Packet Count.
+ * @rx_good_bytes: Receive Good Byte Count (64 bit).
+ * @rx_bad_bytes: Receive Bad Byte Count (64 bit).
+ * @tx_good_bytes: Transmit Good Byte Count (64 bit).
+ * @rx_unicast_pkts_yellow_red: Receive Unicast Packet Count for Yellow & Red packet.
+ * @rx_broadcast_pkts_yellow_red: Receive Broadcast Packet Count for Yellow & Red packet.
+ * @rx_multicast_pkts_yellow_red: Receive Multicast Packet Count for Yellow & Red packet.
+ * @rx_good_bytes_yellow_red: Receive Good Byte Count (64 bit) for Yellow & Red packet.
+ * @rx_good_pkts_yellow_red: Receive Packet Count for Yellow & Red packet.
+ * @tx_unicast_pkts_yellow_red: Transmit Unicast Packet Count for Yellow & Red packet.
+ * @tx_broadcast_pkts_yellow_red: Transmit Broadcast Packet Count for Yellow & Red packet.
+ * @tx_multicast_pkts_yellow_red: Transmit Multicast Packet Count for Yellow & Red packet.
+ * @tx_good_bytes_yellow_red: Transmit Good Byte Count (64 bit) for Yellow & Red packet.
+ * @tx_good_pkts_yellow_red: Transmit Packet Count for Yellow & Red packet.
+ */
+struct mxl862xx_debug_rmon_port_cnt {
+	__le16 port_id;
+	enum mxl862xx_rmon_port_type port_type;
+	__le32 rx_extended_vlan_discard_pkts;
+	__le32 mtu_exceed_discard_pkts;
+	__le32 tx_under_size_good_pkts;
+	__le32 tx_oversize_good_pkts;
+	__le32 rx_good_pkts;
+	__le32 rx_unicast_pkts;
+	__le32 rx_broadcast_pkts;
+	__le32 rx_multicast_pkts;
+	__le32 rx_fcserror_pkts;
+	__le32 rx_under_size_good_pkts;
+	__le32 rx_oversize_good_pkts;
+	__le32 rx_under_size_error_pkts;
+	__le32 rx_good_pause_pkts;
+	__le32 rx_oversize_error_pkts;
+	__le32 rx_align_error_pkts;
+	__le32 rx_filtered_pkts;
+	__le32 rx64byte_pkts;
+	__le32 rx127byte_pkts;
+	__le32 rx255byte_pkts;
+	__le32 rx511byte_pkts;
+	__le32 rx1023byte_pkts;
+	__le32 rx_max_byte_pkts;
+	__le32 tx_good_pkts;
+	__le32 tx_unicast_pkts;
+	__le32 tx_broadcast_pkts;
+	__le32 tx_multicast_pkts;
+	__le32 tx_single_coll_count;
+	__le32 tx_mult_coll_count;
+	__le32 tx_late_coll_count;
+	__le32 tx_excess_coll_count;
+	__le32 tx_coll_count;
+	__le32 tx_pause_count;
+	__le32 tx64byte_pkts;
+	__le32 tx127byte_pkts;
+	__le32 tx255byte_pkts;
+	__le32 tx511byte_pkts;
+	__le32 tx1023byte_pkts;
+	__le32 tx_max_byte_pkts;
+	__le32 tx_dropped_pkts;
+	__le32 tx_acm_dropped_pkts;
+	__le32 rx_dropped_pkts;
+	__le64 rx_good_bytes;
+	__le64 rx_bad_bytes;
+	__le64 tx_good_bytes;
+	__le32 rx_unicast_pkts_yellow_red;
+	__le32 rx_broadcast_pkts_yellow_red;
+	__le32 rx_multicast_pkts_yellow_red;
+	__le64 rx_good_bytes_yellow_red;
+	__le32 rx_good_pkts_yellow_red;
+	__le32 tx_unicast_pkts_yellow_red;
+	__le32 tx_broadcast_pkts_yellow_red;
+	__le32 tx_multicast_pkts_yellow_red;
+	__le64 tx_good_bytes_yellow_red;
+	__le32 tx_good_pkts_yellow_red;
+} __packed;
+
+/**
+ * enum mxl862xx_bridge_port_config_mask - Bridge Port configuration mask
+ */
+enum mxl862xx_bridge_port_config_mask {
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_ID = BIT(0),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_INGRESS_VLAN = BIT(1),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_VLAN = BIT(2),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_INGRESS_MARKING = BIT(3),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_REMARKING = BIT(4),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_INGRESS_METER = BIT(5),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_SUB_METER = BIT(6),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_CTP_MAPPING = BIT(7),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_PORT_MAP = BIT(8),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_DEST_IP_LOOKUP = BIT(9),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_SRC_IP_LOOKUP = BIT(10),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_DEST_MAC_LOOKUP = BIT(11),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_SRC_MAC_LEARNING = BIT(12),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MAC_SPOOFING = BIT(13),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_PORT_LOCK = BIT(14),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MAC_LEARNING_LIMIT = BIT(15),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_MAC_LEARNED_COUNT = BIT(16),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_INGRESS_VLAN_FILTER = BIT(17),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_VLAN_FILTER1 = BIT(18),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_VLAN_FILTER2 = BIT(19),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_VLAN_BASED_MAC_LEARNING = BIT(20),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_VLAN_BASED_MULTICAST_LOOKUP = BIT(21),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_LOOP_VIOLATION_COUNTER = BIT(22),
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_ALL = 0x7FFFFFFF,
+	MXL862XX_BRIDGE_PORT_CONFIG_MASK_FORCE = BIT(31)
+};
+
+/**
+ * enum mxl862xx_bridge_port_egress_meter - Meters for various egress traffic type
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_BROADCAST: Index of broadcast traffic meter
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_MULTICAST: Index of known multicast traffic meter
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_UNKNOWN_MC_IP: Index of unknown multicast IP traffic meter
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_UNKNOWN_MC_NON_IP: Index of unknown multicast non-IP traffic meter
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_UNKNOWN_UC: Index of unknown unicast traffic meter
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_OTHERS: Index of traffic meter for other types
+ * @MXL862XX_BRIDGE_PORT_EGRESS_METER_MAX: Number of index
+ */
+enum mxl862xx_bridge_port_egress_meter {
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_BROADCAST = 0,
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_MULTICAST,
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_UNKNOWN_MC_IP,
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_UNKNOWN_MC_NON_IP,
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_UNKNOWN_UC,
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_OTHERS,
+	MXL862XX_BRIDGE_PORT_EGRESS_METER_MAX,
+};
+
+struct mxl862xx_bridge_port_config {
+	__le16 bridge_port_id;
+	enum mxl862xx_bridge_port_config_mask mask;
+	__le16 bridge_id;
+	u8 ingress_extended_vlan_enable;
+	__le16 ingress_extended_vlan_block_id;
+	__le16 ingress_extended_vlan_block_size;
+	u8 egress_extended_vlan_enable;
+	__le16 egress_extended_vlan_block_id;
+	__le16 egress_extended_vlan_block_size;
+	enum mxl862xx_color_marking_mode ingress_marking_mode;
+	enum mxl862xx_color_remarking_mode egress_remarking_mode;
+	u8 ingress_metering_enable;
+	__le16 ingress_traffic_meter_id;
+	u8 egress_sub_metering_enable[MXL862XX_BRIDGE_PORT_EGRESS_METER_MAX];
+	__le16 egress_traffic_sub_meter_id[MXL862XX_BRIDGE_PORT_EGRESS_METER_MAX];
+	u8 dest_logical_port_id;
+	u8 pmapper_enable;
+	__le16 dest_sub_if_id_group;
+	enum mxl862xx_pmapper_mapping_mode pmapper_mapping_mode;
+	u8 pmapper_id_valid;
+	struct mxl862xx_pmapper pmapper;
+	__le16 bridge_port_map[8];
+	u8 mc_dest_ip_lookup_disable;
+	u8 mc_src_ip_lookup_enable;
+	u8 dest_mac_lookup_disable;
+	u8 src_mac_learning_disable;
+	u8 mac_spoofing_detect_enable;
+	u8 port_lock_enable;
+	u8 mac_learning_limit_enable;
+	__le16 mac_learning_limit;
+	__le16 loop_violation_count;
+	__le16 mac_learning_count;
+	u8 ingress_vlan_filter_enable;
+	__le16 ingress_vlan_filter_block_id;
+	__le16 ingress_vlan_filter_block_size;
+	u8 bypass_egress_vlan_filter1;
+	u8 egress_vlan_filter1enable;
+	__le16 egress_vlan_filter1block_id;
+	__le16 egress_vlan_filter1block_size;
+	u8 egress_vlan_filter2enable;
+	__le16 egress_vlan_filter2block_id;
+	__le16 egress_vlan_filter2block_size;
+	u8 vlan_tag_selection;
+	u8 vlan_src_mac_priority_enable;
+	u8 vlan_src_mac_dei_enable;
+	u8 vlan_src_mac_vid_enable;
+	u8 vlan_dst_mac_priority_enable;
+	u8 vlan_dst_mac_dei_enable;
+	u8 vlan_dst_mac_vid_enable;
+	u8 vlan_multicast_priority_enable;
+	u8 vlan_multicast_dei_enable;
+	u8 vlan_multicast_vid_enable;
+} __packed;
+
+/**
+ * enum mxl862xx_bridge_config_mask - Bridge configuration mask
+ * @MXL862XX_BRIDGE_CONFIG_MASK_MAC_LEARNING_LIMIT: Mask for mac_learning_limit_enable and mac_learning_limit.
+ * @MXL862XX_BRIDGE_CONFIG_MASK_MAC_LEARNED_COUNT: Mask for mac_learning_count
+ * @MXL862XX_BRIDGE_CONFIG_MASK_MAC_DISCARD_COUNT: Mask for learning_discard_event
+ * @MXL862XX_BRIDGE_CONFIG_MASK_SUB_METER: Mask for sub_metering_enable and traffic_sub_meter_id
+ * @MXL862XX_BRIDGE_CONFIG_MASK_FORWARDING_MODE: Mask for forward_broadcast, forward_unknown_multicast_ip, forward_unknown_multicast_non_ip and forward_unknown_unicast.
+ * @MXL862XX_BRIDGE_CONFIG_MASK_ALL: Enable all
+ * @MXL862XX_BRIDGE_CONFIG_MASK_FORCE: Bypass any check for debug purpose
+ */
+enum mxl862xx_bridge_config_mask {
+	MXL862XX_BRIDGE_CONFIG_MASK_MAC_LEARNING_LIMIT = BIT(0),
+	MXL862XX_BRIDGE_CONFIG_MASK_MAC_LEARNED_COUNT = BIT(1),
+	MXL862XX_BRIDGE_CONFIG_MASK_MAC_DISCARD_COUNT = BIT(2),
+	MXL862XX_BRIDGE_CONFIG_MASK_SUB_METER = BIT(3),
+	MXL862XX_BRIDGE_CONFIG_MASK_FORWARDING_MODE = BIT(4),
+	MXL862XX_BRIDGE_CONFIG_MASK_ALL = 0x7FFFFFFF,
+	MXL862XX_BRIDGE_CONFIG_MASK_FORCE = BIT(31)
+};
+
+/**
+ * enum mxl862xx_bridge_forward_mode - Bridge forwarding type of packet
+ * @MXL862XX_BRIDGE_FORWARD_FLOOD: Packet is flooded to port members of ingress bridge port
+ * @MXL862XX_BRIDGE_FORWARD_DISCARD: Packet is dscarded
+ * @MXL862XX_BRIDGE_FORWARD_CPU: Packet is forwarded to logical port 0 CTP port 0 bridge port 0
+ */
+enum mxl862xx_bridge_forward_mode {
+	MXL862XX_BRIDGE_FORWARD_FLOOD = 0,
+	MXL862XX_BRIDGE_FORWARD_DISCARD,
+	MXL862XX_BRIDGE_FORWARD_CPU,
+};
+
+/**
+ * struct mxl862xx_bridge_config - Bridge Configuration
+ * @bridge_id: Bridge ID (FID)
+ * @mask: See &enum mxl862xx_bridge_config_mask
+ * @mac_learning_limit_enable: Enable MAC learning limitation.
+ * @mac_learning_limit: Max number of MAC can be learned in this bridge (all bridge ports).
+ * @mac_learning_count: Get number of MAC address learned from this bridge port
+ * @learning_discard_event: Number of learning discard event due to hardware resource not available
+ * @sub_metering_enable: Traffic metering on type of traffic
+ * @traffic_sub_meter_id: Meter for bridge process with specific type
+ * @forward_broadcast: See &enum mxl862xx_bridge_forward_mode
+ * @forward_unknown_multicast_ip: See &enum mxl862xx_bridge_forward_mode
+ * @forward_unknown_multicast_non_ip: See &enum mxl862xx_bridge_forward_mode
+ * @forward_unknown_unicast: See &enum mxl862xx_bridge_forward_mode
+ */
+struct mxl862xx_bridge_config {
+	__le16 bridge_id;
+	enum mxl862xx_bridge_config_mask mask;
+	u8 mac_learning_limit_enable;
+	__le16 mac_learning_limit;
+	__le16 mac_learning_count;
+	__le32 learning_discard_event;
+	u8 sub_metering_enable[MXL862XX_BRIDGE_PORT_EGRESS_METER_MAX];
+	__le16 traffic_sub_meter_id[MXL862XX_BRIDGE_PORT_EGRESS_METER_MAX];
+	enum mxl862xx_bridge_forward_mode forward_broadcast;
+	enum mxl862xx_bridge_forward_mode forward_unknown_multicast_ip;
+	enum mxl862xx_bridge_forward_mode forward_unknown_multicast_non_ip;
+	enum mxl862xx_bridge_forward_mode forward_unknown_unicast;
+} __packed;
+
+/**
+ * enum mxl862xx_vlan_filter_tci_mask - VLAN Filter TCI mask
+ * @MXL862XX_VLAN_FILTER_TCI_MASK_VID: TCI mask for VLAN ID
+ * @MXL862XX_VLAN_FILTER_TCI_MASK_PCP: TCI mask for VLAN PCP
+ * @MXL862XX_VLAN_FILTER_TCI_MASK_TCI: TCI mask for VLAN TCI
+ */
+enum mxl862xx_vlan_filter_tci_mask {
+	MXL862XX_VLAN_FILTER_TCI_MASK_VID = 0,
+	MXL862XX_VLAN_FILTER_TCI_MASK_PCP = 1,
+	MXL862XX_VLAN_FILTER_TCI_MASK_TCI = 2
+};
+
+/**
+ * enum mxl862xx_extended_vlan_4_tpid_mode - Extended VLAN 4 TPID mode
+ * @MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_1: Use global configured VTE type 1
+ * @MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_2: Use global configured VTE type 2
+ * @MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_3: Use global configured VTE type 3
+ * @MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_4: Use global configured VTE type 4
+ */
+enum mxl862xx_extended_vlan_4_tpid_mode {
+	MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_1 = 0,
+	MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_2 = 1,
+	MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_3 = 2,
+	MXL862XX_EXTENDEDVLAN_TPID_VTETYPE_4 = 3
+};
+
+/**
+ * enum mxl862xx_extended_vlan_filter_tpid - Extended VLAN filter TPID mode
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TPID_NO_FILTER: No filter
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TPID_8021Q: TPID is 0x8100
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TPID_VTETYPE: TPID is global configured value
+ */
+enum mxl862xx_extended_vlan_filter_tpid {
+	MXL862XX_EXTENDEDVLAN_FILTER_TPID_NO_FILTER = 0,
+	MXL862XX_EXTENDEDVLAN_FILTER_TPID_8021Q = 1,
+	MXL862XX_EXTENDEDVLAN_FILTER_TPID_VTETYPE = 2
+};
+
+/**
+ * enum mxl862xx_extended_vlan_treatment_tpid - Extended VLAN treatment TPID
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_TPID: Copy from inner VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_TPID: Copy from outer VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_VTETYPE: Use global configured value
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q: TPID is 0x8100
+ */
+enum mxl862xx_extended_vlan_treatment_tpid {
+	MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_TPID = 0,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_TPID = 1,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_VTETYPE = 2,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q = 3
+};
+
+/**
+ * enum mxl862xx_extended_vlan_filter_dei - Extended VLAN filter DEI
+ * @MXL862XX_EXTENDEDVLAN_FILTER_DEI_NO_FILTER: No filter
+ * @MXL862XX_EXTENDEDVLAN_FILTER_DEI_0: DEI must be 0
+ * @MXL862XX_EXTENDEDVLAN_FILTER_DEI_1: DEI must be 1
+ */
+enum mxl862xx_extended_vlan_filter_dei {
+	MXL862XX_EXTENDEDVLAN_FILTER_DEI_NO_FILTER = 0,
+	MXL862XX_EXTENDEDVLAN_FILTER_DEI_0 = 1,
+	MXL862XX_EXTENDEDVLAN_FILTER_DEI_1 = 2
+};
+
+/**
+ * enum mxl862xx_extended_vlan_treatment_dei - Extended VLAN treatment DEI
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_DEI: Copy from inner VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_DEI: Copy from outer VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0: Force DEI to 0
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_1: Force DEI to 1
+ */
+enum mxl862xx_extended_vlan_treatment_dei {
+	MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_DEI = 0,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_DEI = 1,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0 = 2,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_1 = 3
+};
+
+/**
+ * enum mxl862xx_extended_vlan_filter_type - Extended VLAN filter type
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL: Tagged packet with matching criteria
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER: Tagged packet with no criteria
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TYPE_DEFAULT: Default entry if no rule applies
+ * @MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG: No VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_BLOCK_INVALID: Invalid block
+ */
+enum mxl862xx_extended_vlan_filter_type {
+	MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL = 0,
+	MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER = 1,
+	MXL862XX_EXTENDEDVLAN_FILTER_TYPE_DEFAULT = 2,
+	MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG = 3,
+	MXL862XX_EXTENDEDVLAN_BLOCK_INVALID = 4
+};
+
+/**
+ * enum mxl862xx_extended_vlan_filter_ethertype - Extended VLAN filter ethertype
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_NO_FILTER: No filter
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_IPOE: IPoE frame (0x0800)
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_PPPOE: PPPoE frame (0x8863/0x8864)
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_ARP: ARP frame (0x0806)
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_IPV6IPOE: IPv6 IPoE (0x86DD)
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_EAPOL: EAPOL (0x888E)
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_DHCPV4: DHCPv4 (UDP port 67/68)
+ * @MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_DHCPV6: DHCPv6 (UDP port 546/547)
+ */
+enum mxl862xx_extended_vlan_filter_ethertype {
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_NO_FILTER = 0,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_IPOE = 1,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_PPPOE = 2,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_ARP = 3,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_IPV6IPOE = 4,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_EAPOL = 5,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_DHCPV4 = 6,
+	MXL862XX_EXTENDEDVLAN_FILTER_ETHERTYPE_DHCPV6 = 7
+};
+
+/**
+ * enum mxl862xx_extended_vlan_treatment_priority - Extended VLAN treatment priority
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL: Use a fixed priority
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_PRORITY: Copy priority from inner VLAN
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_PRORITY: Copy priority from outer VLAN
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_DSCP: Derive priority from DSCP
+ */
+enum mxl862xx_extended_vlan_treatment_priority {
+	MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL = 0,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_PRORITY = 1,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_PRORITY = 2,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_DSCP = 3
+};
+
+/**
+ * enum mxl862xx_extended_vlan_treatment_vid - Extended VLAN treatment VID
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL: Use a fixed VID
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_VID: Copy from inner VLAN
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_VID: Copy from outer VLAN
+ */
+enum mxl862xx_extended_vlan_treatment_vid {
+	MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL = 0,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_VID = 1,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_VID = 2,
+};
+
+/**
+ * enum mxl862xx_extended_vlan_treatment_remove_tag - Extended VLAN remove tag action
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG: Do not remove VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG: Remove one VLAN tag
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_2_TAG: Remove two VLAN tags
+ * @MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM: Discard upstream traffic
+ */
+enum mxl862xx_extended_vlan_treatment_remove_tag {
+	MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG = 0,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG = 1,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_2_TAG = 2,
+	MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM = 3,
+};
+
+/**
+ * struct mxl862xx_extendedvlan_filter_vlan - Extended VLAN filter VLAN tag
+ * @type: Filter type
+ * @priority_enable: Enable priority filtering
+ * @priority_val: Priority value to match
+ * @vid_enable: Enable VID filtering
+ * @vid_val: VID value to match
+ * @tpid: VLAN filter TPID
+ * @dei: VLAN filter DEI
+ */
+struct mxl862xx_extendedvlan_filter_vlan {
+	enum mxl862xx_extended_vlan_filter_type type;
+	bool priority_enable;
+	__le32 priority_val;
+	bool vid_enable;
+	__le32 vid_val;
+	enum mxl862xx_extended_vlan_filter_tpid tpid;
+	enum mxl862xx_extended_vlan_filter_dei dei;
+} __packed;
+
+/**
+ * struct mxl862xx_extendedvlan_treatment_vlan - Extended VLAN treatment VLAN tag
+ * @priority_mode: Source of VLAN tag priority
+ * @priority_val: Priority value if using a fixed priority
+ * @vid_mode: Source of VLAN tag VID
+ * @vid_val: VID if using a fixed VID
+ * @tpid: Source of TPID field
+ * @dei: Source of DEI field
+ */
+struct mxl862xx_extendedvlan_treatment_vlan {
+	enum mxl862xx_extended_vlan_treatment_priority priority_mode;
+	__le32 priority_val;
+	enum mxl862xx_extended_vlan_treatment_vid vid_mode;
+	__le32 vid_val;
+	enum mxl862xx_extended_vlan_treatment_tpid tpid;
+	enum mxl862xx_extended_vlan_treatment_dei dei;
+} __packed;
+
+/**
+ * struct mxl862xx_extendedvlan_filter - Extended VLAN filter configuration
+ * @original_packet_filter_mode: True if filtering is on original packet
+ * @filter_4_tpid_mode: 4 TPID mode
+ * @outer_vlan: Filter for outer VLAN
+ * @inner_vlan: Filter for inner VLAN
+ * @ether_type: Filter by ethertype
+ */
+struct mxl862xx_extendedvlan_filter {
+	bool original_packet_filter_mode;
+	enum mxl862xx_extended_vlan_4_tpid_mode filter_4_tpid_mode;
+	struct mxl862xx_extendedvlan_filter_vlan outer_vlan;
+	struct mxl862xx_extendedvlan_filter_vlan inner_vlan;
+	enum mxl862xx_extended_vlan_filter_ethertype ether_type;
+} __packed;
+
+/**
+ * struct mxl862xx_extendedvlan_alloc - Extended VLAN allocation
+ * @number_of_entries: Number of entries requested
+ * @extended_vlan_block_id: Returned block ID
+ */
+struct mxl862xx_extendedvlan_alloc {
+	__le16 number_of_entries;
+	__le16 extended_vlan_block_id;
+} __packed;
+
+/**
+ * struct mxl862xx_extendedvlan_treatment - Extended VLAN treatment
+ * @remove_tag: Tag removal method
+ * @treatment_4_tpid_mode: 4 TPID treatment mode
+ * @add_outer_vlan: If true, apply changes to outer VLAN
+ * @outer_vlan: Outer VLAN changes
+ * @add_inner_vlan: If true, apply changes to inner VLAN
+ * @inner_vlan: Inner VLAN changes
+ * @reassign_bridge_port: If true, reassign to a new bridge port
+ * @new_bridge_port_id: Bridge port ID if reassigned
+ * @new_dscp_enable: If true, override DSCP
+ * @new_dscp: DSCP to set
+ * @new_traffic_class_enable: If true, override traffic class
+ * @new_traffic_class: Traffic class to set
+ * @new_meter_enable: If true, use new meter
+ * @s_new_traffic_meter_id: Meter ID if new meter is used
+ * @mirror_enable: Enable mirroring
+ */
+struct mxl862xx_extendedvlan_treatment {
+	enum mxl862xx_extended_vlan_treatment_remove_tag remove_tag;
+	enum mxl862xx_extended_vlan_4_tpid_mode treatment_4_tpid_mode;
+	bool add_outer_vlan;
+	struct mxl862xx_extendedvlan_treatment_vlan outer_vlan;
+	bool add_inner_vlan;
+	struct mxl862xx_extendedvlan_treatment_vlan inner_vlan;
+	bool reassign_bridge_port;
+	__le16 new_bridge_port_id;
+	bool new_dscp_enable;
+	__le16 new_dscp;
+	bool new_traffic_class_enable;
+	u8 new_traffic_class;
+	bool new_meter_enable;
+	__le16 s_new_traffic_meter_id;
+	u8 dscp2pcp_map[64];
+	bool loopback_enable;
+	bool da_sa_swap_enable;
+	bool mirror_enable;
+} __packed;
+
+/**
+ * struct mxl862xx_extendedvlan_config - Extended VLAN configuration
+ * @extended_vlan_block_id: Block ID
+ * @entry_index: Entry index
+ * @filter: Filter settings
+ * @treatment: Treatment settings
+ */
+struct mxl862xx_extendedvlan_config {
+	__le16 extended_vlan_block_id;
+	__le16 entry_index;
+	struct mxl862xx_extendedvlan_filter filter;
+	struct mxl862xx_extendedvlan_treatment treatment;
+} __packed;
+
+/**
+ * struct mxl862xx_vlanfilter_alloc - VLAN Filter Allocation
+ * @number_of_entries: Number of entries requested
+ * @vlan_filter_block_id: Returned block ID
+ * @discard_untagged: Discard untagged packets
+ * @discard_unmatched_tagged: Discard unmatched tagged packets
+ * @use_default_port_vid: Use default port VLAN ID for filtering
+ */
+struct mxl862xx_vlanfilter_alloc {
+	__le16 number_of_entries;
+	__le16 vlan_filter_block_id;
+	bool discard_untagged;
+	bool discard_unmatched_tagged;
+	bool use_default_port_vid;
+} __packed;
+
+/**
+ * struct mxl862xx_vlanfilter_config - VLAN Filter
+ * @vlan_filter_block_id: Block ID
+ * @entry_index: Entry index
+ * @vlan_filter_mask: VLAN TCI filter mask mode
+ * @val: Value for VLAN filtering
+ * @discard_matched: Discard matched packets
+ */
+struct mxl862xx_vlanfilter_config {
+	__le16 vlan_filter_block_id;
+	__le16 entry_index;
+	enum mxl862xx_vlan_filter_tci_mask vlan_filter_mask;
+	__le32 val;
+	bool discard_matched;
+} __packed;
+
+/**
+ * enum mxl862xx_vlan_rmon_type - VLAN RMON counter type
+ * @MXL862XX_VLAN_RMON_RX: RX RMON counter
+ * @MXL862XX_VLAN_RMON_TX: TX RMON counter
+ * @MXL862XX_VLAN_RMON__PCE_BYPASS: PCE bypass RMON counter
+ */
+enum mxl862xx_vlan_rmon_type {
+	MXL862XX_VLAN_RMON_RX = 0,
+	MXL862XX_VLAN_RMON_TX = 1,
+	MXL862XX_VLAN_RMON__PCE_BYPASS = 2,
+};
+
+/**
+ * struct mxl862xx_vlan_rmon_cnt - VLAN RMON counters
+ * @vlan_counter_index: Counter index
+ * @vlan_rmon_type: RMON counter type
+ * @byte_count_high: High 32 bits of byte count
+ * @byte_count_low: Low 32 bits of byte count
+ * @total_pkt_count: Total packet count
+ * @multicast_pkt_count: Multicast packet count
+ * @drop_pkt_count: Drop packet count
+ * @clear_all: Clear all counters
+ */
+struct mxl862xx_vlan_rmon_cnt {
+	__le16 vlan_counter_index;
+	enum mxl862xx_vlan_rmon_type vlan_rmon_type;
+	__le32 byte_count_high;
+	__le32 byte_count_low;
+	__le32 total_pkt_count;
+	__le32 multicast_pkt_count;
+	__le32 drop_pkt_count;
+	__le32 clear_all;
+} __packed;
+
+/**
+ * struct mxl862xx_vlan_rmon_control - VLAN RMON control
+ * @vlan_rmon_enable: Enable VLAN RMON
+ * @include_broad_cast_pkt_counting: Include broadcast packet counting
+ * @vlan_last_entry: Last entry index
+ */
+struct mxl862xx_vlan_rmon_control {
+	bool vlan_rmon_enable;
+	bool include_broad_cast_pkt_counting;
+	__le32 vlan_last_entry;
+} __packed;
+
+/**
+ * enum mxl862xx_vlan_counter_mapping_type - VLAN counter mapping type
+ * @MXL862XX_VLAN_MAPPING_INGRESS: Ingress mapping
+ * @MXL862XX_VLAN_MAPPING_EGRESS: Egress mapping
+ * @MXL862XX_VLAN_MAPPING_INGRESS_AND_EGRESS: Ingress and egress mapping
+ */
+enum mxl862xx_vlan_counter_mapping_type {
+	MXL862XX_VLAN_MAPPING_INGRESS = 0,
+	MXL862XX_VLAN_MAPPING_EGRESS = 1,
+	MXL862XX_VLAN_MAPPING_INGRESS_AND_EGRESS = 2
+};
+
+/**
+ * enum mxl862xx_vlan_counter_map_filter_type - VLAN counter mapping filter type
+ * @MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_NORMAL: Tagged packet with matching criteria
+ * @MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_NO_FILTER: Tagged packet with no criteria
+ * @MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_DEFAULT: Default entry if no rule applies
+ * @MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_NO_TAG: No VLAN tag
+ * @MXL862XX_VLANCOUNTERMAP_FILTER_INVALID: Invalid filter
+ */
+enum mxl862xx_vlan_counter_map_filter_type {
+	MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_NORMAL = 0,
+	MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_NO_FILTER = 1,
+	MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_DEFAULT = 2,
+	MXL862XX_VLANCOUNTERMAP_FILTER_TYPE_NO_TAG = 3,
+	MXL862XX_VLANCOUNTERMAP_FILTER_INVALID = 4,
+};
+
+/**
+ * struct mxl862xx_vlan_counter_mapping_config - VLAN counter mapping configuration
+ * @counter_index: Counter index
+ * @ctp_port_id: CTP port ID
+ * @priority_enable: Enable priority filtering
+ * @priority_val: Priority value to match
+ * @vid_enable: Enable VID filtering
+ * @vid_val: VID value to match
+ * @vlan_tag_selection_enable: Enable VLAN tag selection
+ * @vlan_counter_mapping_type: Mapping type
+ * @vlan_counter_mapping_filter_type: Filter type
+ */
+struct mxl862xx_vlan_counter_mapping_config {
+	u8 counter_index;
+	__le16 ctp_port_id;
+	bool priority_enable;
+	__le32 priority_val;
+	bool vid_enable;
+	__le32 vid_val;
+	bool vlan_tag_selection_enable;
+	enum mxl862xx_vlan_counter_mapping_type vlan_counter_mapping_type;
+	enum mxl862xx_vlan_counter_map_filter_type vlan_counter_mapping_filter_type;
+} __packed;
+
+/**
+ * struct mxl862xx_sys_fw_image_version - VLAN counter mapping configuration
+ * @iv_major: firmware major version
+ * @iv_minor: firmware minor version
+ * @iv_revision: firmware revision
+ * @iv_build_num: firmware build number
+ */
+struct mxl862xx_sys_fw_image_version {
+	u8 iv_major;
+	u8 iv_minor;
+	__le16 iv_revision;
+	__le32 iv_build_num;
+} __packed;
diff --git a/drivers/net/dsa/mxl862xx/mxl862xx-cmd.h b/drivers/net/dsa/mxl862xx/mxl862xx-cmd.h
new file mode 100644
index 000000000000..93182b499953
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/mxl862xx-cmd.h
@@ -0,0 +1,216 @@
+#define MXL862XX_MMD_DEV 30
+#define MXL862XX_MMD_REG_CTRL 0
+#define MXL862XX_MMD_REG_LEN_RET 1
+#define MXL862XX_MMD_REG_DATA_FIRST 2
+#define MXL862XX_MMD_REG_DATA_LAST 95
+#define MXL862XX_MMD_REG_DATA_MAX_SIZE \
+	(MXL862XX_MMD_REG_DATA_LAST - MXL862XX_MMD_REG_DATA_FIRST + 1)
+
+#define MXL862XX_COMMON_MAGIC 0x100
+#define MXL862XX_TFLOW_MAGIC 0x200
+#define MXL862XX_BRDG_MAGIC 0x300
+#define MXL862XX_BRDGPORT_MAGIC 0x400
+#define MXL862XX_CTP_MAGIC 0x500
+#define MXL862XX_QOS_MAGIC 0x600
+#define MXL862XX_RMON_MAGIC 0x700
+#define MXL862XX_DEBUG_MAGIC 0x800
+#define MXL862XX_PMAC_MAGIC 0x900
+#define MXL862XX_SWMAC_MAGIC 0xA00
+#define MXL862XX_EXTVLAN_MAGIC 0xB00
+#define MXL862XX_VLANFILTER_MAGIC 0xC00
+#define MXL862XX_MULTICAST_MAGIC 0xD00
+#define MXL862XX_TRUNKING_MAGIC 0xE00
+#define MXL862XX_STP_MAGIC 0xF00
+#define MXL862XX_PBB_MAGIC 0x1000
+#define MXL862XX_VLAN_RMON_MAGIC 0x1100
+#define MXL862XX_SS_MAGIC 0x1600
+
+#define GPY_GPY2XX_MAGIC 0x1800
+
+#define SYS_MISC_MAGIC 0x1900
+
+#define MMD_API_SET_DATA_0 (0x0 + 0x2)
+#define MMD_API_SET_DATA_1 (0x0 + 0x3)
+#define MMD_API_SET_DATA_2 (0x0 + 0x4)
+#define MMD_API_GET_DATA_0 (0x0 + 0x5)
+#define MMD_API_GET_DATA_1 (0x0 + 0x6)
+#define MMD_API_GET_DATA_2 (0x0 + 0x7)
+#define MMD_API_RST_DATA (0x0 + 0x8)
+
+#define MXL862XX_COMMON_REGISTERGET (MXL862XX_COMMON_MAGIC + 0x1)
+#define MXL862XX_COMMON_REGISTERSET (MXL862XX_COMMON_MAGIC + 0x2)
+#define MXL862XX_COMMON_CPU_PORTCFGGET (MXL862XX_COMMON_MAGIC + 0x3)
+#define MXL862XX_COMMON_CPU_PORTCFGSET (MXL862XX_COMMON_MAGIC + 0x4)
+#define MXL862XX_COMMON_PORTLINKCFGGET (MXL862XX_COMMON_MAGIC + 0x5)
+#define MXL862XX_COMMON_PORTLINKCFGSET (MXL862XX_COMMON_MAGIC + 0x6)
+#define MXL862XX_COMMON_PORTCFGGET (MXL862XX_COMMON_MAGIC + 0x7)
+#define MXL862XX_COMMON_PORTCFGSET (MXL862XX_COMMON_MAGIC + 0x8)
+#define MXL862XX_COMMON_CFGGET (MXL862XX_COMMON_MAGIC + 0x9)
+#define MXL862XX_COMMON_CFGSET (MXL862XX_COMMON_MAGIC + 0xA)
+#define MXL862XX_COMMON_MONITORPORTCFGGET (MXL862XX_COMMON_MAGIC + 0xD)
+#define MXL862XX_COMMON_MONITORPORTCFGSET (MXL862XX_COMMON_MAGIC + 0xE)
+#define MXL862XX_COMMON_FREEZE (MXL862XX_COMMON_MAGIC + 0xF)
+#define MXL862XX_COMMON_UNFREEZE (MXL862XX_COMMON_MAGIC + 0x10)
+#define MXL862XX_COMMON_REGISTERMOD (MXL862XX_COMMON_MAGIC + 0x11)
+
+#define MXL862XX_TFLOW_PCERULEREAD (MXL862XX_TFLOW_MAGIC + 0x1)
+#define MXL862XX_TFLOW_PCERULEWRITE (MXL862XX_TFLOW_MAGIC + 0x2)
+#define MXL862XX_TFLOW_PCERULEDELETE (MXL862XX_TFLOW_MAGIC + 0x3)
+#define MXL862XX_TFLOW_PCERULEALLOC (MXL862XX_TFLOW_MAGIC + 0x4)
+#define MXL862XX_TFLOW_PCERULEFREE (MXL862XX_TFLOW_MAGIC + 0x5)
+#define MXL862XX_TFLOW_PCERULEENABLE (MXL862XX_TFLOW_MAGIC + 0x6)
+#define MXL862XX_TFLOW_PCERULEDISABLE (MXL862XX_TFLOW_MAGIC + 0x7)
+
+#define MXL862XX_BRIDGE_ALLOC (MXL862XX_BRDG_MAGIC + 0x1)
+#define MXL862XX_BRIDGE_CONFIGSET (MXL862XX_BRDG_MAGIC + 0x2)
+#define MXL862XX_BRIDGE_CONFIGGET (MXL862XX_BRDG_MAGIC + 0x3)
+#define MXL862XX_BRIDGE_FREE (MXL862XX_BRDG_MAGIC + 0x4)
+
+#define MXL862XX_BRIDGEPORT_ALLOC (MXL862XX_BRDGPORT_MAGIC + 0x1)
+#define MXL862XX_BRIDGEPORT_CONFIGSET (MXL862XX_BRDGPORT_MAGIC + 0x2)
+#define MXL862XX_BRIDGEPORT_CONFIGGET (MXL862XX_BRDGPORT_MAGIC + 0x3)
+#define MXL862XX_BRIDGEPORT_FREE (MXL862XX_BRDGPORT_MAGIC + 0x4)
+
+#define MXL862XX_CTP_PORTASSIGNMENTALLOC (MXL862XX_CTP_MAGIC + 0x1)
+#define MXL862XX_CTP_PORTASSIGNMENTFREE (MXL862XX_CTP_MAGIC + 0x2)
+#define MXL862XX_CTP_PORTASSIGNMENTSET (MXL862XX_CTP_MAGIC + 0x3)
+#define MXL862XX_CTP_PORTASSIGNMENTGET (MXL862XX_CTP_MAGIC + 0x4)
+#define MXL862XX_CTP_PORTCONFIGSET (MXL862XX_CTP_MAGIC + 0x5)
+#define MXL862XX_CTP_PORTCONFIGGET (MXL862XX_CTP_MAGIC + 0x6)
+#define MXL862XX_CTP_PORTCONFIGRESET (MXL862XX_CTP_MAGIC + 0x7)
+
+#define MXL862XX_QOS_METERCFGGET (MXL862XX_QOS_MAGIC + 0x1)
+#define MXL862XX_QOS_METERCFGSET (MXL862XX_QOS_MAGIC + 0x2)
+#define MXL862XX_QOS_DSCP_CLASSGET (MXL862XX_QOS_MAGIC + 0x4)
+#define MXL862XX_QOS_DSCP_CLASSSET (MXL862XX_QOS_MAGIC + 0x5)
+#define MXL862XX_QOS_DSCP_DROPPRECEDENCECFGGET (MXL862XX_QOS_MAGIC + 0x6)
+#define MXL862XX_QOS_DSCP_DROPPRECEDENCECFGSET (MXL862XX_QOS_MAGIC + 0x7)
+#define MXL862XX_QOS_PORTREMARKINGCFGGET (MXL862XX_QOS_MAGIC + 0x8)
+#define MXL862XX_QOS_PORTREMARKINGCFGSET (MXL862XX_QOS_MAGIC + 0x9)
+#define MXL862XX_QOS_PCP_CLASSGET (MXL862XX_QOS_MAGIC + 0xA)
+#define MXL862XX_QOS_PCP_CLASSSET (MXL862XX_QOS_MAGIC + 0xB)
+#define MXL862XX_QOS_PORTCFGGET (MXL862XX_QOS_MAGIC + 0xC)
+#define MXL862XX_QOS_PORTCFGSET (MXL862XX_QOS_MAGIC + 0xD)
+#define MXL862XX_QOS_QUEUEPORTGET (MXL862XX_QOS_MAGIC + 0xE)
+#define MXL862XX_QOS_QUEUEPORTSET (MXL862XX_QOS_MAGIC + 0xF)
+#define MXL862XX_QOS_SCHEDULERCFGGET (MXL862XX_QOS_MAGIC + 0x10)
+#define MXL862XX_QOS_SCHEDULERCFGSET (MXL862XX_QOS_MAGIC + 0x11)
+#define MXL862XX_QOS_SHAPERCFGGET (MXL862XX_QOS_MAGIC + 0x12)
+#define MXL862XX_QOS_SHAPERCFGSET (MXL862XX_QOS_MAGIC + 0x13)
+#define MXL862XX_QOS_SHAPERQUEUEASSIGN (MXL862XX_QOS_MAGIC + 0x14)
+#define MXL862XX_QOS_SHAPERQUEUEDEASSIGN (MXL862XX_QOS_MAGIC + 0x15)
+#define MXL862XX_QOS_SHAPERQUEUEGET (MXL862XX_QOS_MAGIC + 0x16)
+#define MXL862XX_QOS_STORMCFGSET (MXL862XX_QOS_MAGIC + 0x17)
+#define MXL862XX_QOS_STORMCFGGET (MXL862XX_QOS_MAGIC + 0x18)
+#define MXL862XX_QOS_WREDCFGGET (MXL862XX_QOS_MAGIC + 0x19)
+#define MXL862XX_QOS_WREDCFGSET (MXL862XX_QOS_MAGIC + 0x1A)
+#define MXL862XX_QOS_WREDQUEUECFGGET (MXL862XX_QOS_MAGIC + 0x1B)
+#define MXL862XX_QOS_WREDQUEUECFGSET (MXL862XX_QOS_MAGIC + 0x1C)
+#define MXL862XX_QOS_WREDPORTCFGGET (MXL862XX_QOS_MAGIC + 0x1D)
+#define MXL862XX_QOS_WREDPORTCFGSET (MXL862XX_QOS_MAGIC + 0x1E)
+#define MXL862XX_QOS_FLOWCTRLCFGGET (MXL862XX_QOS_MAGIC + 0x1F)
+#define MXL862XX_QOS_FLOWCTRLCFGSET (MXL862XX_QOS_MAGIC + 0x20)
+#define MXL862XX_QOS_FLOWCTRLPORTCFGGET (MXL862XX_QOS_MAGIC + 0x21)
+#define MXL862XX_QOS_FLOWCTRLPORTCFGSET (MXL862XX_QOS_MAGIC + 0x22)
+#define MXL862XX_QOS_QUEUEBUFFERRESERVECFGGET (MXL862XX_QOS_MAGIC + 0x23)
+#define MXL862XX_QOS_QUEUEBUFFERRESERVECFGSET (MXL862XX_QOS_MAGIC + 0x24)
+#define MXL862XX_QOS_COLORMARKINGTABLEGET (MXL862XX_QOS_MAGIC + 0x26)
+#define MXL862XX_QOS_COLORMARKINGTABLESET (MXL862XX_QOS_MAGIC + 0x27)
+#define MXL862XX_QOS_COLORREMARKINGTABLESET (MXL862XX_QOS_MAGIC + 0x28)
+#define MXL862XX_QOS_COLORREMARKINGTABLEGET (MXL862XX_QOS_MAGIC + 0x29)
+#define MXL862XX_QOS_METERALLOC (MXL862XX_QOS_MAGIC + 0x2A)
+#define MXL862XX_QOS_METERFREE (MXL862XX_QOS_MAGIC + 0x2B)
+#define MXL862XX_QOS_DSCP2PCPTABLESET (MXL862XX_QOS_MAGIC + 0x2C)
+#define MXL862XX_QOS_DSCP2PCPTABLEGET (MXL862XX_QOS_MAGIC + 0x2D)
+#define MXL862XX_QOS_PMAPPERTABLESET (MXL862XX_QOS_MAGIC + 0x2E)
+#define MXL862XX_QOS_PMAPPERTABLEGET (MXL862XX_QOS_MAGIC + 0x2F)
+#define MXL862XX_QOS_SVLAN_PCP_CLASSGET (MXL862XX_QOS_MAGIC + 0x30)
+#define MXL862XX_QOS_SVLAN_PCP_CLASSSET (MXL862XX_QOS_MAGIC + 0x31)
+
+#define MXL862XX_RMON_PORT_GET (MXL862XX_RMON_MAGIC + 0x1)
+#define MXL862XX_RMON_MODE_SET (MXL862XX_RMON_MAGIC + 0x2)
+#define MXL862XX_RMON_METER_GET (MXL862XX_RMON_MAGIC + 0x3)
+#define MXL862XX_RMON_CLEAR (MXL862XX_RMON_MAGIC + 0x4)
+#define MXL862XX_RMON_TFLOWGET (MXL862XX_RMON_MAGIC + 0x5)
+#define MXL862XX_RMON_TFLOWCLEAR (MXL862XX_RMON_MAGIC + 0x6)
+#define MXL862XX_RMON_TFLOWCOUNTMODESET (MXL862XX_RMON_MAGIC + 0x7)
+#define MXL862XX_RMON_TFLOWCOUNTMODEGET (MXL862XX_RMON_MAGIC + 0x8)
+
+#define MXL862XX_DEBUG_RMON_PORT_GET (MXL862XX_DEBUG_MAGIC + 0x1)
+
+#define MXL862XX_PMAC_COUNTGET (MXL862XX_PMAC_MAGIC + 0x1)
+#define MXL862XX_PMAC_GBL_CFGSET (MXL862XX_PMAC_MAGIC + 0x2)
+#define MXL862XX_PMAC_GBL_CFGGET (MXL862XX_PMAC_MAGIC + 0x3)
+#define MXL862XX_PMAC_BM_CFGSET (MXL862XX_PMAC_MAGIC + 0x4)
+#define MXL862XX_PMAC_BM_CFGGET (MXL862XX_PMAC_MAGIC + 0x5)
+#define MXL862XX_PMAC_IG_CFGSET (MXL862XX_PMAC_MAGIC + 0x6)
+#define MXL862XX_PMAC_IG_CFGGET (MXL862XX_PMAC_MAGIC + 0x7)
+#define MXL862XX_PMAC_EG_CFGSET (MXL862XX_PMAC_MAGIC + 0x8)
+#define MXL862XX_PMAC_EG_CFGGET (MXL862XX_PMAC_MAGIC + 0x9)
+
+#define MXL862XX_MAC_TABLECLEAR (MXL862XX_SWMAC_MAGIC + 0x1)
+#define MXL862XX_MAC_TABLEENTRYADD (MXL862XX_SWMAC_MAGIC + 0x2)
+#define MXL862XX_MAC_TABLEENTRYREAD (MXL862XX_SWMAC_MAGIC + 0x3)
+#define MXL862XX_MAC_TABLEENTRYQUERY (MXL862XX_SWMAC_MAGIC + 0x4)
+#define MXL862XX_MAC_TABLEENTRYREMOVE (MXL862XX_SWMAC_MAGIC + 0x5)
+#define MXL862XX_MAC_DEFAULTFILTERSET (MXL862XX_SWMAC_MAGIC + 0x6)
+#define MXL862XX_MAC_DEFAULTFILTERGET (MXL862XX_SWMAC_MAGIC + 0x7)
+#define MXL862XX_MAC_TABLECLEARCOND (MXL862XX_SWMAC_MAGIC + 0x8)
+
+#define MXL862XX_EXTENDEDVLAN_ALLOC (MXL862XX_EXTVLAN_MAGIC + 0x1)
+#define MXL862XX_EXTENDEDVLAN_SET (MXL862XX_EXTVLAN_MAGIC + 0x2)
+#define MXL862XX_EXTENDEDVLAN_GET (MXL862XX_EXTVLAN_MAGIC + 0x3)
+#define MXL862XX_EXTENDEDVLAN_FREE (MXL862XX_EXTVLAN_MAGIC + 0x4)
+
+#define MXL862XX_VLANFILTER_ALLOC (MXL862XX_VLANFILTER_MAGIC + 0x1)
+#define MXL862XX_VLANFILTER_SET (MXL862XX_VLANFILTER_MAGIC + 0x2)
+#define MXL862XX_VLANFILTER_GET (MXL862XX_VLANFILTER_MAGIC + 0x3)
+#define MXL862XX_VLANFILTER_FREE (MXL862XX_VLANFILTER_MAGIC + 0x4)
+
+#define MXL862XX_VLAN_COUNTER_MAPPING_SET (MXL862XX_VLAN_RMON_MAGIC + 0x1)
+#define MXL862XX_VLAN_COUNTER_MAPPING_GET (MXL862XX_VLAN_RMON_MAGIC + 0x2)
+#define MXL862XX_VLAN_RMON_GET (MXL862XX_VLAN_RMON_MAGIC + 0x3)
+#define MXL862XX_VLAN_RMON_CLEAR (MXL862XX_VLAN_RMON_MAGIC + 0x4)
+#define MXL862XX_VLAN_RMON_CONTROL_SET (MXL862XX_VLAN_RMON_MAGIC + 0x5)
+#define MXL862XX_VLAN_RMON_CONTROL_GET (MXL862XX_VLAN_RMON_MAGIC + 0x6)
+
+#define MXL862XX_MULTICAST_ROUTERPORTADD (MXL862XX_MULTICAST_MAGIC + 0x1)
+#define MXL862XX_MULTICAST_ROUTERPORTREAD (MXL862XX_MULTICAST_MAGIC + 0x2)
+#define MXL862XX_MULTICAST_ROUTERPORTREMOVE (MXL862XX_MULTICAST_MAGIC + 0x3)
+#define MXL862XX_MULTICAST_SNOOPCFGGET (MXL862XX_MULTICAST_MAGIC + 0x4)
+#define MXL862XX_MULTICAST_SNOOPCFGSET (MXL862XX_MULTICAST_MAGIC + 0x5)
+#define MXL862XX_MULTICAST_TABLEENTRYADD (MXL862XX_MULTICAST_MAGIC + 0x6)
+#define MXL862XX_MULTICAST_TABLEENTRYREAD (MXL862XX_MULTICAST_MAGIC + 0x7)
+#define MXL862XX_MULTICAST_TABLEENTRYREMOVE (MXL862XX_MULTICAST_MAGIC + 0x8)
+
+#define MXL862XX_TRUNKING_CFGGET (MXL862XX_TRUNKING_MAGIC + 0x1)
+#define MXL862XX_TRUNKING_CFGSET (MXL862XX_TRUNKING_MAGIC + 0x2)
+#define MXL862XX_TRUNKING_PORTCFGGET (MXL862XX_TRUNKING_MAGIC + 0x3)
+#define MXL862XX_TRUNKING_PORTCFGSET (MXL862XX_TRUNKING_MAGIC + 0x4)
+
+#define MXL862XX_STP_PORTCFGGET (MXL862XX_STP_MAGIC + 0x1)
+#define MXL862XX_STP_PORTCFGSET (MXL862XX_STP_MAGIC + 0x2)
+#define MXL862XX_STP_BPDU_RULEGET (MXL862XX_STP_MAGIC + 0x3)
+#define MXL862XX_STP_BPDU_RULESET (MXL862XX_STP_MAGIC + 0x4)
+
+#define MXL862XX_PBB_TEMPLATEALLOC (MXL862XX_PBB_MAGIC + 0x1)
+#define MXL862XX_PBB_TEMPLATEFREE (MXL862XX_PBB_MAGIC + 0x2)
+#define MXL862XX_PBB_TEMPLATESET (MXL862XX_PBB_MAGIC + 0x3)
+#define MXL862XX_PBB_TEMPLATEGET (MXL862XX_PBB_MAGIC + 0x4)
+
+#define MXL862XX_SS_SPTAG_GET (MXL862XX_SS_MAGIC + 0x01)
+#define MXL862XX_SS_SPTAG_SET (MXL862XX_SS_MAGIC + 0x02)
+
+#define INT_GPHY_READ (GPY_GPY2XX_MAGIC + 0x01)
+#define INT_GPHY_WRITE (GPY_GPY2XX_MAGIC + 0x02)
+#define INT_GPHY_MOD (GPY_GPY2XX_MAGIC + 0x03)
+#define EXT_MDIO_READ (GPY_GPY2XX_MAGIC + 0x11)
+#define EXT_MDIO_WRITE (GPY_GPY2XX_MAGIC + 0x12)
+#define EXT_MDIO_MOD (GPY_GPY2XX_MAGIC + 0x13)
+
+#define SYS_MISC_FW_UPDATE (SYS_MISC_MAGIC + 0x01)
+#define SYS_MISC_FW_VERSION (SYS_MISC_MAGIC + 0x02)
+#define SYS_MISC_PVT_TEMP (SYS_MISC_MAGIC + 0x03)
+#define SYS_MISC_PVT_VOLTAGE (SYS_MISC_MAGIC + 0x04)
+
+#define MMD_API_MAXIMUM_ID 0x7FFF
diff --git a/drivers/net/dsa/mxl862xx/mxl862xx-host.c b/drivers/net/dsa/mxl862xx/mxl862xx-host.c
new file mode 100644
index 000000000000..dc80eaf8925c
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/mxl862xx-host.c
@@ -0,0 +1,201 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Based upon the Maxlinear SDK driver
+ *
+ * Copyright (C) 2024 MaxLinear Inc.
+ * Copyright (C) 2025 John Crispin <john@phrozen.org>
+ */
+
+#include <linux/bits.h>
+#include <net/dsa.h>
+#include "mxl862xx.h"
+#include "mxl862xx-host.h"
+
+#define CTRL_BUSY_MASK BIT(15)
+#define CTRL_CMD_MASK (BIT(15) - 1)
+
+#define MAX_BUSY_LOOP 1000 /* roughly 10ms */
+
+#define MXL862XX_MMD_DEV 30
+#define MXL862XX_MMD_REG_CTRL 0
+#define MXL862XX_MMD_REG_LEN_RET 1
+#define MXL862XX_MMD_REG_DATA_FIRST 2
+#define MXL862XX_MMD_REG_DATA_LAST 95
+#define MXL862XX_MMD_REG_DATA_MAX_SIZE \
+        (MXL862XX_MMD_REG_DATA_LAST - MXL862XX_MMD_REG_DATA_FIRST + 1)
+
+#define MMD_API_SET_DATA_0 (0x0 + 0x2)
+#define MMD_API_GET_DATA_0 (0x0 + 0x5)
+#define MMD_API_RST_DATA (0x0 + 0x8)
+
+static int mxl862xx_read(struct mxl862xx_priv *dev, u32 addr)
+{
+	return __mdiobus_c45_read(dev->bus, dev->sw_addr, MXL862XX_MMD_DEV, addr);
+}
+
+int mxl862xx_write(struct mxl862xx_priv *dev, u32 addr, u16 data)
+{
+	return  __mdiobus_c45_write(dev->bus, dev->sw_addr, MXL862XX_MMD_DEV, addr, data);
+}
+
+static int mxl862xx_busy_wait(struct mxl862xx_priv *dev)
+{
+	int ret, i;
+
+	for (i = 0; i < MAX_BUSY_LOOP; i++) {
+		ret = mxl862xx_read(dev, MXL862XX_MMD_REG_CTRL);
+		if (ret < 0)
+			return ret;
+
+		if (ret & CTRL_BUSY_MASK)
+			usleep_range(10, 15);
+		else
+			return 0;
+
+	}
+
+	return -ETIMEDOUT;
+}
+
+static int mxl862xx_set_data(struct mxl862xx_priv *dev, u16 words)
+{
+	int ret;
+	u16 cmd;
+
+	ret = mxl862xx_write(dev, MXL862XX_MMD_REG_LEN_RET,
+			MXL862XX_MMD_REG_DATA_MAX_SIZE * sizeof(u16));
+	if (ret < 0)
+		return ret;
+
+	cmd = words / MXL862XX_MMD_REG_DATA_MAX_SIZE - 1;
+	if (!(cmd < 2))
+		return -EINVAL;
+
+	cmd += MMD_API_SET_DATA_0;
+	ret = mxl862xx_write(dev, MXL862XX_MMD_REG_CTRL, cmd | CTRL_BUSY_MASK);
+	if (ret < 0)
+		return ret;
+
+	return mxl862xx_busy_wait(dev);
+}
+
+static int mxl862xx_get_data(struct mxl862xx_priv *dev, u16 words)
+{
+	int ret;
+	u16 cmd;
+
+	ret = mxl862xx_write(dev, MXL862XX_MMD_REG_LEN_RET,
+			MXL862XX_MMD_REG_DATA_MAX_SIZE * sizeof(u16));
+	if (ret < 0)
+		return ret;
+
+	cmd = words / MXL862XX_MMD_REG_DATA_MAX_SIZE;
+	if (!(cmd > 0 && cmd < 3))
+		return -EINVAL;
+
+	cmd += MMD_API_GET_DATA_0;
+	ret = mxl862xx_write(dev, MXL862XX_MMD_REG_CTRL, cmd | CTRL_BUSY_MASK);
+	if (ret < 0)
+		return ret;
+
+	return mxl862xx_busy_wait(dev);
+}
+
+static int mxl862xx_send_cmd(struct mxl862xx_priv *dev, u16 cmd, u16 size,
+			  int16_t *presult)
+{
+	int ret;
+
+	ret = mxl862xx_write(dev, MXL862XX_MMD_REG_LEN_RET, size);
+	if (ret)
+		return ret;
+
+	ret = mxl862xx_write(dev, MXL862XX_MMD_REG_CTRL, cmd | CTRL_BUSY_MASK);
+	if (ret)
+		return ret;
+
+	ret = mxl862xx_busy_wait(dev);
+	if (ret)
+		return ret;
+
+	ret = mxl862xx_read(dev, MXL862XX_MMD_REG_LEN_RET);
+	if (ret < 0)
+		return ret;
+
+	*presult = ret;
+	return 0;
+}
+
+int mxl862xx_api_wrap(struct mxl862xx_priv *priv, u16 cmd, void *_data,
+		      u16 size, bool read)
+{
+	u16 *data = _data;
+	int16_t result = 0;
+	u16 max, i;
+	int ret;
+
+	mutex_lock_nested(&priv->bus->mdio_lock, MDIO_MUTEX_NESTED);
+
+	max = (size + 1) / 2;
+
+	ret = mxl862xx_busy_wait(priv);
+	if (ret < 0)
+		goto out;
+
+	for (i = 0; i < max; i++) {
+		u16 off = i % MXL862XX_MMD_REG_DATA_MAX_SIZE;
+
+		if (i && off == 0) {
+			/* Send command to set data when every
+			 * MXL862XX_MMD_REG_DATA_MAX_SIZE of WORDs are written.
+			 */
+			ret = mxl862xx_set_data(priv, i);
+			if (ret < 0)
+				goto out;
+		}
+
+		mxl862xx_write(priv, MXL862XX_MMD_REG_DATA_FIRST + off,
+			  le16_to_cpu(data[i]));
+	}
+
+	ret = mxl862xx_send_cmd(priv, cmd, size, &result);
+	if (ret < 0)
+		goto out;
+
+	if (result < 0) {
+		ret = result;
+		goto out;
+	}
+
+	for (i = 0; i < max && read; i++) {
+		u16 off = i % MXL862XX_MMD_REG_DATA_MAX_SIZE;
+
+		if (i && off == 0) {
+			/* Send command to fetch next batch of data
+			 * when every MXL862XX_MMD_REG_DATA_MAX_SIZE of WORDs
+			 * are read.
+			 */
+			ret = mxl862xx_get_data(priv, i);
+			if (ret < 0)
+				goto out;
+		}
+
+		ret = mxl862xx_read(priv, MXL862XX_MMD_REG_DATA_FIRST + off);
+		if (ret < 0)
+			goto out;
+
+		if ((i * 2 + 1) == size) {
+			/* Special handling for last BYTE
+			 * if it's not WORD aligned.
+			 */
+			*(uint8_t *)&data[i] = ret & 0xFF;
+		} else {
+			data[i] = cpu_to_le16((u16)ret);
+		}
+	}
+	ret = result;
+
+out:
+	mutex_unlock(&priv->bus->mdio_lock);
+	return ret;
+}
diff --git a/drivers/net/dsa/mxl862xx/mxl862xx-host.h b/drivers/net/dsa/mxl862xx/mxl862xx-host.h
new file mode 100644
index 000000000000..0ed0d5f54900
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/mxl862xx-host.h
@@ -0,0 +1,3 @@
+int mxl862xx_write(struct mxl862xx_priv *dev, u32 regaddr, u16 data);
+extern int mxl862xx_api_wrap(struct mxl862xx_priv *priv, u16 cmd, void *data, u16 size, bool read);
+
diff --git a/drivers/net/dsa/mxl862xx/mxl862xx.c b/drivers/net/dsa/mxl862xx/mxl862xx.c
new file mode 100644
index 000000000000..0ed6c2d7260b
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/mxl862xx.c
@@ -0,0 +1,3568 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Based upon the Maxlinear SDK driver
+ *
+ * Copyright (C) 2024 MaxLinear Inc.
+ * Copyright (C) 2025 John Crispin <john@phrozen.org>
+ * Copyright (C) 2025 Daniel Golle <daniel@makrotopia.org>
+ */
+
+#include <linux/bits.h>
+#include <linux/delay.h>
+#include <linux/etherdevice.h>
+#include <linux/if_bridge.h>
+#include <linux/if_vlan.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/of_device.h>
+#include <linux/phy.h>
+#include <net/dsa.h>
+#include <linux/dsa/8021q.h>
+#include <linux/stddef.h>
+
+#include "mxl862xx.h"
+#include "mxl862xx-api.h"
+#include "mxl862xx-cmd.h"
+#include "mxl862xx-host.h"
+
+
+#define MXL862XX_API_WRITE(dev, cmd, data) \
+	mxl862xx_api_wrap(dev, cmd, &(data), sizeof((data)), false)
+#define MXL862XX_API_READ(dev, cmd, data) \
+	mxl862xx_api_wrap(dev, cmd, &(data), sizeof((data)), true)
+
+/* DSA port index is 0 based, the MXL FW has 1 as the base index */
+#define DSA_MXL_PORT(port) ((port) + 1)
+
+#define MXL862XX_SDMA_PCTRLP(p) (0xBC0 + ((p) * 0x6))
+#define MXL862XX_SDMA_PCTRL_EN BIT(0) /* SDMA Port Enable */
+
+/* Ethernet Switch Fetch DMA Port Control Register */
+#define MXL862XX_FDMA_PCTRLP(p) (0xA80 + ((p) * 0x6))
+#define MXL862XX_FDMA_PCTRL_EN BIT(0) /* FDMA Port Enable */
+
+#define MAX_BRIDGES 16
+#define MAX_VLAN_ENTRIES (1024 - 160)
+#define IDX_INVAL (-1)
+
+#define INGRESS_FINAL_RULES 5
+#define INGRESS_VID_RULES VID_RULES
+#define EGRESS_FINAL_RULES 3
+#define EGRESS_VID_RULES VID_RULES
+/* It's only the size of the array for storing VLAN info.
+ * The real number of simultaneous VLANS is lower
+ * and depends on the number of filtering rules and ports.
+ * It is calculated dynamically at runtime.
+ */
+#define MAX_RULES_RECYCLED MAX_VLANS
+
+struct mxl862xx_mibs {
+	unsigned int size;
+	unsigned int offset;
+	const char *name;
+};
+
+#define MIB_DESC(_name, _element)						\
+{										\
+	.name = _name,								\
+	.offset = offsetof(struct mxl862xx_debug_rmon_port_cnt, _element)	\
+}
+
+static const struct mxl862xx_mibs mxl862xx_mibs_rx[] = {
+	MIB_DESC("RxGoodPkts", rx_good_pkts),
+	MIB_DESC("RxUnicastPkts", rx_unicast_pkts),
+	MIB_DESC("RxBroadcastPkts", rx_broadcast_pkts),
+	MIB_DESC("RxMulticastPkts", rx_multicast_pkts),
+	MIB_DESC("RxFCSErrorPkts", rx_fcserror_pkts),
+	MIB_DESC("RxUnderSizeGoodPkts", rx_under_size_good_pkts),
+	MIB_DESC("RxOversizeGoodPkts", rx_oversize_error_pkts),
+	MIB_DESC("RxUnderSizeErrorPkts", rx_under_size_error_pkts),
+	MIB_DESC("RxOversizeErrorPkts", rx_oversize_error_pkts),
+	MIB_DESC("RxFilteredPkts", rx_filtered_pkts),
+	MIB_DESC("Rx64BytePkts", rx64byte_pkts),
+	MIB_DESC("Rx127BytePkts", rx127byte_pkts),
+	MIB_DESC("Rx255BytePkts", rx255byte_pkts),
+	MIB_DESC("Rx511BytePkts", rx511byte_pkts),
+	MIB_DESC("Rx1023BytePkts", rx1023byte_pkts),
+	MIB_DESC("RxMaxBytePkts", rx_max_byte_pkts),
+	MIB_DESC("RxDroppedPkts", rx_dropped_pkts),
+	MIB_DESC("RxExtendedVlanDiscardPkts", rx_extended_vlan_discard_pkts),
+	MIB_DESC("MtuExceedDiscardPkts", mtu_exceed_discard_pkts),
+	MIB_DESC("RxGoodBytes", rx_good_bytes),
+	MIB_DESC("RxBadBytes", rx_bad_bytes),
+	MIB_DESC("RxUnicastPktsYellowRed", rx_unicast_pkts_yellow_red),
+	MIB_DESC("RxBroadcastPktsYellowRed", rx_broadcast_pkts_yellow_red),
+	MIB_DESC("RxMulticastPktsYellowRed", rx_multicast_pkts_yellow_red),
+	MIB_DESC("RxGoodPktsYellowRed", rx_good_pkts_yellow_red),
+	MIB_DESC("RxGoodBytesYellowRed", rx_good_bytes_yellow_red),
+	MIB_DESC("RxGoodPausePkts", rx_good_pause_pkts),
+	MIB_DESC("RxAlignErrorPkts", rx_align_error_pkts),
+};
+
+static const struct mxl862xx_mibs mxl862xx_mibs_tx[] = {
+	MIB_DESC("TxGoodPkts", tx_good_pkts),
+	MIB_DESC("TxUnicastPkts", tx_unicast_pkts),
+	MIB_DESC("TxBroadcastPkts", tx_broadcast_pkts),
+	MIB_DESC("TxMulticastPkts", tx_multicast_pkts),
+	MIB_DESC("Tx64BytePkts", tx64byte_pkts),
+	MIB_DESC("Tx127BytePkts", tx127byte_pkts),
+	MIB_DESC("Tx255BytePkts", tx255byte_pkts),
+	MIB_DESC("Tx511BytePkts", tx511byte_pkts),
+	MIB_DESC("Tx1023BytePkts", tx1023byte_pkts),
+	MIB_DESC("TxMaxBytePkts", tx_max_byte_pkts),
+	MIB_DESC("TxDroppedPkts", tx_dropped_pkts),
+	MIB_DESC("TxAcmDroppedPkts", tx_acm_dropped_pkts),
+	MIB_DESC("TxGoodBytes", tx_good_bytes),
+	MIB_DESC("TxUnicastPktsYellowRed", tx_unicast_pkts_yellow_red),
+	MIB_DESC("TxBroadcastPktsYellowRed", tx_broadcast_pkts_yellow_red),
+	MIB_DESC("TxMulticastPktsYellowRed", tx_multicast_pkts_yellow_red),
+	MIB_DESC("TxGoodPktsYellowRed", tx_good_pkts_yellow_red),
+	MIB_DESC("TxGoodBytesYellowRed", tx_good_bytes_yellow_red),
+	MIB_DESC("TxSingleCollCount", tx_single_coll_count),
+	MIB_DESC("TxMultCollCount", tx_mult_coll_count),
+	MIB_DESC("TxLateCollCount", tx_late_coll_count),
+	MIB_DESC("TxExcessCollCount", tx_excess_coll_count),
+	MIB_DESC("TxCollCount", tx_coll_count),
+	MIB_DESC("TxPauseCount", tx_pause_count),
+};
+
+static int mxl862xx_phy_read_mmd(struct mxl862xx_priv *priv, int port, int devadd, int reg)
+{
+	struct mdio_relay_data param = {
+		.phy = port,
+		.mmd = devadd,
+		.reg = reg & 0xffff,
+	};
+	int ret;
+
+	ret = MXL862XX_API_READ(priv, INT_GPHY_READ, param);
+	if (ret) {
+		pr_err("mxl862xx: failed to read mmd on port %d\n", port);
+		return ret;
+	}
+
+	return param.data;
+}
+
+static int mxl862xx_phy_write_mmd(struct mxl862xx_priv *priv, int port,
+				  int devadd, int reg, u16 data)
+{
+	struct mdio_relay_data param = {
+		.phy = port,
+		.mmd = devadd,
+		.reg = reg,
+		.data = data,
+	};
+	int ret;
+
+	ret = MXL862XX_API_WRITE(priv, INT_GPHY_WRITE, param);
+	if (ret)
+		pr_err("mxl862xx: failed to write mmd on port %d\n", port);
+
+	return ret;
+}
+
+static int mxl862xx_phy_read(struct dsa_switch *ds, int port, int reg)
+{
+	return mxl862xx_phy_read_mmd(ds->priv, port, 0, reg);
+}
+
+static int mxl862xx_phy_write(struct dsa_switch *ds, int port, int reg,
+			      u16 data)
+{
+	return mxl862xx_phy_write_mmd(ds->priv, port, 0, reg, data);
+}
+
+static int mxl862xx_mmd_write(struct dsa_switch *ds, int reg, u16 data)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret;
+
+	mutex_lock_nested(&priv->bus->mdio_lock, MDIO_MUTEX_NESTED);
+	ret = mxl862xx_write(priv, reg, data);
+	mutex_unlock(&priv->bus->mdio_lock);
+
+	return ret;
+}
+
+static int mxl862xx_update_bridge_conf_port(struct dsa_switch *ds, u8 port,
+					    struct net_device *bridge, int action)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	u8 phy_ports = priv->hw_info->phy_ports;
+	u8 cpu_port = priv->hw_info->cpu_port;
+	u8 i;
+	bool vlan_sp_tag = (priv->port_info[cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862_8021Q);
+
+	/*struct dsa_port *dp = dsa_to_port(priv->ds, port), *other_dp;
+	 * struct mxl862xx_port_info *other_p;
+	 *int other_port;
+	 */
+	int ret;
+
+	if (!dsa_is_cpu_port(ds, port)) {
+		int bridge_id = priv->port_info[i].bridge_id;
+
+		if (action)
+			priv->bridge_portmap[bridge_id] |= BIT(DSA_MXL_PORT(port));
+		else
+			priv->bridge_portmap[bridge_id] &= ~BIT(DSA_MXL_PORT(port));
+	}
+
+	/* Update switch according to local bridge port map */
+	/* Add this port to the port maps of other ports skiping it's own map */
+	for (i = 0; i < phy_ports; i++) {
+		struct mxl862xx_bridge_port_config br_port_cfg = { };
+		int bridge_id = priv->port_info[i].bridge_id;
+
+		if (!(dsa_is_user_port(ds, i)))
+			continue;
+
+		/* Case for standalone bridges assigned only to single user and CPU ports.
+		 * Used only for initial ports isolation
+		 */
+		if (bridge && i != port)
+			continue;
+
+		/* Do not reconfigure any standalone bridge if this is bridge join scenario */
+		if (bridge && !priv->port_info[i].bridge)
+			continue;
+
+		br_port_cfg.bridge_port_id = DSA_MXL_PORT(i);
+		br_port_cfg.mask |=
+			MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_PORT_MAP |
+			MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_ID;
+
+		ret = MXL862XX_API_READ(priv, MXL862XX_BRIDGEPORT_CONFIGGET, br_port_cfg);
+		if (ret) {
+			dev_err(ds->dev, "failed to set bridge port configuration on port %d\n",
+				port);
+			return ret;;
+		}
+
+		/* Skip port map update if for the existing bridge the port
+		 * is not assigned there.
+		 */
+		if (i != port && (br_port_cfg.bridge_id != bridge_id ||
+				  br_port_cfg.bridge_id == 0))
+			continue;
+
+		br_port_cfg.mask |=
+			MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_PORT_MAP |
+			MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_ID |
+			MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_SRC_MAC_LEARNING;
+
+		/* Skip the port itself in it's own portmap */
+		br_port_cfg.bridge_port_map[0] =
+			priv->bridge_portmap[bridge_id] & ~(BIT(i + 1));
+
+		if (action) {
+			br_port_cfg.src_mac_learning_disable = !bridge;
+			br_port_cfg.bridge_id = bridge_id;
+		} else {
+			/* When port is removed from the bridge, assign it back to the default
+			 * bridge 0
+			 */
+			br_port_cfg.src_mac_learning_disable = true;
+			/* Cleanup the port own map leaving only the CPU port mapping. */
+			if (i == port) {
+				br_port_cfg.bridge_port_map[0] = BIT(DSA_MXL_PORT(cpu_port));
+				br_port_cfg.bridge_id = 0;
+			}
+		}
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGEPORT_CONFIGSET, br_port_cfg);
+		if (ret) {
+			dev_err(ds->dev, "failed to set bridge port configuration on port %d\n", port);
+			return ret;
+		}
+	}
+
+	/* Configure additional bridge port for VLAN based tagging */
+	if (vlan_sp_tag) {
+		int bridge_id = priv->port_info[port].bridge_id;
+		uint16_t bridge_port_cpu = port + 1 + 16;
+		struct mxl862xx_bridge_port_alloc bpa_param = { };
+		struct mxl862xx_bridge_port_config br_port_cfg = { };
+
+		bpa_param.bridge_port_id = bridge_port_cpu;
+
+		if (action) {
+			/* add */
+			ret = MXL862XX_API_READ(priv, MXL862XX_BRIDGEPORT_ALLOC, bpa_param);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare associated bridge port\n",
+					__func__, port);
+				return ret;
+			}
+
+			br_port_cfg.mask |=
+				MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_PORT_MAP |
+				MXL862XX_BRIDGE_PORT_CONFIG_MASK_BRIDGE_ID |
+				MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_CTP_MAPPING |
+				MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_SRC_MAC_LEARNING;
+			br_port_cfg.bridge_id = bridge_id;
+			br_port_cfg.bridge_port_id = bridge_port_cpu;
+			br_port_cfg.bridge_port_map[0] = BIT(port + 1);
+			br_port_cfg.dest_logical_port_id = cpu_port + 1;
+			br_port_cfg.src_mac_learning_disable = true;
+
+			ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGEPORT_CONFIGSET, br_port_cfg);
+			if (ret) {
+				dev_err(ds->dev,
+				"%s: Configuration of cpu bridge port:%d  for port:%d on bridge:%d failed with ret=%d\n",
+				__func__, bridge_port_cpu, port, bridge_id, ret);
+				return ret;
+			}
+
+			/* Add bridge cpu port to portmap */
+			priv->bridge_portmap[bridge_id] |= BIT(bridge_port_cpu);
+			priv->port_info[port].bridge_port_cpu = bridge_port_cpu;
+		} else {
+			/* remove */
+			ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGEPORT_FREE, bpa_param);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to free associated bridge port\n",
+					__func__, port);
+				return ret;
+			}
+			/* Remove bridge cpu port from portmap */
+			priv->bridge_portmap[bridge_id] &= ~BIT(bridge_port_cpu);
+			priv->port_info[port].bridge_port_cpu = 0;
+		}
+	}
+
+	return 0;
+}
+
+static int mxl862_configure_tag_proto(struct dsa_switch *ds, u8 port, bool enable)
+{
+	struct mxl862xx_ss_sp_tag ss_sp_tag_param = {
+		.pid = DSA_MXL_PORT(port),
+		.mask = BIT(0) | BIT(1),
+		.rx = enable ? 2 : 1,
+		.tx = enable ? 2 : 3,
+	};
+	struct mxl862xx_ctp_port_assignment ctp_port_assignment_param = {
+		.number_of_ctp_port = enable ? (32 - (DSA_MXL_PORT(port))) : 1,
+		.logical_port_id = DSA_MXL_PORT(port),
+		.first_ctp_port_id = DSA_MXL_PORT(port),
+		.mode = MXL862XX_LOGICAL_PORT_GPON,
+	};
+	int ret;
+
+	ret = MXL862XX_API_WRITE(ds->priv, MXL862XX_SS_SPTAG_SET, ss_sp_tag_param);
+	if (ret) {
+		dev_err(ds->dev, "failed to %s tagging on port %d\n",
+			enable ? "enable" : "disable", port);
+		return ret;
+	}
+
+	ret = MXL862XX_API_WRITE(ds->priv, MXL862XX_CTP_PORTASSIGNMENTSET, ctp_port_assignment_param);
+	if (ret)
+		dev_err(ds->dev, "failed to configure port assignment on port %d\n", port);
+
+	return ret;
+}
+
+static int mxl862xx_port_state(struct dsa_switch *ds, int port, bool enable)
+{
+	struct mxl862xx_register_mod sdma_param = {
+		.addr = MXL862XX_SDMA_PCTRLP(DSA_MXL_PORT(port)),
+		.data = enable ? MXL862XX_SDMA_PCTRL_EN : 0,
+		.mask = MXL862XX_SDMA_PCTRL_EN,
+	};
+	struct mxl862xx_register_mod fdma_param = {
+		.addr = MXL862XX_FDMA_PCTRLP(DSA_MXL_PORT(port)),
+		.data = enable ? MXL862XX_FDMA_PCTRL_EN : 0,
+		.mask = MXL862XX_FDMA_PCTRL_EN,
+	};
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret;
+
+	if (!dsa_is_user_port(ds, port))
+		return 0;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_COMMON_REGISTERMOD, sdma_param);
+	if (ret) {
+		dev_err(ds->dev, "failed to enable SDMA on port %d\n", port);
+		return ret;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_COMMON_REGISTERMOD, fdma_param);
+	if (ret) {
+		dev_err(ds->dev, "failed to enable FDMA on port %d\n", port);
+		return ret;
+	}
+
+	priv->port_info[port].port_enabled = enable;
+
+	return 0;
+}
+
+static int mxl862xx_port_enable(struct dsa_switch *ds, int port, struct phy_device *phydev)
+{
+	return mxl862xx_port_state(ds, port, true);
+}
+
+static void mxl862xx_port_disable(struct dsa_switch *ds, int port)
+{
+	mxl862xx_port_state(ds, port, false);
+}
+
+static void mxl862xx_port_fast_age(struct dsa_switch *ds, int port)
+{
+	struct mxl862xx_mac_table_clear param = {
+		.type = MXL862XX_MAC_CLEAR_PHY_PORT,
+		.port_id = DSA_MXL_PORT(port),
+	};
+
+	if (MXL862XX_API_WRITE(ds->priv, MXL862XX_MAC_TABLECLEARCOND, param))
+		dev_err(ds->dev, "failed to clear fdb on port %d\n", port);
+}
+
+static int get_vlan_vid_filters_idx(struct mxl862xx_priv *priv, uint8_t port, bool ingress,
+		uint16_t vid, int *f_0, int *f_1, uint16_t *vlan_idx)
+{
+	int ret = -EINVAL;
+	int x, i = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+	struct mxl862xx_extended_vlan_block_info *block_info;
+
+	if (ingress)
+		block_info = &(priv->port_info[port].vlan.ingress_vlan_block_info);
+	else
+		block_info = &(priv->port_info[port].vlan.egress_vlan_block_info);
+
+	/* Check if there's active entry for the requested VLAN. If found, overwrite it. */
+	if (filter_0 < 0 && filter_1 < 0) {
+		for (i = 0; i < MAX_VLANS; i++) {
+			if (block_info->vlans[i].vid == vid) {
+				filter_0 = block_info->vlans[i].filters_idx[0];
+				filter_1 = block_info->vlans[i].filters_idx[1];
+				ret = 0;
+				break;
+			}
+		}
+	}
+
+	/* If there are no matching active VLAN entries, check in recycled */
+	if (filter_0 < 0 && filter_1 < 0) {
+	/* check if there are recycled filter entries for use */
+		for (x = 0; x < MAX_VLANS; x++) {
+			if (block_info->filter_entries_recycled[x].valid) {
+				filter_0 = block_info->filter_entries_recycled[x].filters_idx[0];
+				filter_1 = block_info->filter_entries_recycled[x].filters_idx[1];
+				/* remove filter entries from recycled inventory */
+				block_info->filter_entries_recycled[x].valid = false;
+				ret = 0;
+				break;
+			}
+		}
+
+		/* find empty slot for storing ID's of vlan filtering rules */
+		for (i = 0; i < MAX_VLANS; i++) {
+			if (!(block_info->vlans[i].used)) {
+				ret = 0;
+				break;
+			}
+			if (i == priv->max_vlans - 1) {
+				dev_err(priv->dev,
+					"%s: Port:%d reached max number of defined VLAN's: %d\n",
+					__func__, port, priv->max_vlans);
+				return -ENOSPC;
+			}
+		}
+	}
+
+	if (f_0 != NULL)
+		*f_0 = filter_0;
+	if (f_1 != NULL)
+		*f_1 = filter_1;
+	if (vlan_idx != NULL)
+		*vlan_idx = i;
+
+	return ret;
+}
+
+static int deactivate_vlan_filter_entry(struct dsa_switch *ds, u16 block_id, u16 entry_idx)
+{
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret;
+
+	/* Set default reset values as it makes the rule transparent */
+	vlan_cfg.extended_vlan_block_id = block_id;
+	vlan_cfg.entry_index = entry_idx;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.priority_enable = true;
+	vlan_cfg.filter.outer_vlan.priority_val = 0;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = 0;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.priority_enable = true;
+	vlan_cfg.filter.inner_vlan.priority_val = 0;
+	vlan_cfg.filter.inner_vlan.vid_enable = true;
+	vlan_cfg.filter.inner_vlan.vid_val = 0;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.priority_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.add_inner_vlan = true;
+	vlan_cfg.treatment.inner_vlan.priority_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.inner_vlan.priority_val = 0;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		pr_err("%s: failed to deactivate entry:%d for VLAN block ID:%d\n",
+			__func__, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+
+	return ret;
+}
+
+static int mxl862xx_allocate_extended_vlan_block(struct mxl862xx_priv *priv,
+						 struct mxl862xx_extended_vlan_block_info *block_info)
+{
+	int ret;
+
+	if (!block_info->allocated) {
+		struct mxl862xx_extendedvlan_alloc vlan_alloc = { };
+
+		vlan_alloc.number_of_entries = block_info->filters_max;
+		ret = MXL862XX_API_READ(priv, MXL862XX_EXTENDEDVLAN_ALLOC, vlan_alloc);
+		if (ret)
+			return ret;
+
+		block_info->allocated = true;
+		block_info->block_id = vlan_alloc.extended_vlan_block_id;
+	}
+
+	return 0;
+}
+
+static int prepare_vlan_egress_filters_off_sp_tag_no_vid(struct dsa_switch *ds, uint8_t port)
+{
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret = -EINVAL;
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.egress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	// Static entry :  Outer and iner tag.
+	// Remove outer tag  one as it must be sp_tag. Transparent for inner tag.
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	/* remove  sp tag */
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	// Last entry :  Only outer tag. Remove it as it must be sp_tag
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 1;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	/* remove  sp tag */
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	return 0;
+}
+
+static int prepare_vlan_egress_filters_off_sp_tag(struct dsa_switch *ds, uint8_t port, uint16_t vid, bool untagged)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+	struct mxl862xx_priv *priv = ds->priv;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.egress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* VID specific entries must be processed before the final entries,
+	 * so putting them at the beginnig of the block */
+
+	ret = get_vlan_vid_filters_idx(priv, port, false, vid, &filter_0, &filter_1, &idx);
+	dev_dbg(priv->dev, "%s: Port:%d  vid:%d f_0:%d f_1:%d idx:%d\n", __func__, port, vid, filter_0, filter_1, idx);
+	if (ret)
+		return ret;
+
+	// Entry 0 :  Outer and Inner tags are present. Inner tag matching vid.
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[port]
+				.vlan.egress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.vid_enable = true;
+	vlan_cfg.filter.inner_vlan.vid_val = vid;
+
+	if (untagged) {
+		/* remove both sp_tag(outer) and vid (inner) */
+		vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_2_TAG;
+	} else {
+		/* remove only sp tag */
+		vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+	priv->port_info[port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = IDX_INVAL;
+
+	// Static entry :  Outer and iner tag, not matching vid. Remove outer tag  one as it must be sp_tag
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	/* remove  sp tag */
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	// Last entry :  Only outer tag. Remove it as it must be sp_tag
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	/* remove  sp tag */
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	// Last entry :  Only outer tag. Remove it as it must be sp_tag
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 1;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	/* remove  sp tag */
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index ;
+
+
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].used = true;
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].untagged = untagged;
+
+	return 0;
+}
+
+static int prepare_vlan_egress_filters_off(struct mxl862xx_priv *priv, uint8_t port, uint16_t vid, bool untagged)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.egress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* VID specific entries must be processed before the final entries,
+	 * so putting them at the beginnig of the block */
+
+	ret = get_vlan_vid_filters_idx(priv, port, false, vid, &filter_0, &filter_1, &idx);
+	if (ret)
+		return ret;
+
+	// Entry 0 : ACCEPT VLAN tags that are matching  VID. Outer and Inner tags are present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[port]
+				.vlan.egress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.vid_enable = true;
+	vlan_cfg.filter.inner_vlan.vid_val = vid;
+	if (untagged)
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	else
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+	//	 Entry 1 : ACCEPT VLAN tags that are matching PVID or port VID. Only the outer tags are present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_1 >= 0 ?
+			filter_1 :
+			priv->port_info[port]
+				.vlan.egress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.filter.inner_vlan.vid_enable = true;
+	vlan_cfg.filter.inner_vlan.vid_val = vid;
+	if (untagged)
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	else
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = vlan_cfg.entry_index;
+
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].used = true;
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].untagged = untagged;
+
+
+	return ret;
+}
+
+
+static int prepare_vlan_ingress_filters_off_sp_tag_no_vid(struct dsa_switch *ds, uint8_t port)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	struct dsa_port *dp = dsa_to_port(ds, port);
+	int ret = -EINVAL;
+	struct mxl862xx_extended_vlan_block_info *block_info =
+		&priv->port_info[port].vlan.ingress_vlan_block_info;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv, block_info);
+	if (ret)
+		return ret;
+
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+
+	//Static rules. No tags, add SP tag
+	vlan_cfg.entry_index = block_info->filters_max - 3;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.tpid =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	// Static rules
+	// Single tag. Use transparent mode. Add sp tag
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.tpid =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	// Two tags. Use transparent mode. Do not apply vid as this is tagged pkt
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->filters_max - 1;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.tpid =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	return ret;
+}
+
+static int prepare_vlan_ingress_filters_off_sp_tag(struct dsa_switch *ds, uint8_t port, uint16_t vid)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	struct dsa_port *dp = dsa_to_port(ds, port);
+	int ret = -EINVAL;
+	//there's possible only one rule for single pvid, so it always uses idx 0
+	uint16_t idx = 0;
+	struct mxl862xx_extended_vlan_block_info *block_info =
+		&priv->port_info[port].vlan.ingress_vlan_block_info;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv, block_info);
+	if (ret)
+		return ret;
+
+	/*  If port has pvid then add vid dependand dynamic rule.
+	 *  It's done that way because it's required for proper handling of
+	 *  vlan delete scenario. If no pvid configured, create 'static' rule */
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+
+	// vid dynamic rule
+	if (priv->port_info[port].vlan.pvid) {
+		/* As there's only one  pvid  per port possible, always overwrite the rule at position 0 */
+		vlan_cfg.entry_index = 0;
+		vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+		vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+		vlan_cfg.treatment.add_outer_vlan = true;
+		vlan_cfg.treatment.outer_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.outer_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.outer_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.outer_vlan.priority_val = 0;
+		vlan_cfg.treatment.outer_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+		vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+		vlan_cfg.treatment.add_inner_vlan = true;
+		vlan_cfg.treatment.inner_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.inner_vlan.vid_val =
+			priv->port_info[port].vlan.pvid;
+		vlan_cfg.treatment.inner_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.inner_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.inner_vlan.priority_val = 0;
+		vlan_cfg.treatment.inner_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+		if (ret) {
+			dev_err(priv->dev,
+				"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+				__func__, port, vlan_cfg.entry_index,
+				vlan_cfg.extended_vlan_block_id);
+			return ret;
+		}
+
+		block_info->vlans[idx].filters_idx[0] = vlan_cfg.entry_index;
+		block_info->vlans[idx].filters_idx[1] = IDX_INVAL;
+
+		block_info->vlans[idx].vid = vid;
+		block_info->vlans[idx].used = true;
+
+	}
+	// no pvid, static rule
+	else {
+		// deactivate possible dynamic rule if there's no pvid
+		if (block_info->vlans[idx].vid) {
+			ret = deactivate_vlan_filter_entry(ds, block_info->block_id, block_info->vlans[idx].filters_idx[0]);
+			if (ret)
+				return ret;
+			block_info->vlans[idx].vid = 0;
+			block_info->vlans[idx].used = false;
+		}
+
+		vlan_cfg.entry_index = block_info->filters_max - 3;
+		vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+		vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+		vlan_cfg.treatment.add_outer_vlan = true;
+		vlan_cfg.treatment.outer_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.outer_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.outer_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.outer_vlan.priority_val = 0;
+		vlan_cfg.treatment.outer_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+		vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+		if (ret) {
+			dev_err(priv->dev,
+				"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+				__func__, port, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+			return ret;
+		}
+
+		block_info->final_filters_idx = vlan_cfg.entry_index;
+	}
+
+	// Static rules
+	// Single tag. Use transparent mode. Do not apply PVID as this is the tagged traffic
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.tpid =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	// Two tags. Use transparent mode. Do not apply vid as this is tagged pkt
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->filters_max - 1;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.tpid =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	return ret;
+}
+
+static int prepare_vlan_ingress_filters_off(struct mxl862xx_priv *priv, uint8_t port, uint16_t vid)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.ingress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	// Entry 4  untagged pkts. If there's PVID accept and add PVID tag
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	/* for cpu port this entry is fixed and always put at the end of the block */
+	if (port == priv->hw_info->cpu_port)
+		vlan_cfg.entry_index =  priv->port_info[port].vlan.ingress_vlan_block_info.filters_max - 1;
+	else {
+		vlan_cfg.entry_index =
+			priv->port_info[port]
+				.vlan.ingress_vlan_block_info.final_filters_idx--;
+	}
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+
+	if (priv->port_info[port].vlan.pvid) {
+		vlan_cfg.treatment.add_outer_vlan = true;
+		vlan_cfg.treatment.outer_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.outer_vlan.vid_val =
+			priv->port_info[port].vlan.pvid;
+		vlan_cfg.treatment.outer_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.outer_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.outer_vlan.priority_val = 0;
+		vlan_cfg.treatment.outer_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	ret = get_vlan_vid_filters_idx(priv, port, true, vid, NULL, NULL, &idx);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d couldn't get idx for VID:%d and  block ID:%d\n",
+			__func__, port, vid, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[port].vlan.ingress_vlan_block_info.vlans[idx].used = true;
+
+	return ret;
+}
+
+static int mxl862xx_port_vlan_filtering(struct dsa_switch *ds, int port,
+					bool vlan_filtering,
+					struct netlink_ext_ack *extack)
+{
+	int ret = 0;
+	struct mxl862xx_priv *priv = ds->priv;
+	struct dsa_port *dsa_port = dsa_to_port(ds, port);
+	struct net_device *bridge = dsa_port_bridge_dev_get(dsa_port);
+
+	/* Prevent dynamic setting of the vlan_filtering. */
+	if (bridge && priv->port_info[port].vlan.filtering_mode_locked) {
+		ret = -ENOTSUPP;
+		dev_err(ds->dev, "%s: Change of vlan_filtering mode is not allowed while port:%d is joined to a bridge\n",
+				__func__, port);
+				NL_SET_ERR_MSG_MOD(extack, "Change of vlan_filtering mode is not allowedwhile port is joind to a bridge.");
+
+	} else {
+		priv->port_info[port].vlan.filtering = vlan_filtering;
+		/* Do not lock if port is isolated. */
+		if (!priv->port_info[port].isolated)
+			priv->port_info[port].vlan.filtering_mode_locked = true;
+	}
+
+	return ret;
+}
+
+static int prepare_vlan_egress_filters(struct dsa_switch *ds, uint8_t port, uint16_t vid, bool untagged)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+	struct mxl862xx_priv *priv = ds->priv;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+	struct mxl862xx_extended_vlan_block_info *block_info =
+		&priv->port_info[port].vlan.egress_vlan_block_info;
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv, block_info);
+	if (ret)
+		return ret;
+
+	/* First populate the block with set of rules which should be executed finally after
+	 * VID specific filtering. The final rules (not related to VID) are placed on the end of the block. The number of
+	 * rules is fixed  per port. Order of execution  is important. To avoid static reservations they are
+	 * stored in reversed order starting from the end of the block */
+
+	//Entry 4: no outer/inner tag, no PVID  DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->final_filters_idx--;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	//Entry 3: Only Outer tag present. Discard if VID is not matching the previous rules
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->final_filters_idx--;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	//Entry 2: Outer and Inner tags are present. Discard if VID is not matching the previous rules
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	vlan_cfg.entry_index = block_info->final_filters_idx--;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* VID specific entries must be processed before the final entries,
+	 * so putting them at the beginnig of the block */
+	ret = get_vlan_vid_filters_idx(priv, port, false, vid, &filter_0, &filter_1, &idx);
+	if (ret)
+		return ret;
+
+	// Entry 0 : ACCEPT VLAN tags that are matching  VID. Outer and Inner tags are present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ? filter_0 : block_info->vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+
+	if (untagged)
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	else
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	block_info->vlans[idx].filters_idx[0] = vlan_cfg.entry_index;
+
+	//	 Entry 1 : ACCEPT VLAN tags that are matching PVID or port VID. Only the outer tags are present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_1 >= 0 ? filter_1 : block_info->vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	if (untagged)
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	else
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	block_info->vlans[idx].filters_idx[1] = vlan_cfg.entry_index;
+
+	block_info->vlans[idx].vid = vid;
+	block_info->vlans[idx].used = true;
+	block_info->vlans[idx].untagged = untagged;
+
+	return ret;
+}
+
+static int prepare_vlan_egress_filters_sp_tag(struct dsa_switch *ds, uint8_t port, uint16_t vid, bool untagged)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = IDX_INVAL;
+	int filter_1 = IDX_INVAL;
+	struct mxl862xx_priv *priv = ds->priv;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.egress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* First populate the fixed block of rules which should be executed finally after
+	 * VID specific filtering. The final rules (not related to VID)
+	 * are placed at the end of the block. */
+
+	//Entry 4: only outer tag (SP tag), no PVID  DISCARD
+	if (untagged) {
+		memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+		vlan_cfg.extended_vlan_block_id =
+			priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	   vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 1;
+		vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+		vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+		if (ret) {
+			dev_err(priv->dev,
+				"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+				__func__, port, vlan_cfg.entry_index,
+				vlan_cfg.extended_vlan_block_id);
+			return ret;
+		}
+
+		priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx =
+			vlan_cfg.entry_index;
+	}
+
+	//Entry 3: there is any other inner tag -> discard upstream traffic
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =	MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx =
+		vlan_cfg.entry_index;
+
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.egress_vlan_block_info.filters_max - 3;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	/* VID specific entries must be processed before the final entries,
+	 * so putting them at the beginnig of the block */
+	ret = get_vlan_vid_filters_idx(priv, port, false, vid, &filter_0, &filter_1, &idx);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d couldn't get idx for VID specific filters for VID:%d and  block ID:%d\n",
+			__func__, port, vid, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* Set of dynamic rules that depend on VID.
+	 * The number of rules depends on the number of handled vlans */
+
+	// Entry 0 : ACCEPT VLAN tags that are matching  VID. Outer and Inner tags are present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[port]
+				.vlan.egress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.vid_enable = true;
+	vlan_cfg.filter.inner_vlan.vid_val = vid;
+
+	if (untagged) {
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_2_TAG;
+	} else {
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_1_TAG;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+	/* mark as unused */
+	priv->port_info[port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = IDX_INVAL;
+
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].used = true;
+	priv->port_info[port].vlan.egress_vlan_block_info.vlans[idx].untagged = untagged;
+
+	return ret;
+}
+
+
+static int prepare_vlan_egress_filters_off_sp_tag_cpu(struct dsa_switch *ds, uint8_t cpu_port)
+{
+	int ret = -EINVAL;
+	struct mxl862xx_priv *priv = ds->priv;
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+	struct mxl862xx_extended_vlan_block_info *block_info =
+		&priv->port_info[cpu_port].vlan.egress_vlan_block_info;
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv, block_info);
+	if (ret)
+		return ret;
+
+	// Entry last - 1  : Outer and Inner tags are present.
+	// Transparent mode, no tag modifications
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+
+	vlan_cfg.entry_index = block_info->filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, cpu_port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	// Entry last : Outer tag is present.
+	// Transparent mode, no tag modifications
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id = block_info->block_id;
+
+	vlan_cfg.entry_index = block_info->filters_max - 1;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, cpu_port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	block_info->final_filters_idx = vlan_cfg.entry_index;
+
+	return ret;
+}
+
+static int prepare_vlan_egress_filters_sp_tag_cpu(struct dsa_switch *ds, uint8_t cpu_port, uint16_t vid, bool untagged)
+{
+	int ret = -EINVAL;
+	struct mxl862xx_priv *priv = ds->priv;
+	int filter_0 = -1;
+	int filter_1 = -1;
+	uint16_t idx = 0;
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[cpu_port].vlan.egress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* Populate the  block of rules related to VID */
+
+	/* VID specific entries must be processed before the final entries,
+	 * so putting them at the beginnig of the block */
+	ret = get_vlan_vid_filters_idx(priv, cpu_port, false, vid, &filter_0, &filter_1, &idx);
+
+	if (ret)
+		return ret;
+
+	// Entry 0 : Outer and Inner tags are present. If user port is untagged
+	// remove inner tag if the outer tag is matching the user port
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[cpu_port].vlan.egress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[cpu_port]
+				.vlan.egress_vlan_block_info.vid_filters_idx++;
+
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_FILTER;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.vid_enable = true;
+	vlan_cfg.filter.inner_vlan.vid_val = vid;
+
+	if (untagged) {
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_REMOVE_2_TAG;
+		vlan_cfg.treatment.add_outer_vlan = true;
+		vlan_cfg.treatment.outer_vlan.vid_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_VID;
+		vlan_cfg.treatment.outer_vlan.tpid = MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.outer_vlan.priority_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_OUTER_PRORITY;
+		vlan_cfg.treatment.outer_vlan.dei = MXL862XX_EXTENDEDVLAN_TREATMENT_INNER_DEI;
+	}	else {
+		vlan_cfg.treatment.remove_tag = MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for egress extended VLAN block ID:%d\n",
+			__func__, cpu_port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[cpu_port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+   /* mark as unused */
+	priv->port_info[cpu_port]
+		.vlan.egress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = IDX_INVAL;
+
+	priv->port_info[cpu_port].vlan.egress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[cpu_port].vlan.egress_vlan_block_info.vlans[idx].untagged = untagged;
+	priv->port_info[cpu_port].vlan.egress_vlan_block_info.vlans[idx].used = true;
+
+	return ret;
+
+}
+
+static int prepare_vlan_ingress_filters_sp_tag(struct dsa_switch *ds, uint8_t port, uint16_t vid)
+{
+	struct dsa_port *dp = dsa_to_port(ds, port);
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+	struct mxl862xx_priv *priv = ds->priv;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.ingress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* First populate the fixed block of rules which should be executed finally after
+	 * VID specific filtering. The final rules (not related to VID)
+	 * are placed at the end of the block. */
+
+	//Entry 6 no other rule applies Outer tag default Inner tag  not present DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.ingress_vlan_block_info.filters_max - 1;
+	vlan_cfg.filter.outer_vlan.type =
+		MXL862XX_EXTENDEDVLAN_FILTER_TYPE_DEFAULT;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	//Entry 5 no other rule applies Outer tag default Inner tag  present DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.ingress_vlan_block_info.filters_max - 2;
+	vlan_cfg.filter.outer_vlan.type =
+		MXL862XX_EXTENDEDVLAN_FILTER_TYPE_DEFAULT;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	// Entry 4  untagged pkts. If there's PVID accept and add PVID tag, otherwise reject
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.ingress_vlan_block_info.filters_max - 3;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	if (!priv->port_info[port].vlan.pvid) {
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+	} else {
+		vlan_cfg.treatment.add_outer_vlan = true;
+		vlan_cfg.treatment.outer_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.outer_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.outer_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.outer_vlan.priority_val = 0;
+		vlan_cfg.treatment.outer_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+		vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+		vlan_cfg.treatment.add_inner_vlan = true;
+		vlan_cfg.treatment.inner_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.inner_vlan.vid_val =
+			priv->port_info[port].vlan.pvid;
+		vlan_cfg.treatment.inner_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.inner_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.inner_vlan.priority_val = 0;
+		vlan_cfg.treatment.inner_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add PVID entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx =
+		vlan_cfg.entry_index;
+
+	// Entry 3 : Only Outer tag present : not matching  DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.ingress_vlan_block_info.filters_max - 4;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add DISCARD entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx =
+		vlan_cfg.entry_index;
+
+	// Entry 2 : Outer and Inner VLAN tag present : not matching  DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index = priv->port_info[port].vlan.ingress_vlan_block_info.filters_max - 5;
+
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add DISCARD entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx = vlan_cfg.entry_index;
+
+	/* VID specific filtering rules which should be executed first before final ones.
+	 * Storing starts at the beginning of the block. */
+
+	ret = get_vlan_vid_filters_idx(priv, port, true, vid, &filter_0, &filter_1, &idx);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d couldn't get idx for VID specific filters for VID:%d and  block ID:%d\n",
+			__func__, port, vid, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	// Entry 0 : Outer and Inner VLAN tag present :  matching  ACCEPT
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[port]
+				.vlan.ingress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+	vlan_cfg.treatment.outer_vlan.tpid = MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei = MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for block_id:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.ingress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+	// Entry 1 : Only Outer tags is present : matching  ACCEPT
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_1 >= 0 ?
+			filter_1 :
+			priv->port_info[port]
+				.vlan.ingress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.add_outer_vlan = true;
+	vlan_cfg.treatment.outer_vlan.vid_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+	vlan_cfg.treatment.outer_vlan.vid_val = dsa_tag_8021q_standalone_vid(dp);
+	vlan_cfg.treatment.outer_vlan.tpid = MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+	vlan_cfg.treatment.outer_vlan.priority_mode = MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+	vlan_cfg.treatment.outer_vlan.priority_val = 0;
+	vlan_cfg.treatment.outer_vlan.dei = MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add entry:%d for block_id:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.ingress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = vlan_cfg.entry_index;
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[port].vlan.ingress_vlan_block_info.vlans[idx].used = true;
+
+	return ret;
+}
+
+
+static int prepare_vlan_ingress_filters_sp_tag_cpu(struct dsa_switch *ds, uint8_t port, uint8_t cpu_port)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+	struct mxl862xx_priv *priv = ds->priv;
+	uint16_t bridge_port_cpu = priv->port_info[port].bridge_port_cpu;
+	struct dsa_port *dp = dsa_to_port(ds, port);
+	uint16_t vid = dsa_tag_8021q_standalone_vid(dp);
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[cpu_port].vlan.ingress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* VID specific filtering rules which should be executed first before final ones.
+	 * Storing starts at the beginning of the block. */
+	ret = get_vlan_vid_filters_idx(priv, cpu_port, true, vid, &filter_0, &filter_1, &idx);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d couldn't get idx for VID specific filters for VID:%d and  block ID:%d\n",
+			__func__, cpu_port, vid, vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	// Entry 0 : Outer and Inner VLAN tag present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[cpu_port].vlan.ingress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[cpu_port]
+				.vlan.ingress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.reassign_bridge_port = true;
+	vlan_cfg.treatment.new_bridge_port_id = bridge_port_cpu;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: cpu_port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, cpu_port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[cpu_port]
+		.vlan.ingress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+	// Entry 1 : Only Outer tags is present
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[cpu_port].vlan.ingress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_1 >= 0 ?
+			filter_1 :
+			priv->port_info[cpu_port]
+				.vlan.ingress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.reassign_bridge_port = true;
+	vlan_cfg.treatment.new_bridge_port_id = bridge_port_cpu;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: cpu_port:%d failed to add entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, cpu_port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[cpu_port]
+		.vlan.ingress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = vlan_cfg.entry_index;
+
+	priv->port_info[cpu_port].vlan.ingress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[cpu_port].vlan.ingress_vlan_block_info.vlans[idx].used = true;
+
+	return ret;
+}
+
+static int prepare_vlan_ingress_filters(struct dsa_switch *ds, uint8_t port, uint16_t vid)
+{
+	int ret = -EINVAL;
+	uint16_t idx = 0;
+	/* negative values if not found */
+	int filter_0 = -1;
+	int filter_1 = -1;
+	struct mxl862xx_priv *priv = ds->priv;
+
+	struct mxl862xx_extendedvlan_config vlan_cfg = { };
+	ret = mxl862xx_allocate_extended_vlan_block(priv,
+		&priv->port_info[port].vlan.ingress_vlan_block_info);
+	if (ret)
+		return ret;
+
+	/* First populate the block with set of rules which should be executed finally after
+	 * VID specific filtering. The final rules (not related to VID) are placed on the end of the block. The number of
+	 * rules is fixed  per port. Order of execution  is important. To avoid static reservations they are
+	 * stored in reversed order starting from the end of the block */
+
+	//Entry 6 no other rule applies Outer tag default Inner tag  not present DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index =
+		priv->port_info[port]
+			.vlan.ingress_vlan_block_info.final_filters_idx--;
+	vlan_cfg.filter.outer_vlan.type =
+		MXL862XX_EXTENDEDVLAN_FILTER_TYPE_DEFAULT;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add default DISCARD entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	//Entry 5 no other rule applies Outer tag default Inner tag  present DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index =
+		priv->port_info[port]
+			.vlan.ingress_vlan_block_info.final_filters_idx--;
+	vlan_cfg.filter.outer_vlan.type =
+		MXL862XX_EXTENDEDVLAN_FILTER_TYPE_DEFAULT;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret) {
+		dev_err(priv->dev,
+			"%s: Port:%d failed to add default DISCARD entry:%d for ingress extended VLAN block ID:%d\n",
+			__func__, port, vlan_cfg.entry_index,
+			vlan_cfg.extended_vlan_block_id);
+		return ret;
+	}
+
+	// Entry 4  untagged pkts. If there's PVID accept and add PVID tag, otherwise reject
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index =
+		priv->port_info[port]
+			.vlan.ingress_vlan_block_info.final_filters_idx--;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	if (!priv->port_info[port].vlan.pvid) {
+		vlan_cfg.treatment.remove_tag =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+	} else {
+		vlan_cfg.treatment.add_outer_vlan = true;
+		vlan_cfg.treatment.outer_vlan.vid_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_VID_VAL;
+		vlan_cfg.treatment.outer_vlan.tpid =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_8021Q;
+		vlan_cfg.treatment.outer_vlan.priority_mode =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_PRIORITY_VAL;
+		vlan_cfg.treatment.outer_vlan.priority_val = 0;
+		vlan_cfg.treatment.outer_vlan.dei =
+			MXL862XX_EXTENDEDVLAN_TREATMENT_DEI_0;
+		vlan_cfg.treatment.outer_vlan.vid_val =
+			priv->port_info[port].vlan.pvid;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	// Entry 3 : Only Outer tag present : not matching  DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index =
+		priv->port_info[port]
+			.vlan.ingress_vlan_block_info.final_filters_idx--;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	// Entry 2 : Outer and Inner VLAN tag present : not matching  DISCARD
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	vlan_cfg.entry_index =
+		priv->port_info[port]
+			.vlan.ingress_vlan_block_info.final_filters_idx--;
+
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_DISCARD_UPSTREAM;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* VID specific filtering rules which should be executed first before final ones.
+	 * Storing starts at the beginning of the block. */
+
+	ret = get_vlan_vid_filters_idx(priv, port, true, vid, &filter_0, &filter_1, &idx);
+	if (ret)
+		return ret;
+
+	// Entry 0 : Outer and Inner VLAN tag present :  matching  ACCEPT
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_0 >= 0 ?
+			filter_0 :
+			priv->port_info[port]
+				.vlan.ingress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.ingress_vlan_block_info.vlans[idx]
+		.filters_idx[0] = vlan_cfg.entry_index;
+
+	// Entry 1 : Only Outer tag is present : matching  ACCEPT
+	memset(&vlan_cfg, 0, sizeof(vlan_cfg));
+	vlan_cfg.extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+	/* if found recycled entry reuse it, otherwise create new one */
+	vlan_cfg.entry_index =
+		filter_1 >= 0 ?
+			filter_1 :
+			priv->port_info[port]
+				.vlan.ingress_vlan_block_info.vid_filters_idx++;
+	vlan_cfg.filter.outer_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NORMAL;
+	vlan_cfg.filter.outer_vlan.vid_enable = true;
+	vlan_cfg.filter.outer_vlan.vid_val = vid;
+	vlan_cfg.filter.inner_vlan.type = MXL862XX_EXTENDEDVLAN_FILTER_TYPE_NO_TAG;
+	vlan_cfg.treatment.remove_tag =
+		MXL862XX_EXTENDEDVLAN_TREATMENT_NOT_REMOVE_TAG;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_EXTENDEDVLAN_SET, vlan_cfg);
+	if (ret)
+		return ret;
+
+	/* store VLAN filtering rules ID's (for VLAN delete, if needed) */
+	priv->port_info[port]
+		.vlan.ingress_vlan_block_info.vlans[idx]
+		.filters_idx[1] = vlan_cfg.entry_index;
+
+	priv->port_info[port].vlan.ingress_vlan_block_info.vlans[idx].vid = vid;
+	priv->port_info[port].vlan.ingress_vlan_block_info.vlans[idx].used = true;
+
+	return ret;
+}
+
+static int mxl862xx_port_vlan_add(struct dsa_switch *ds, int port,
+                                  const struct switchdev_obj_port_vlan *vlan,
+                                  struct netlink_ext_ack *extack)
+{
+	int ret = -EINVAL;
+	struct mxl862xx_priv *priv = ds->priv;
+	struct mxl862xx_bridge_port_config br_port_cfg = { };
+	bool untagged = vlan->flags & BRIDGE_VLAN_INFO_UNTAGGED;
+	bool pvid = vlan->flags & BRIDGE_VLAN_INFO_PVID;
+	uint8_t cpu_port = priv->hw_info->cpu_port;
+	bool vlan_sp_tag = (priv->port_info[cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862_8021Q);
+	bool standalone_port = false;
+	uint16_t vid = vlan->vid;
+
+	if (port < 0 || port >= MAX_PORTS) {
+		dev_err(priv->dev, "invalid port: %d\n", port);
+		NL_SET_ERR_MSG_MOD(extack, "Port out of range");
+		return ret;
+	}
+
+	if (!((struct dsa_port *)dsa_to_port(ds, port))) {
+		dev_err(ds->dev, "%s:  port:%d is out of DSA domain\n", __func__, port);
+		NL_SET_ERR_MSG_MOD(extack, "Port out of DSA domain");
+		return ret;
+	}
+
+	/* standalone port */
+	if ((priv->port_info[port].bridge == NULL) && (!dsa_is_cpu_port(ds, port)))
+		standalone_port = true;
+
+	if (vid == 0)
+		return ret;
+
+	/* If this is request to set pvid, just overwrite it as there may be
+	 * only one pid per port */
+	if (pvid)
+		priv->port_info[port].vlan.pvid = vid;
+	/* If this is pvid disable request, check if there's already matching vid
+	 * and only then disable it. If vid doesn't match active pvid, don't touch it */
+	else {
+		if (priv->port_info[port].vlan.pvid == vid)
+			priv->port_info[port].vlan.pvid = 0;
+	}
+
+	/* Check if there's enough room for ingress and egress rules */
+	if ((priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx -
+			priv->port_info[port].vlan.ingress_vlan_block_info.vid_filters_idx) <
+			(priv->port_info[port].vlan.ingress_vlan_block_info.entries_per_vlan)) {
+
+		dev_err(ds->dev,
+			"%s: Port:%d vlan:%d. Number of avaliable ingress entries too low. Required:%d  ff_idx:%d vf_idx:%d .\n",
+			__func__, port, vid,
+			priv->port_info[port].vlan.ingress_vlan_block_info.entries_per_vlan,
+			priv->port_info[port].vlan.ingress_vlan_block_info.final_filters_idx,
+			priv->port_info[port].vlan.ingress_vlan_block_info.vid_filters_idx);
+
+		ret = -ENOSPC;
+		NL_SET_ERR_MSG_MOD(extack, "Reached max number of VLAN ingress filter entries per port");
+		return ret;
+	}
+
+	if ((priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx -
+			priv->port_info[port].vlan.egress_vlan_block_info.vid_filters_idx) <
+			(priv->port_info[port].vlan.egress_vlan_block_info.entries_per_vlan)) {
+
+		dev_err(ds->dev,
+			"%s: Port:%d vlan:%d. Number of avaliable egress entries too low. Required:%d  ff_idx:%d vf_idx:%d .\n",
+			__func__, port, vid,
+			priv->port_info[port].vlan.egress_vlan_block_info.entries_per_vlan,
+			priv->port_info[port].vlan.egress_vlan_block_info.final_filters_idx,
+			priv->port_info[port].vlan.egress_vlan_block_info.vid_filters_idx);
+
+		ret = -ENOSPC;
+		NL_SET_ERR_MSG_MOD(extack, "Reached max number of VLAN egress filter entries per port");
+		return ret;
+	}
+
+	/* Although 4-byte vlan special tagging handling is similar to 8 byte MxL tagging,
+	 * keep VLAN rules separate for better readibility */
+	if (vlan_sp_tag) {
+		if (!dsa_is_cpu_port(ds, port)) {
+		/* Special rules for CPU port based on user port id */
+			ret = prepare_vlan_ingress_filters_sp_tag_cpu(ds, port, cpu_port);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare ingress filters for VLAN:%d with vlan_filtering disabled\n",
+					__func__, port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare ingress filters with vlan_filtering disabled");
+				return ret;
+			}
+			ret = prepare_vlan_egress_filters_sp_tag_cpu(ds, cpu_port, vid, untagged);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare egress filters for VLAN:%d with vlan_filtering disabled\n",
+					__func__, cpu_port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare egress filters with vlan_filtering disabled");
+				return ret;
+			}
+			/* vlan_filtering disabled */
+			/* skiping this configuration for vlan_sp_tag/cpu port as it requires special rules defined above */
+			if (!priv->port_info[port].vlan.filtering) {
+				dev_info(ds->dev,
+					"%s: port:%d setting VLAN:%d with vlan_filtering disabled\n",
+					__func__, port, vid);
+				ret = prepare_vlan_ingress_filters_off_sp_tag(ds, port, vid);
+				if (ret) {
+					dev_err(ds->dev,
+						"%s: Port:%d failed to prepare ingress filters for VLAN:%d with vlan_filtering disabled\n",
+						__func__, port, vid);
+					NL_SET_ERR_MSG_MOD(extack, "Failed to prepare ingress filters with vlan_filtering disabled");
+					return ret;
+				}
+
+				ret = prepare_vlan_egress_filters_off_sp_tag(ds, port, vid, untagged);
+				if (ret) {
+					dev_err(ds->dev,
+						"%s: Port:%d failed to prepare egress filters for VLAN:%d with vlan_filtering disabled\n",
+						__func__, port, vid);
+					NL_SET_ERR_MSG_MOD(extack, "Failed to prepare egress filters with vlan_filtering disabled");
+					return ret;
+				}
+			}
+			/* vlan_filtering enabled */
+			else {
+				/* special rules for the CPU port are already defined,
+				 * so define only the rules for user ports */
+				ret = prepare_vlan_ingress_filters_sp_tag(ds, port, vid);
+				if (ret) {
+					dev_err(ds->dev,
+						"%s: Port:%d failed to prepare ingress filters for VLAN:%d\n",
+						__func__, port, vid);
+					NL_SET_ERR_MSG_MOD(extack, "Failed to prepare ingress filters for VLAN");
+					return ret;
+				}
+
+				ret = prepare_vlan_egress_filters_sp_tag(ds, port, vid, untagged);
+				if (ret) {
+					dev_err(ds->dev,
+						"%s: Port:%d failed to prepare egress filters for VLAN:%d\n",
+						__func__, port, vid);
+					NL_SET_ERR_MSG_MOD(extack, "Failed to prepare egress filters for VLAN");
+					return ret;
+				}
+			}
+		} else {
+			/* CPU port. This else block handles explicit request for adding
+			 * VLAN to CPU port. Only egress rule requires reconfiguration.*/
+			ret = prepare_vlan_egress_filters_sp_tag_cpu(ds, cpu_port, vid, untagged);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare egress filters for VLAN:%d with vlan_filtering disabled\n",
+					__func__, cpu_port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare egress filters with vlan_filtering disabled");
+				return ret;
+			}
+		}
+
+		/* CPU port is explicitely added by the DSA framework to the new vlans.
+		   Apply block_id with filtering rules defined while processing user ports
+			For 8021q special tag mode cpu port rules may change because of new ports added,
+			so they need to be reloaded */
+		{
+			struct mxl862xx_ctp_port_config ctp_param = { };
+
+			ctp_param.logical_port_id = cpu_port + 1;
+			ctp_param.mask = MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN |
+					     MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN;
+			ctp_param.egress_extended_vlan_enable = true;
+			ctp_param.egress_extended_vlan_block_id =
+			priv->port_info[cpu_port].vlan.egress_vlan_block_info.block_id;
+			ctp_param.ingress_extended_vlan_enable = true;
+			ctp_param.ingress_extended_vlan_block_id =
+				priv->port_info[cpu_port].vlan.ingress_vlan_block_info.block_id;
+
+			ret = MXL862XX_API_WRITE(priv, MXL862XX_CTP_PORTCONFIGSET, ctp_param);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: CTP port %d config failed on port config set with %d\n",
+					__func__, cpu_port, ret);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to configure VLAN for cpu port");
+				return ret;
+			}
+		}
+	} else {
+		/* VLAN rules for 8 byte MxL tagging*/
+		/* vlan_filtering disabled */
+		/* skiping this configuration for vlan_sp_tag/cpu port as it requires special rules defined above */
+		if (!priv->port_info[port].vlan.filtering) {
+			ret = prepare_vlan_ingress_filters_off(priv, port, vid);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare ingress filters for VLAN:%d with vlan_filtering disabled\n",
+					__func__, port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare ingress filters with vlan_filtering disabled");
+				return ret;
+			}
+
+			ret = prepare_vlan_egress_filters_off(priv, port, vid, untagged);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare egress filters for VLAN:%d with vlan_filtering disabled\n",
+					__func__, port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare egress filters with vlan_filtering disabled");
+				return ret;
+			}
+		}
+		/* vlan_filtering enabled */
+		else {
+			ret = prepare_vlan_ingress_filters(ds, port, vid);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare ingress filters for VLAN:%d\n",
+					__func__, port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare ingress filters for VLAN");
+				return ret;
+			}
+			ret = prepare_vlan_egress_filters(ds, port, vid, untagged);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: Port:%d failed to prepare egress filters for VLAN:%d\n",
+					__func__, port, vid);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to prepare egress filters for VLAN");
+				return ret;
+			}
+		}
+
+		/* CPU port is explicitely added by the DSA framework to new vlans */
+		if (dsa_is_cpu_port(ds, port)) {
+			struct mxl862xx_ctp_port_config ctp_param = { };
+
+			ctp_param.logical_port_id = port + 1;
+			ctp_param.mask = MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN |
+					     MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN;
+			ctp_param.egress_extended_vlan_enable = true;
+			ctp_param.egress_extended_vlan_block_id =
+				priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+			ctp_param.ingress_extended_vlan_enable = true;
+			ctp_param.ingress_extended_vlan_block_id =
+				priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+
+			ret = MXL862XX_API_WRITE(priv, MXL862XX_CTP_PORTCONFIGSET, ctp_param);
+			if (ret) {
+				dev_err(ds->dev,
+					"%s: CTP port %d config failed on port config set with %d\n",
+					__func__, port, ret);
+				NL_SET_ERR_MSG_MOD(extack, "Failed to configure VLAN for cpu port");
+				return ret;
+			}
+
+			return ret;
+		}
+	}
+
+	/* Update bridge port */
+	br_port_cfg.bridge_port_id = port + 1;
+	br_port_cfg.mask |= MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_VLAN |
+			     MXL862XX_BRIDGE_PORT_CONFIG_MASK_INGRESS_VLAN |
+				  MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_SRC_MAC_LEARNING;
+	br_port_cfg.egress_extended_vlan_enable = true;
+	br_port_cfg.egress_extended_vlan_block_id =
+		priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+	br_port_cfg.ingress_extended_vlan_enable = true;
+	br_port_cfg.ingress_extended_vlan_block_id =
+		priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+
+	/* Disable MAC learning for standalone ports. */
+	br_port_cfg.src_mac_learning_disable =
+				(standalone_port) ? true : false;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGEPORT_CONFIGSET, br_port_cfg);
+	if (ret) {
+		dev_err(ds->dev,
+			"%s: Bridge port configuration for port %d failed with %d\n",
+			__func__, port, ret);
+		NL_SET_ERR_MSG_MOD(extack, "Bridge port configuration for VLAN failed");
+		return ret;
+	}
+
+	return ret;
+}
+
+
+static int mxl862xx_port_vlan_del(struct dsa_switch *ds, int port,
+				  const struct switchdev_obj_port_vlan *vlan)
+{
+	int ret = -EINVAL;
+	int dir;
+	struct mxl862xx_priv *priv = ds->priv;
+	uint16_t vid = vlan->vid;
+
+	for (dir = 0 ; dir < 2 ; dir++) {
+		struct mxl862xx_extended_vlan_block_info *block_info = (dir == 0)
+			? &priv->port_info[port].vlan.ingress_vlan_block_info
+			: &priv->port_info[port].vlan.egress_vlan_block_info;
+		char *dir_txt = (dir == 0)	? "ingress" : "egress";
+		int16_t entry_idx;
+		int vlan_idx, x;
+		u16 block_id = block_info->block_id;
+		/* Indicator of the last dynamic vid related entry being processed.
+		 * Required for cleanup of static rules at the end of the block. */
+		bool last_vlan = false;
+		bool vlan_found = false;
+
+		/* check if vlan is present */
+		for (vlan_idx = 0; vlan_idx < MAX_VLANS; vlan_idx++) {
+			if ((block_info->vlans[vlan_idx].vid == vid)
+					&& block_info->vlans[vlan_idx].used)
+				vlan_found = true;
+
+			if (vlan_idx == MAX_VLANS - 1)
+				last_vlan = true;
+
+			if (vlan_found)
+				break;
+		}
+
+		if (!vlan_found) {
+			dev_err(ds->dev, "%s: Port:%d VLAN:%d not found (%s)\n", __func__, port, vid, dir_txt);
+			goto static_rules_cleanup;
+		}
+
+		/* cleanup */
+		for (x = 0; x < VID_RULES ; x++) {
+			entry_idx = block_info->vlans[vlan_idx].filters_idx[x];
+			if (entry_idx != IDX_INVAL) {
+				ret = deactivate_vlan_filter_entry(ds, block_id, entry_idx);
+				if (ret)
+					return ret;
+			}
+		}
+
+		/* cleanup of the vlan record in the port vlan inventory */
+		block_info->vlans[vlan_idx].vid = 0;
+		block_info->vlans[vlan_idx].used = false;
+
+		/* find the first free slot for storing recycled filter entries */
+		for (x = 0; x < MAX_VLANS; x++) {
+			if (!(block_info->filter_entries_recycled[x].valid)) {
+				block_info->filter_entries_recycled[x].filters_idx[0] = block_info->vlans[vlan_idx].filters_idx[0];
+				block_info->filter_entries_recycled[x].filters_idx[1] = block_info->vlans[vlan_idx].filters_idx[1];
+				block_info->filter_entries_recycled[x].valid = true;
+				block_info->vlans[vlan_idx].filters_idx[0] = IDX_INVAL;
+				block_info->vlans[vlan_idx].filters_idx[1] = IDX_INVAL;
+				break;
+			}
+
+			if (x == MAX_VLANS - 1) {
+				ret = -ENOSPC;
+				dev_err(ds->dev,
+					"%s: Port:%d no free slots for recycled %s filter entries\n",
+					__func__, port, dir_txt);
+				return ret;
+			}
+		}
+
+static_rules_cleanup:
+		/* If this is the last vlan entry or no entries left,
+		 * remove static entries (placed at the end of the block) */
+		if (last_vlan) {
+			for (entry_idx = block_info->final_filters_idx; entry_idx < block_info->filters_max ; entry_idx++) {
+				ret = deactivate_vlan_filter_entry(ds, block_id, entry_idx);
+				if (ret)
+					return ret;
+			}
+			/* Entries cleared, so point out to the end */
+			block_info->final_filters_idx = entry_idx;
+		}
+	}
+
+	return 0;
+}
+
+
+static int mxl862xx_isolate_port(struct dsa_switch *ds, int port)
+{
+	struct mxl862xx_bridge_alloc param = {};
+	struct mxl862xx_priv *priv = ds->priv;
+	uint8_t cpu_port = priv->hw_info->cpu_port;
+	bool vlan_sp_tag = (priv->port_info[cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862_8021Q);
+	int ret;
+
+	if (priv->port_info[port].isolated)
+		return 0;
+
+	ret = MXL862XX_API_READ(priv, MXL862XX_BRIDGE_ALLOC, param);
+	if (ret) {
+		dev_err(ds->dev, "failed to allocate a bridge for port %d\n", port);
+		return ret;
+	}
+
+	priv->port_info[port].bridge_id = param.bridge_id;
+	priv->port_info[port].bridge = NULL;
+	ret = mxl862xx_update_bridge_conf_port(ds, port, NULL, 1);
+	if (ret) {
+		dev_err(ds->dev, "failed to add port %d to bridge %d\n", port, param.bridge_id);
+		return ret;
+	}
+
+	/* for VLAN special tagging mode add port to vlan 1 to apply also
+	 * the special tag handling filters */
+	if (vlan_sp_tag) {
+		/* set port vlan 1 untagged */
+		struct switchdev_obj_port_vlan vlan;
+		uint16_t vid = 1;
+		bool filtering_prev = priv->port_info[port].vlan.filtering;
+		priv->port_info[port].vlan.filtering = true;
+		vlan.flags = BRIDGE_VLAN_INFO_UNTAGGED | BRIDGE_VLAN_INFO_PVID;
+		vlan.vid = vid;
+		ret = mxl862xx_port_vlan_add(ds, port, &vlan, NULL);
+		if (ret) {
+			dev_err(ds->dev,
+				"%s: adding port %d, to vlan:%d failed with ret %d\n",
+				__func__, port, vlan.vid, ret);
+		}
+		priv->port_info[port].vlan.filtering = filtering_prev;
+	}
+
+	if (!ret)
+		priv->port_info[port].isolated = true;
+
+	return ret;
+}
+
+static void mxl862xx_deisolate_port(struct dsa_switch *ds, u8 port)
+{
+	struct mxl862xx_bridge_alloc bridge_alloc = { };
+	struct mxl862xx_priv *priv = ds->priv;
+	uint8_t cpu_port = priv->hw_info->cpu_port;
+	bool vlan_sp_tag = (priv->port_info[cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862_8021Q);
+	int ret;
+
+	if (!priv->port_info[port].isolated)
+		return;
+
+	ret = mxl862xx_update_bridge_conf_port(ds, port, NULL, 0);
+	if (ret) {
+		dev_err(ds->dev, "failed to remove port %d from bridge\n", port);
+		return;
+	}
+
+	bridge_alloc.bridge_id = priv->port_info[port].bridge_id;
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGE_FREE, bridge_alloc);
+	if (ret) {
+		dev_err(ds->dev, "failed to free bridge %d\n", bridge_alloc.bridge_id);
+		return;
+	}
+
+	/* For VLAN special tagging mode isolated port is assigned to VLAN 1
+	 * to apply also the special tag handling filters. Now for deisolation
+	 * VLAN 1 must be unassigned */
+	if (vlan_sp_tag) {
+		struct switchdev_obj_port_vlan vlan;
+		uint16_t vid = 1;
+		int i;
+
+		vlan.flags = BRIDGE_VLAN_INFO_UNTAGGED | BRIDGE_VLAN_INFO_PVID;
+		vlan.vid = vid;
+		/* Removes vid dependant 'dynamic' rules */
+		ret = mxl862xx_port_vlan_del(ds, port, &vlan);
+		if (ret) {
+			dev_err(ds->dev,
+				"%s: deleting port %d, from vlan:%d failed with ret %d\n",
+				__func__, port, vid, ret);
+		}
+
+		/* Clear/deactivate 'static' set of filtering rules, placed at the end of the block */
+		for (i = 0 ; i < 2 ; i++) {
+			uint16_t j, start_idx, stop_idx, block_id;
+			struct mxl862xx_extended_vlan_block_info *block_info = (i == 0)
+				? &priv->port_info[port].vlan.ingress_vlan_block_info
+				: &priv->port_info[port].vlan.egress_vlan_block_info;
+
+			block_id = block_info->block_id;
+			stop_idx = block_info->filters_max;
+			start_idx = block_info->final_filters_idx;
+
+			for (j = start_idx ; j < stop_idx ; j++) {
+				ret = deactivate_vlan_filter_entry(ds, block_id, j);
+				if (ret)
+					return;
+			}
+			/* Entries cleared, so point out to the end */
+			block_info->final_filters_idx = j;
+		}
+	}
+
+	priv->port_info[port].isolated = false;
+}
+
+static int mxl862xx_find_bridge_id(struct dsa_switch *ds, struct net_device *bridge)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	u8 i;
+
+	if (bridge)
+		for (i = 0; i < priv->hw_info->phy_ports; i++)
+			if (priv->port_info[i].bridge == bridge)
+				return priv->port_info[i].bridge_id;
+
+	return 0;
+}
+
+static int mxl862xx_mac_learning(struct dsa_switch *ds, int port, bool enable)
+{
+	struct mxl862xx_bridge_port_config param = {
+		.mask = MXL862XX_BRIDGE_PORT_CONFIG_MASK_MC_SRC_MAC_LEARNING,
+		.bridge_port_id = DSA_MXL_PORT(port),
+		.src_mac_learning_disable = !enable,
+	};
+	int ret;
+
+	ret = MXL862XX_API_WRITE(ds->priv, MXL862XX_BRIDGEPORT_CONFIGSET, param);
+	if (ret)
+		dev_err(ds->dev, "failed to %s MAC learning on port %d\n",
+			enable ? "enable" : "disable", port);
+	return ret;
+}
+
+static void mxl862xx_set_vlan_filter_limits(struct dsa_switch *ds)
+{
+	u8 i;
+	u16 cpu_ingress_entries;
+	u16 cpu_egress_entries;
+	u16 user_ingress_entries;
+	u16 user_egress_entries;
+	struct mxl862xx_priv *priv = ds->priv;
+	u8 cpu_port = priv->hw_info->cpu_port;
+	struct mxl862xx_port_vlan_info *vlan = &priv->port_info[cpu_port].vlan;
+
+	/* Set limits and indexes required for processing VLAN rules for CPU port */
+
+	/* The calculation of the max number of simultaneously supported VLANS (priv->max_vlans)
+	 * comes from the equation:
+	 *
+	 * MAX_VLAN_ENTRIES = phy_ports * (EGRESS_FINAL_RULES + EGRESS_VID_RULES * priv->max_vlans)
+	 *  + phy_ports * (INGRESS_FINAL_RULES + INGRESS_VID_RULES * priv-> max_vlans)
+	 *  + cpu_ingress_entries + cpu_egress_entries
+	 */
+	if (priv->port_info[cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862_8021Q) {
+		priv->max_vlans = (MAX_VLAN_ENTRIES - priv->hw_info->phy_ports *
+				   (EGRESS_FINAL_RULES + INGRESS_FINAL_RULES + 2) - 3) /
+				  (priv->hw_info->phy_ports *
+				   (EGRESS_VID_RULES + INGRESS_VID_RULES) + 2);
+		/* 2 entries per port and 1 entry for fixed rule */
+		cpu_ingress_entries = priv->hw_info->phy_ports * 2 + 1;
+		/* 2 entries per each vlan and 2 entries for fixed rules */
+		cpu_egress_entries = priv->max_vlans * 2 + 2;
+
+		vlan->ingress_vlan_block_info.entries_per_vlan = 0;
+		vlan->ingress_vlan_block_info.filters_max = cpu_ingress_entries;
+		vlan->egress_vlan_block_info.entries_per_vlan = 2;
+		vlan->egress_vlan_block_info.filters_max = cpu_egress_entries;
+
+		user_ingress_entries = INGRESS_FINAL_RULES + INGRESS_VID_RULES * priv->max_vlans;
+		user_egress_entries = EGRESS_FINAL_RULES + EGRESS_VID_RULES * priv->max_vlans;
+	} else {
+		priv->max_vlans = (MAX_VLAN_ENTRIES - priv->hw_info->phy_ports *
+				(EGRESS_FINAL_RULES + INGRESS_FINAL_RULES) - 1) /
+			(priv->hw_info->phy_ports * (EGRESS_VID_RULES + INGRESS_VID_RULES) + 2);
+		/* 1 entry for fixed rule */
+		cpu_ingress_entries =  1;
+		/* 2 entries per each vlan  */
+		cpu_egress_entries = priv->max_vlans * 2;
+		vlan->ingress_vlan_block_info.entries_per_vlan = 0;
+		vlan->ingress_vlan_block_info.filters_max = cpu_ingress_entries;
+		vlan->egress_vlan_block_info.entries_per_vlan = 2;
+		vlan->egress_vlan_block_info.filters_max = cpu_egress_entries;
+
+		user_ingress_entries = INGRESS_FINAL_RULES + INGRESS_VID_RULES * priv->max_vlans;
+		user_egress_entries = EGRESS_FINAL_RULES + EGRESS_VID_RULES * priv->max_vlans;
+	}
+
+	/* This index is counted backwards */
+	vlan->ingress_vlan_block_info.final_filters_idx =
+		vlan->ingress_vlan_block_info.filters_max - 1;
+	vlan->egress_vlan_block_info.final_filters_idx =
+		vlan->egress_vlan_block_info.filters_max - 1;
+
+	/* Set limits and indexes required for processing VLAN rules for user ports */
+	for (i = 0; i < priv->hw_info->phy_ports; i++) {
+		vlan = &priv->port_info[i].vlan;
+		vlan->ingress_vlan_block_info.entries_per_vlan = INGRESS_VID_RULES;
+		vlan->ingress_vlan_block_info.filters_max = user_ingress_entries;
+		vlan->egress_vlan_block_info.entries_per_vlan = EGRESS_VID_RULES;
+		vlan->egress_vlan_block_info.filters_max = user_egress_entries;
+		/* This index is counted backwards */
+		vlan->ingress_vlan_block_info.final_filters_idx =
+			vlan->ingress_vlan_block_info.filters_max - 1;
+		vlan->egress_vlan_block_info.final_filters_idx =
+			vlan->egress_vlan_block_info.filters_max - 1;
+	}
+	dev_info(ds->dev, "%s: phy_ports:%d, priv->max_vlans: %d, cpu_egress_entries: %d, "
+		 "user_ingress_entries: %d, INGRESS_VID_RULES: %d\n",
+		 __func__, priv->hw_info->phy_ports, priv->max_vlans,
+		 cpu_egress_entries, user_ingress_entries, INGRESS_VID_RULES);
+}
+
+static int mxl862xx_set_ageing_time(struct dsa_switch *ds, unsigned int msecs)
+{
+	struct mxl862xx_cfg param;
+	int ret;
+
+	ret = MXL862XX_API_READ(ds->priv, MXL862XX_COMMON_CFGGET, param);
+	if (ret) {
+		dev_err(ds->dev, "failed to read switch config\n");
+		return ret;
+	}
+
+	param.mac_table_age_timer = MXL862XX_AGETIMER_CUSTOM;
+	param.age_timer = msecs / 1000;
+	ret = MXL862XX_API_WRITE(ds->priv, MXL862XX_COMMON_CFGSET, param);
+	if (ret)
+		dev_err(ds->dev, "failed to set ageing\n");
+
+	return ret;
+}
+
+static int mxl862xx_port_bridge_join(struct dsa_switch *ds, int port, struct dsa_bridge bridge,
+				     bool *tx_fwd_offload, struct netlink_ext_ack *extack)
+
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	uint8_t cpu_port = priv->hw_info->cpu_port;
+	bool vlan_sp_tag = (priv->port_info[cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862_8021Q);
+	int bridge_id;
+	int ret;
+
+	mxl862xx_deisolate_port(ds, port);
+
+	bridge_id = mxl862xx_find_bridge_id(ds, bridge.dev);
+
+	if (bridge_id == 0) {
+		struct mxl862xx_bridge_alloc bridge_alloc = { };
+
+		ret = MXL862XX_API_READ(priv, MXL862XX_BRIDGE_ALLOC, bridge_alloc);
+		if (ret) {
+			dev_err(ds->dev, "failed to allocate new bridge\n");
+			return ret;
+		}
+		priv->port_info[port].bridge_id = bridge_alloc.bridge_id;
+		priv->port_info[port].bridge = bridge.dev;
+	} else {
+		priv->port_info[port].bridge_id = bridge_id;
+		priv->port_info[port].bridge = bridge.dev;
+	}
+
+	ret = mxl862xx_update_bridge_conf_port(ds, port, bridge.dev, 1);
+	if (ret) {
+		dev_err(ds->dev,
+			"%s: bridge port adding failed for port %d, ret %d\n",
+			__func__, port, ret);
+		return ret;
+	}
+
+	if (vlan_sp_tag) {
+		struct mxl862xx_ctp_port_config ctp_param = { };
+		struct mxl862xx_bridge_port_config br_port_cfg = { };
+
+		ret = prepare_vlan_ingress_filters_sp_tag_cpu(ds, port, cpu_port);
+		if (ret)
+			return ret;
+		ret = prepare_vlan_egress_filters_off_sp_tag_cpu(ds, cpu_port);
+		if (ret)
+			return ret;
+		ret = prepare_vlan_ingress_filters_off_sp_tag_no_vid(ds, port);
+		if (ret)
+			return ret;
+		ret = prepare_vlan_egress_filters_off_sp_tag_no_vid(ds, port);
+		if (ret)
+			return ret;
+
+		/* update cpu port */
+		ctp_param.logical_port_id = cpu_port + 1;
+		ctp_param.mask = MXL862XX_CTP_PORT_CONFIG_MASK_EGRESS_VLAN |
+				     MXL862XX_CTP_PORT_CONFIG_MASK_INGRESS_VLAN;
+		ctp_param.egress_extended_vlan_enable = true;
+		ctp_param.egress_extended_vlan_block_id =
+		priv->port_info[cpu_port].vlan.egress_vlan_block_info.block_id;
+		ctp_param.ingress_extended_vlan_enable = true;
+		ctp_param.ingress_extended_vlan_block_id =
+			priv->port_info[cpu_port].vlan.ingress_vlan_block_info.block_id;
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_CTP_PORTCONFIGSET, ctp_param);
+		if (ret) {
+			dev_err(ds->dev,
+				"%s: CTP port %d config failed on port config set with %d\n",
+				__func__, cpu_port, ret);
+			NL_SET_ERR_MSG_MOD(extack, "Failed to configure VLAN for cpu port");
+			return ret;
+		}
+
+		/* Update bridge port */
+		br_port_cfg.bridge_port_id = port + 1;
+		br_port_cfg.mask |= MXL862XX_BRIDGE_PORT_CONFIG_MASK_EGRESS_VLAN |
+			     MXL862XX_BRIDGE_PORT_CONFIG_MASK_INGRESS_VLAN;
+		br_port_cfg.egress_extended_vlan_enable = true;
+		br_port_cfg.egress_extended_vlan_block_id =
+			priv->port_info[port].vlan.egress_vlan_block_info.block_id;
+		br_port_cfg.ingress_extended_vlan_enable = true;
+		br_port_cfg.ingress_extended_vlan_block_id =
+			priv->port_info[port].vlan.ingress_vlan_block_info.block_id;
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGEPORT_CONFIGSET, br_port_cfg);
+		if (ret) {
+			dev_err(ds->dev,
+				"%s: Bridge port configuration for port %d failed with %d\n",
+				__func__, port, ret);
+			NL_SET_ERR_MSG_MOD(extack, "Bridge port configuration for VLAN failed");
+		}
+	}
+
+	return 0;
+}
+
+static void mxl862xx_port_bridge_leave(struct dsa_switch *ds, int port,
+				       struct dsa_bridge bridge)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	struct mxl862xx_bridge_alloc bridge_alloc = {
+		.bridge_id = priv->port_info[port].bridge_id,
+	};
+	unsigned int cpu_port = priv->hw_info->cpu_port;
+	int bridge_id;
+	int ret;
+
+	bridge_id = mxl862xx_find_bridge_id(ds, bridge.dev);
+	ret = mxl862xx_update_bridge_conf_port(ds, port, bridge.dev, 0);
+	if (ret) {
+		dev_err(ds->dev, "failed to remove port %d from bridge\n", port);
+		return;
+	}
+
+	if (priv->bridge_portmap[bridge_id] == BIT(DSA_MXL_PORT(cpu_port))) {
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_BRIDGE_FREE, bridge_alloc);
+		if (ret) {
+			dev_err(ds->dev, "failed to free bridge %d\n", bridge_alloc.bridge_id);
+			return;
+		}
+	}
+
+	mxl862xx_isolate_port(ds, port);
+	priv->port_info[port].vlan.filtering_mode_locked = false;
+}
+
+static int mxl862xx_phy_read_mii_bus(struct mii_bus *bus, int port,
+				     int regnum)
+{
+	return mxl862xx_phy_read_mmd(bus->priv, port, 0, regnum);
+}
+
+static int mxl862xx_phy_write_mii_bus(struct mii_bus *bus, int port,
+				      int regnum, u16 val)
+{
+	return mxl862xx_phy_write_mmd(bus->priv, port, 0, regnum, val);
+}
+
+static int mxl862xx_phy_read_c45_mii_bus(struct mii_bus *bus, int port,
+					 int devadd, int regnum)
+{
+	return mxl862xx_phy_read_mmd(bus->priv, port, devadd, regnum);
+}
+
+static int mxl862xx_phy_write_c45_mii_bus(struct mii_bus *bus, int port,
+					  int devadd, int regnum, u16 val)
+{
+	return mxl862xx_phy_write_mmd(bus->priv, port, devadd, regnum, val);
+}
+
+static int mxl862xx_setup_mdio(struct dsa_switch *ds)
+{
+	struct device *dev = ds->dev;
+	struct mii_bus *bus;
+	static int idx;
+	int ret;
+
+	bus = devm_mdiobus_alloc(dev);
+	if (!bus)
+		return -ENOMEM;
+	bus->priv = ds->priv;
+
+	ds->user_mii_bus = bus;
+	bus->name = KBUILD_MODNAME "-mii";
+	snprintf(bus->id, MII_BUS_ID_SIZE, KBUILD_MODNAME "-%d", idx++);
+	bus->read_c45 = mxl862xx_phy_read_c45_mii_bus;
+	bus->write_c45 = mxl862xx_phy_write_c45_mii_bus;
+	bus->read = mxl862xx_phy_read_mii_bus;
+	bus->write = mxl862xx_phy_write_mii_bus;
+	bus->parent = dev;
+	bus->phy_mask = ~ds->phys_mii_mask;
+
+	ret = devm_mdiobus_register(dev, bus);
+	if (ret)
+		dev_err(dev, "failed to register MDIO bus: %d\n", ret);
+
+	return ret;
+}
+
+static int mxl862xx_setup(struct dsa_switch *ds)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	unsigned int cpu_port = priv->hw_info->cpu_port;
+	int ret;
+	u8 i;
+
+	ret = mxl862xx_setup_mdio(ds);
+	if (ret) {
+		dev_err(ds->dev, "failed to setup the mdio bus\n");
+		return ret;
+	}
+
+	/* trigger software reset */
+	ret = mxl862xx_mmd_write(ds, 1, 0);
+	if (ret) {
+		dev_err(ds->dev, "failed to reset switch\n");
+		return ret;
+	}
+	ret = mxl862xx_mmd_write(ds, 0, 0x9907);
+	if (ret) {
+		dev_err(ds->dev, "failed to reset switch\n");
+		return ret;
+	}
+	usleep_range(4000000, 6000000);
+
+	priv->port_info[priv->hw_info->cpu_port].tag_protocol = DSA_TAG_PROTO_MXL862_8021Q;
+
+	if (priv->port_info[priv->hw_info->cpu_port].tag_protocol == DSA_TAG_PROTO_MXL862) {
+		ret = mxl862_configure_tag_proto(ds, cpu_port, true);
+		if (ret)
+			return ret;
+	}
+
+	mxl862xx_mac_learning(ds, cpu_port, true);
+
+	for (i = 0; i < MAX_BRIDGES; i++)
+		priv->bridge_portmap[i] = BIT(DSA_MXL_PORT(cpu_port));
+
+	mxl862xx_set_vlan_filter_limits(ds);
+	for (i = 0; i < MAX_VLANS; i++)
+		priv->port_info[cpu_port].vlan.egress_vlan_block_info.vlans[i].untagged = true;
+
+	for (i = 0; i < priv->hw_info->phy_ports; i++) {
+		priv->port_info[i].vlan.filtering_mode_locked = false;
+		priv->port_info[i].isolated = true;
+
+		mxl862xx_port_state(ds, i, false);
+		mxl862xx_isolate_port(ds, i);
+		mxl862xx_port_fast_age(ds, i);
+	}
+
+	mxl862xx_port_fast_age(ds, cpu_port);
+
+	return 0;
+}
+
+static void mxl862xx_port_stp_state_set(struct dsa_switch *ds, int port,
+					u8 state)
+{
+	struct mxl862xx_stp_port_cfg param = {
+		.port_id = DSA_MXL_PORT(port),
+	};
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret;
+
+	switch (state) {
+	case BR_STATE_DISABLED:
+		param.port_state = MXL862XX_STP_PORT_STATE_DISABLE;
+		return;
+	case BR_STATE_BLOCKING:
+	case BR_STATE_LISTENING:
+		param.port_state = MXL862XX_STP_PORT_STATE_BLOCKING;
+		break;
+	case BR_STATE_LEARNING:
+		param.port_state = MXL862XX_STP_PORT_STATE_LEARNING;
+		break;
+	case BR_STATE_FORWARDING:
+		param.port_state = MXL862XX_STP_PORT_STATE_FORWARD;
+		break;
+	default:
+		dev_err(priv->dev, "invalid STP state: %d\n", state);
+		return;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_STP_PORTCFGSET, param);
+	if (ret)
+		dev_err(ds->dev, "failed to set STP state on port %d\n", port);
+
+	if (!priv->port_info[port].bridge || dsa_is_cpu_port(ds, port))
+		mxl862xx_mac_learning(ds, port, false);
+}
+
+static void mxl862xx_phylink_get_caps(struct dsa_switch *ds, int port,
+				      struct phylink_config *config)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+
+	config->mac_capabilities = MAC_ASYM_PAUSE | MAC_SYM_PAUSE | MAC_10 |
+				   MAC_100 | MAC_1000 | MAC_2500FD;
+
+	if (port >= 0 && port < priv->hw_info->phy_ports) {
+		__set_bit(PHY_INTERFACE_MODE_INTERNAL, config->supported_interfaces);
+	} else if (port == 8 || port == 9) {
+		__set_bit(PHY_INTERFACE_MODE_USXGMII, config->supported_interfaces);
+		config->mac_capabilities |= MAC_5000FD | MAC_10000FD;
+	} else if (port > 9) {
+		__set_bit(PHY_INTERFACE_MODE_NA, config->supported_interfaces);
+	}
+}
+
+static void mxl862xx_phylink_mac_config(struct phylink_config *config, unsigned int mode,
+					const struct phylink_link_state *state)
+{
+	struct dsa_port *dp = dsa_phylink_to_port(config);
+
+	switch (state->interface) {
+	case PHY_INTERFACE_MODE_INTERNAL:
+	case PHY_INTERFACE_MODE_SGMII:
+	case PHY_INTERFACE_MODE_USXGMII:
+		return;
+	default:
+		dev_err(dp->ds->dev, "Unsupported interface: %d\n", state->interface);
+		return;
+	}
+}
+
+static void mxl862xx_phylink_mac_link_down(struct phylink_config *config, unsigned int mode,
+					   phy_interface_t interface)
+{
+	struct dsa_port *dp = dsa_phylink_to_port(config);
+	struct mxl862xx_port_link_cfg param = {
+		.port_id = DSA_MXL_PORT(dp->index),
+		.link_force = true,
+		.link = MXL862XX_PORT_LINK_DOWN,
+	};
+	int ret;
+
+	if (dsa_is_cpu_port(dp->ds, dp->index))
+		return;
+
+	ret = MXL862XX_API_WRITE(dp->ds->priv, MXL862XX_COMMON_PORTLINKCFGSET, param);
+	if (ret)
+		dev_err(dp->ds->dev, "failed to stop link on port %d\n", dp->index);
+}
+
+static void mxl862xx_phylink_mac_link_up(struct phylink_config *config,
+					 struct phy_device *phydev, unsigned int mode,
+					 phy_interface_t interface, int speed, int duplex,
+					 bool tx_pause, bool rx_pause)
+{
+	struct dsa_port *dp = dsa_phylink_to_port(config);
+	struct mxl862xx_port_link_cfg port_link_cfg = {
+		.port_id = DSA_MXL_PORT(dp->index),
+		.link = MXL862XX_PORT_LINK_UP,
+		.duplex_force = true,
+		.speed_force = true,
+		.link_force = true,
+	};
+	struct mxl862xx_port_cfg port_cfg = {
+		.port_id = DSA_MXL_PORT(dp->index),
+	};
+	int ret;
+
+	if (dsa_is_cpu_port(dp->ds, dp->index))
+		return;
+
+	switch (speed) {
+	case SPEED_10:
+		port_link_cfg.speed = MXL862XX_PORT_SPEED_10;
+		break;
+	case SPEED_100:
+		port_link_cfg.speed = MXL862XX_PORT_SPEED_100;
+		break;
+	case SPEED_1000:
+		port_link_cfg.speed = MXL862XX_PORT_SPEED_1000;
+		break;
+	case SPEED_2500:
+		port_link_cfg.speed = MXL862XX_PORT_SPEED_2500;
+		break;
+	case SPEED_5000:
+		port_link_cfg.speed = MXL862XX_PORT_SPEED_5000;
+		break;
+	case SPEED_10000:
+		port_link_cfg.speed = MXL862XX_PORT_SPEED_10000;
+		break;
+	default:
+		dev_err(dp->ds->dev, "unsupported links speed on port %d\n", dp->index);
+		return;
+	}
+
+	switch (duplex) {
+	case DUPLEX_HALF:
+		port_link_cfg.duplex = MXL862XX_DUPLEX_HALF;
+		break;
+	case DUPLEX_FULL:
+		port_link_cfg.duplex = MXL862XX_DUPLEX_FULL;
+		break;
+	default:
+		port_link_cfg.duplex = MXL862XX_DUPLEX_AUTO;
+		break;
+	}
+
+	ret = MXL862XX_API_WRITE(dp->ds->priv, MXL862XX_COMMON_PORTLINKCFGSET, port_link_cfg);
+	if (ret) {
+		dev_err(dp->ds->dev, "failed to configure link on port %d\n", dp->index);
+		return;
+	}
+
+	ret = MXL862XX_API_READ(dp->ds->priv, MXL862XX_COMMON_PORTCFGGET, port_cfg);
+	if (ret) {
+		dev_err(dp->ds->dev, "failed to read configuration on port %d\n", dp->index);
+		return;
+	}
+
+	if (tx_pause && rx_pause)
+		port_cfg.flow_ctrl = MXL862XX_FLOW_RXTX;
+	else if (tx_pause)
+		port_cfg.flow_ctrl = MXL862XX_FLOW_TX;
+	else if (rx_pause)
+		port_cfg.flow_ctrl = MXL862XX_FLOW_RX;
+	else
+		port_cfg.flow_ctrl = MXL862XX_FLOW_OFF;
+
+	ret = MXL862XX_API_WRITE(dp->ds->priv, MXL862XX_COMMON_PORTCFGSET, port_cfg);
+	if (ret)
+		dev_err(dp->ds->dev, "failed to configure port %d\n", dp->index);
+}
+
+static void mxl862xx_get_ethtool_stats(struct dsa_switch *ds, int port,
+				       uint64_t *data)
+{
+	struct mxl862xx_debug_rmon_port_cnt param = {
+		.port_id = DSA_MXL_PORT(port),
+		.port_type = MXL862XX_RMON_CTP_PORT_RX,
+	};
+	u8 *mibs = (void *)&param;
+	int ret, i;
+
+	ret = MXL862XX_API_READ(ds->priv, MXL862XX_DEBUG_RMON_PORT_GET, param);
+	if (ret) {
+		dev_err(ds->dev, "failed to read RX stats on port %d\n", port);
+		return;
+	}
+	for (i = 0; i < ARRAY_SIZE(mxl862xx_mibs_rx); i++)
+		*data++ = (u32)mibs[mxl862xx_mibs_rx[i].offset];
+
+	param.port_type = MXL862XX_RMON_CTP_PORT_RX;
+	ret = MXL862XX_API_READ(ds->priv, MXL862XX_DEBUG_RMON_PORT_GET, param);
+	if (ret) {
+		dev_err(ds->dev, "failed to read RX stats on port %d\n", port);
+		return;
+	}
+	for (i = 0; i < ARRAY_SIZE(mxl862xx_mibs_tx); i++)
+		*data++ = (u32)mibs[mxl862xx_mibs_tx[i].offset];
+}
+
+static void mxl862xx_get_strings(struct dsa_switch *ds, int port,
+				 u32 stringset, u8 *data)
+{
+	u8 i;
+
+	if (stringset != ETH_SS_STATS)
+		return;
+
+	for (i = 0; i < ARRAY_SIZE(mxl862xx_mibs_rx); i++)
+		ethtool_puts(&data, mxl862xx_mibs_rx[i].name);
+
+	for (i = 0; i < ARRAY_SIZE(mxl862xx_mibs_tx); i++)
+		ethtool_puts(&data, mxl862xx_mibs_tx[i].name);
+}
+
+static int mxl862xx_get_sset_count(struct dsa_switch *ds, int port, int sset)
+{
+	if (sset != ETH_SS_STATS)
+		return 0;
+
+	return ARRAY_SIZE(mxl862xx_mibs_rx) + ARRAY_SIZE(mxl862xx_mibs_tx);
+}
+
+static int mxl862xx_port_mirror_add(struct dsa_switch *ds, int port,
+				    struct dsa_mall_mirror_tc_entry *mirror,
+				    bool ingress, struct netlink_ext_ack *extack)
+{
+	struct mxl862xx_ctp_port_config ctp_port = {
+		.logical_port_id = DSA_MXL_PORT(port),
+		.mask = MXL862XX_CTP_PORT_CONFIG_MASK_ALL,
+	};
+	struct mxl862xx_monitor_port_cfg monitor_port = {
+		.port_id = DSA_MXL_PORT(mirror->to_local_port),
+	};
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret;
+
+	ret = MXL862XX_API_READ(priv, MXL862XX_CTP_PORTCONFIGGET, ctp_port);
+	if (ret) {
+		dev_err(ds->dev, "failed to enable mirroring on port %d\n", port);
+		return ret;
+	}
+
+	ctp_port.mask = MXL862XX_CTP_PORT_CONFIG_LOOPBACK_AND_MIRROR;
+	ctp_port.ingress_mirror_enable = ingress;
+	ctp_port.egress_mirror_enable = !ingress;
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_CTP_PORTCONFIGSET, ctp_port);
+	if (ret) {
+		dev_err(ds->dev, "failed to enable monitoring on port %d\n", port);
+		return ret;
+	}
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_COMMON_MONITORPORTCFGSET, monitor_port);
+	if (ret) {
+		dev_err(ds->dev, "failed to setup monitor port\n");
+		return ret;
+	}
+
+	if (mirror->ingress)
+		priv->port_info[port].ingress_mirror_enabled = true;
+	else
+		priv->port_info[port].egress_mirror_enabled = true;
+
+	return 0;
+}
+
+static void mxl862xx_port_mirror_del(struct dsa_switch *ds, int port,
+				     struct dsa_mall_mirror_tc_entry *mirror)
+{
+	struct mxl862xx_ctp_port_config param = {
+		.logical_port_id = DSA_MXL_PORT(port),
+		.mask = MXL862XX_CTP_PORT_CONFIG_LOOPBACK_AND_MIRROR,
+	};
+	struct mxl862xx_priv *priv = ds->priv;
+	u8 phy_ports = priv->hw_info->phy_ports;
+	int active_mirrors = 0;
+	int ret, i;
+
+	if (mirror->ingress)
+		priv->port_info[port].ingress_mirror_enabled = false;
+	else
+		priv->port_info[port].egress_mirror_enabled = false;
+
+	ret = MXL862XX_API_WRITE(priv, MXL862XX_CTP_PORTCONFIGSET, param);
+	if (ret) {
+		dev_err(ds->dev, "failed to disable mirroring on port %d\n", port);
+		return;
+	}
+
+	for (i = 0; i < phy_ports; i++)
+		if (priv->port_info[i].egress_mirror_enabled ||
+		    priv->port_info[i].egress_mirror_enabled)
+			active_mirrors = 1;
+
+	if (!active_mirrors) {
+		struct mxl862xx_monitor_port_cfg monitor_port = { };
+
+		ret = MXL862XX_API_WRITE(priv, MXL862XX_COMMON_MONITORPORTCFGSET, monitor_port);
+		if (ret)
+			dev_err(ds->dev, "failed to release monitor port\n");
+	}
+}
+
+static int mxl862xx_port_fdb_add(struct dsa_switch *ds, int port,
+				 const unsigned char *addr, u16 vid, struct dsa_db db)
+{
+	struct mxl862xx_mac_table_add param = {
+		.port_id = DSA_MXL_PORT(port),
+		.tci = vid & 0xFFF,
+		.static_entry = true,
+	};
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret, i;
+
+	memcpy(param.mac, addr, ETH_ALEN);
+
+	for (i = 0; i < priv->hw_info->phy_ports; i++) {
+		if (!dsa_is_cpu_port(ds, port) && i != port)
+			continue;
+
+		if (priv->port_info[i].isolated)
+			continue;
+
+		param.fid = priv->port_info[i].bridge_id;
+		ret = MXL862XX_API_READ(ds->priv, MXL862XX_MAC_TABLEENTRYADD, param);
+		if (ret) {
+			dev_err(ds->dev, "failed to add FDB entry on port %d / fid %d\n",
+				port, param.fid);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int mxl862xx_port_fdb_del(struct dsa_switch *ds, int port,
+				 const unsigned char *addr, u16 vid, struct dsa_db db)
+{
+	struct mxl862xx_mac_table_remove param = {
+		.tci = vid & 0xFFF,
+	};
+	struct mxl862xx_priv *priv = ds->priv;
+	int ret, i;
+
+	memcpy(param.mac, addr, ETH_ALEN);
+
+	for (i = 0; i < priv->hw_info->phy_ports; i++) {
+		if (!dsa_is_cpu_port(ds, port) && i != port)
+			continue;
+
+		param.fid = priv->port_info[i].bridge_id;
+		ret = MXL862XX_API_READ(priv, MXL862XX_MAC_TABLEENTRYREMOVE, param);
+		if (ret) {
+			dev_err(ds->dev, "failed to remove FDB entry on port %d / fid %d\n",
+				port, param.fid);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int mxl862xx_port_fdb_dump(struct dsa_switch *ds, int port,
+				  dsa_fdb_dump_cb_t *cb, void *data)
+{
+	struct mxl862xx_mac_table_read param = {
+		.initial = 1,
+	};
+	int ret;
+
+	while (true) {
+		ret = MXL862XX_API_READ(ds->priv, MXL862XX_MAC_TABLEENTRYREAD, param);
+		if (ret) {
+			dev_err(ds->dev, "failed to read FDB entries on port %d\n", port);
+			return ret;
+		}
+
+		if (param.last == 1)
+			break;
+
+		if (param.port_id == DSA_MXL_PORT(port))
+			cb(param.mac, param.tci & 0x0FFF, param.static_entry, data);
+
+		memset(&param, 0, sizeof(param));
+	}
+
+	return 0;
+}
+
+static int mxl862xx_port_pre_bridge_flags(struct dsa_switch *ds, int port,
+					  struct switchdev_brport_flags flags,
+					  struct netlink_ext_ack *extack)
+{
+	if (flags.mask & ~(BR_FLOOD | BR_MCAST_FLOOD | BR_BCAST_FLOOD |
+			   BR_LEARNING | BR_PORT_LOCKED)) {
+		dev_err(ds->dev, "unsupported bridge flags on port %d\n", port);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int mxl862xx_port_bridge_flags(struct dsa_switch *ds, int port,
+				      struct switchdev_brport_flags flags,
+				      struct netlink_ext_ack *extack)
+{
+	struct mxl862xx_priv *priv = ds->priv;
+	bool bridge_ctx = true;
+	u16 bridge_id;
+	int ret = 0;
+
+	if (!dsa_is_user_port(ds, port))
+		return 0;
+
+	bridge_id = priv->port_info[port].bridge_id;
+	if (!bridge_id || !priv->port_info[port].bridge)
+		bridge_ctx = false;
+
+	if (bridge_ctx && (flags.mask & (BR_FLOOD | BR_MCAST_FLOOD | BR_BCAST_FLOOD))) {
+		struct mxl862xx_bridge_config bridge_config = { };
+
+		bridge_config.mask = MXL862XX_BRIDGE_CONFIG_MASK_FORWARDING_MODE;
+		bridge_config.bridge_id = bridge_id;
+
+		if (flags.mask & BR_FLOOD)
+			bridge_config.forward_unknown_unicast = (flags.val & BR_FLOOD) ?
+				MXL862XX_BRIDGE_FORWARD_FLOOD : MXL862XX_BRIDGE_FORWARD_DISCARD;
+
+		if (flags.mask & BR_MCAST_FLOOD) {
+			bridge_config.forward_unknown_multicast_ip = (flags.val & BR_MCAST_FLOOD) ?
+				MXL862XX_BRIDGE_FORWARD_FLOOD : MXL862XX_BRIDGE_FORWARD_DISCARD;
+			bridge_config.forward_unknown_multicast_non_ip =
+				bridge_config.forward_unknown_multicast_ip;
+		}
+
+		if (flags.mask & BR_BCAST_FLOOD)
+			bridge_config.forward_broadcast = (flags.val & BR_BCAST_FLOOD) ?
+				MXL862XX_BRIDGE_FORWARD_FLOOD : MXL862XX_BRIDGE_FORWARD_DISCARD;
+
+		ret = MXL862XX_API_WRITE(ds->priv, MXL862XX_BRIDGE_CONFIGSET, bridge_config);
+		if (ret) {
+			dev_err(ds->dev, "%s: Port:%d bridge:%d configuration  failed\n",
+				__func__, port, bridge_config.bridge_id);
+			return ret;;
+		}
+	}
+
+	if (flags.mask & BR_LEARNING)
+		mxl862xx_mac_learning(ds, port, flags.val & BR_LEARNING);
+
+	return 0;
+}
+
+static enum dsa_tag_protocol mxl862xx_get_tag_protocol(struct dsa_switch *ds,
+						       int port, enum dsa_tag_protocol m)
+{
+/* ToDo */
+	return DSA_TAG_PROTO_MXL862_8021Q;
+}
+
+static int mxl862xx_change_tag_protocol(struct dsa_switch *ds,
+				     enum dsa_tag_protocol proto)
+{
+/* ToDo */
+	return 0;
+};
+
+static const struct phylink_mac_ops mxl862xx_phylink_mac_ops = {
+	.mac_config = mxl862xx_phylink_mac_config,
+	.mac_link_down = mxl862xx_phylink_mac_link_down,
+	.mac_link_up = mxl862xx_phylink_mac_link_up,
+};
+
+static const struct dsa_switch_ops mxl862xx_switch_ops = {
+	.get_ethtool_stats = mxl862xx_get_ethtool_stats,
+	.get_strings = mxl862xx_get_strings,
+	.get_sset_count = mxl862xx_get_sset_count,
+	.change_tag_protocol = mxl862xx_change_tag_protocol,
+	.get_tag_protocol = mxl862xx_get_tag_protocol,
+	.phy_read = mxl862xx_phy_read,
+	.phy_write = mxl862xx_phy_write,
+	.phylink_get_caps = mxl862xx_phylink_get_caps,
+	.set_ageing_time = mxl862xx_set_ageing_time,
+	.port_bridge_join = mxl862xx_port_bridge_join,
+	.port_bridge_leave = mxl862xx_port_bridge_leave,
+	.port_disable = mxl862xx_port_disable,
+	.port_enable = mxl862xx_port_enable,
+	.port_fast_age = mxl862xx_port_fast_age,
+	.port_stp_state_set = mxl862xx_port_stp_state_set,
+	.port_mirror_add = mxl862xx_port_mirror_add,
+	.port_mirror_del = mxl862xx_port_mirror_del,
+	.port_vlan_filtering = mxl862xx_port_vlan_filtering,
+	.port_vlan_add = mxl862xx_port_vlan_add,
+	.port_vlan_del = mxl862xx_port_vlan_del,
+	.port_fdb_add = mxl862xx_port_fdb_add,
+	.port_fdb_del = mxl862xx_port_fdb_del,
+	.port_fdb_dump = mxl862xx_port_fdb_dump,
+	.port_pre_bridge_flags = mxl862xx_port_pre_bridge_flags,
+	.port_bridge_flags = mxl862xx_port_bridge_flags,
+	.setup = mxl862xx_setup,
+};
+
+static int mxl862xx_probe(struct mdio_device *mdiodev)
+{
+	struct mxl862xx_sys_fw_image_version fw_version;
+	struct device *dev = &mdiodev->dev;
+	struct mxl862xx_priv *priv;
+	struct dsa_switch *ds;
+	int ret;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	priv->dev = dev;
+	priv->bus = mdiodev->bus;
+	priv->sw_addr = mdiodev->addr;
+	priv->hw_info = of_device_get_match_data(dev);
+	if (!priv->hw_info)
+		return -EINVAL;
+
+	mutex_init(&priv->pce_table_lock);
+
+	ds = devm_kzalloc(dev, sizeof(*ds), GFP_KERNEL);
+	if (!ds)
+		return -ENOMEM;
+
+	priv->ds = ds;
+	ds->dev = dev;
+	ds->priv = priv;
+	ds->ops = &mxl862xx_switch_ops;
+	ds->phylink_mac_ops = &mxl862xx_phylink_mac_ops;
+	ds->num_ports = priv->hw_info->max_ports;
+	ds->assisted_learning_on_cpu_port = true;
+
+	dev_set_drvdata(dev, ds);
+
+	ret = dsa_register_switch(ds);
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "failed to register DSA switch\n");
+		return ret;
+	}
+
+	ret = MXL862XX_API_READ(priv, SYS_MISC_FW_VERSION, fw_version);
+	if (ret) {
+		dev_err(dev, "failed to read firmware version\n");
+		return -EINVAL;
+	}
+
+	dev_info(dev, "Firmware version %d.%d.%d.%d",
+		 fw_version.iv_major, fw_version.iv_minor,
+		 fw_version.iv_revision, fw_version.iv_build_num);
+
+	return 0;
+}
+
+static void mxl862xx_remove(struct mdio_device *mdiodev)
+{
+	struct dsa_switch *ds = dev_get_drvdata(&mdiodev->dev);
+
+	dsa_unregister_switch(ds);
+}
+
+static const struct mxl862xx_hw_info mxl86282_data = {
+	.max_ports = 9,
+	.phy_ports = 8,
+	.cpu_port = 8,
+};
+
+static const struct mxl862xx_hw_info mxl86252_data = {
+	.max_ports = 9,
+	.phy_ports = 5,
+	.cpu_port = 8,
+};
+
+static const struct of_device_id mxl862xx_of_match[] = {
+	{ .compatible = "mxl,86282", .data = &mxl86282_data },
+	{ .compatible = "mxl,86252", .data = &mxl86252_data },
+	{ /* sentinel */ },
+};
+
+MODULE_DEVICE_TABLE(of, mxl862xx_of_match);
+
+static struct mdio_driver mxl862xx_driver = {
+	.probe  = mxl862xx_probe,
+	.remove = mxl862xx_remove,
+	.mdiodrv.driver = {
+		.name = "mxl862xx",
+		.of_match_table = mxl862xx_of_match,
+	},
+};
+
+mdio_module_driver(mxl862xx_driver);
+
+MODULE_DESCRIPTION("Driver for MaxLinear MxL862xx switch family");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:mxl862xx");
diff --git a/drivers/net/dsa/mxl862xx/mxl862xx.h b/drivers/net/dsa/mxl862xx/mxl862xx.h
new file mode 100644
index 000000000000..c500793ef976
--- /dev/null
+++ b/drivers/net/dsa/mxl862xx/mxl862xx.h
@@ -0,0 +1,86 @@
+#define VID_RULES 2
+#define MAX_VLANS  100
+#define MAX_PORTS 13
+#define MAX_BRIDGES 16
+
+struct mxl862xx_hw_info {
+	u8 max_ports;
+	u8 phy_ports;
+	u8 cpu_port;
+};
+
+struct mxl862xx_filter_ids {
+	s16 filters_idx[VID_RULES];
+	bool valid;
+};
+
+struct mxl862xx_vlan {
+	bool used;
+	u16 vid;
+	/* indexes of filtering rules(entries) used for this VLAN */
+	s16 filters_idx[VID_RULES];
+	/* Indicates if tags are added for eggress direction. Makes sense only in egress block */
+	bool untagged;
+};
+
+struct mxl862xx_extended_vlan_block_info {
+	bool allocated;
+	/* current index of the VID related filtering rules  */
+	u16 vid_filters_idx;
+	/* current index of the final filtering rules;
+	 * counted backwards starting from the block end
+	 */
+	u16 final_filters_idx;
+	/* number of allocated  entries for filtering rules */
+	u16 filters_max;
+	/* number of entries per vlan */
+	u16 entries_per_vlan;
+	u16 block_id;
+	/* use this for storing indexes of vlan entries
+	 * for VLAN delete
+	 */
+	struct mxl862xx_vlan vlans[MAX_VLANS];
+	/* collect released filter entries (pairs) that can be reused */
+	struct mxl862xx_filter_ids filter_entries_recycled[MAX_VLANS];
+};
+
+struct mxl862xx_port_vlan_info {
+	u16 pvid;
+	bool filtering;
+	/* Allow one-time initial vlan_filtering port attribute configuration. */
+	bool filtering_mode_locked;
+	/* Only one block can be assigned per port and direction. Take care about releasing
+	 * the previous one when overwriting with the new one
+	 */
+	struct mxl862xx_extended_vlan_block_info ingress_vlan_block_info;
+	struct mxl862xx_extended_vlan_block_info egress_vlan_block_info;
+};
+
+struct mxl862xx_port_info {
+	bool port_enabled;
+	bool isolated;
+	u16 bridge_id;
+	u16 bridge_port_cpu;
+	struct net_device *bridge;
+	enum dsa_tag_protocol tag_protocol;
+	bool ingress_mirror_enabled;
+	bool egress_mirror_enabled;
+	struct mxl862xx_port_vlan_info vlan;
+};
+
+struct mxl862xx_priv {
+	struct dsa_switch *ds;
+	struct mii_bus *bus;
+	struct device *dev;
+	int sw_addr;
+	const struct mxl862xx_hw_info *hw_info;
+	struct mxl862xx_port_info port_info[MAX_PORTS];
+	u16 bridge_portmap[MAX_BRIDGES];
+	/* Number of simultaneously supported vlans (calculated in the runtime) */
+	u16 max_vlans;
+	/* pce_table_lock required for kernel 5.16 or later,
+	 * since rtnl_lock has been dropped from DSA.port_fdb_{add,del}
+	 * might cause dead-locks / hang in previous versions
+	 */
+	struct mutex pce_table_lock;
+};
-- 
2.39.5

